{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Redes neuronales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En el cuaderno anterior hemos creado una red con varias neuronas, así que es necesario explicar cómo se conectan varias neuronas (perceptrones) para formar una red neuronal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"text-align:center;\">\n",
        "  <img src=\"Imagenes/red_neuronal_profunda.PNG\" alt=\"red neuronal profunda\"> <!-- style=\"width:425px;height:425px;\" -->\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aquí podemos ver un ejemplo de red neuronal genérica, veamos algunas características:\n",
        " * Se puede tener todas las entradas que se quiera\n",
        " * Las entradas entran a la primera capa de la red que se suele llamar capa de entrada o en inglés input layer. Esta capa puede tener todas las neuronas que se quiera\n",
        " * Después la información se propaga a las capas intermedias que se suelen llamar capas ocultas o hidden layers. Puede haber tantas capas ocultas como se quiera, y cada una de ellas puede tener las neuronas que se quiera también, no es necesario que todas tengan el mismo número de neuronas\n",
        " * Por último la información va a la capa de salida o output layer. Esta capa suele tener el mismo número de neuronas que soluciones queremos que tenga nuestra red. Por ejemplo, si quieremos usar la red para crear un clasificador de números, como hay 10 diferentes números, la capa de salida debería tener 10 neuronas.\n",
        " * Todas las entradas están conectadas a todas las neuronas de la capa de entrada\n",
        " * En el resto de la red, todas las neuronas de una capa están conectadas a todas las neuronas de la otra capa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En cada neurona de la capa de entrada va a entrar cada una de las entradas de la red, por lo que el cálculo que hará cada una de las neuronas de la capa de entrada será\n",
        "\n",
        "$$ z_{0} = \\omega_{00} + \\omega_{01}x_1 + \\omega_{02}x_2 + \\omega_{03}x_3 + \\omega_{04}x_4 + ... + \\omega_{0n}x_n = \\omega_{00} + \\sum_{i=1}^{n}{\\omega_{0i}x_i}$$\n",
        "$$ z_{1} = \\omega_{10} + \\omega_{11}x_1 + \\omega_{12}x_2 + \\omega_{13}x_3 + \\omega_{14}x_4 + ... + \\omega_{1n}x_n = \\omega_{10} + \\sum_{i=1}^{n}{\\omega_{1i}x_i}$$\n",
        "$$...$$\n",
        "$$ z_{m} = \\omega_{m0} + \\omega_{m1}x_1 + \\omega_{m2}x_2 + \\omega_{m3}x_3 + \\omega_{m4}x_4 + ... + \\omega_{mn}x_n = \\omega_{m0} + \\sum_{i=1}^{n}{\\omega_{mi}x_i}$$\n",
        "\n",
        "Donde $n$ es el número de entradas a la red y $m$ es el número de neuronas de la capa de entrada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A cada uno de estos cálculos hay que aplicarles la función de activación, que puede ser la que queramos, con tal de que rompa la linealida\n",
        "\n",
        "$$ \\sigma_{0} = f\\left(z_0 \\right)$$\n",
        "$$ \\sigma_{2} = f\\left(z_1 \\right)$$\n",
        "$$...$$\n",
        "$$ \\sigma_{m} = f\\left(z_m \\right)$$\n",
        "\n",
        "Estos valores de $\\sigma$ serán las entradas para las siguientes capas y así sucesivamente hasta el final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos a poner las ecuaciones de la segunda capa, pero sería igual en el resto de capas\n",
        "\n",
        "$$ z_{0} = \\omega_{00} + \\omega_{01}\\sigma_1 + \\omega_{02}\\sigma_2 + \\omega_{03}\\sigma_3 + \\omega_{04}\\sigma_4 + ... + \\omega_{0m}\\sigma_n = \\omega_{00} + \\sum_{i=1}^{m}{\\omega_{0i}\\sigma_i}$$\n",
        "$$ z_{1} = \\omega_{10} + \\omega_{11}\\sigma_1 + \\omega_{12}\\sigma_2 + \\omega_{13}\\sigma_3 + \\omega_{14}\\sigma_4 + ... + \\omega_{1m}\\sigma_n = \\omega_{10} + \\sum_{i=1}^{m}{\\omega_{1i}\\sigma_i}$$\n",
        "$$...$$\n",
        "$$ z_{m} = \\omega_{p0} + \\omega_{p1}\\sigma_1 + \\omega_{p2}\\sigma_2 + \\omega_{p3}\\sigma_3 + \\omega_{p4}\\sigma_4 + ... + \\omega_{pm}\\sigma_n = \\omega_{p0} + \\sum_{i=1}^{m}{\\omega_{pi}\\sigma_i}$$\n",
        "\n",
        "En este caso $m$ es el número de entradas de cada neurona, que correspone al numero de salidas de la capa anterior. Y $p$ es el número de neuronas de la segunda capa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Por último se vuelven a aplicar las funciones de activación, que no tienen por que ser las mismas que la de la capa anterior\n",
        "\n",
        "$$ \\sigma_{0} = f\\left(z_0 \\right)$$\n",
        "$$ \\sigma_{2} = f\\left(z_1 \\right)$$\n",
        "$$...$$\n",
        "$$ \\sigma_{p} = f\\left(z_p \\right)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Todos estos pesos que aparecen ($\\omega$), son los que se modificarán en el entrenamiento de la red"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "d1c24abb23a313e1f9ae042292cd8e6e3c60c5818227ced3d46e3df2c65171ef"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
