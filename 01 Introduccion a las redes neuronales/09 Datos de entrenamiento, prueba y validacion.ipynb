{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Datos de entrenamiento, prueba y validación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hasta ahora hemos visto ejemplos dónde solo teníamos datos de entrenamiento, pero en la práctica no se suele hacer esto, sino que se dividen los datos en **entrenamiento**, **test** y **validación**.\n",
        "\n",
        "Esto es porque si a la red solo le damos datos de entrenamiento, y repetimos muchas veces el proceso de entrenamiento podemos hacer que la red aprenda a predecir las salidas de nuestros datos de entrenamiento, pero no se ajuste a la realidad del problema. Esto se puede ver muy bien en la siguiente imagen\n",
        "\n",
        "<div style=\"text-align:center;\">\n",
        "  <img src=\"Imagenes/sobreentrenamiento.png\" alt=\"subentrenamiento, entrenamiento y sobreentrenamiento\"> <!-- style=\"width:425px;height:425px;\" -->\n",
        "</div>\n",
        "\n",
        "Como podemos ver, a la derecha, se ha entrenado tanto a la red que es capaz de predecir el valor exacto de cada dato de entrenamiento, pero en realidad el algoritmo que más se asemeja a la realidad de los datos es el que genera la salida de la imagen de en medio\n",
        "\n",
        "Por último tenemos el caso de que entrenemos tan poco a la red que no sea capaz de generar una salida válida"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Que una red esté subentrenada, bien entrenada o sobre entrenada se ajusta mediante el número de steps o épocas, que es el número de veces que la red pasa por todos los datos que tenemos de entrenamiento para modificar los pesos.\n",
        "\n",
        "A priori no tendremos un número exacto de las épocas que tenemos que hacer que la red entrene, así que lo tenemos que ir modificando mediante prueba y error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Datos de validación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "¿Cómo sabemos que la red ha aprendido y no se ha sobre entrenado? Contrastando con los datos de validación\n",
        "\n",
        "Cada vez que la red ha visto todos los datos de entrenamiento se prueba a esta sobre los datos de validación y medimos el error de la red en los datos de validación, de manera que debemos esperar a que la red tenga menos error en el conjunto de datos de entrenamiento y en el conjunto de datos de validación. Hecho esto volvemos a pasar a la red por los datos de entrenamiento y luego por los datos de validación\n",
        "\n",
        "Realizamos este proceso hasta que lleguemos a una error de entrenamiento y de validación que consideremos bueno"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos a ver gráficamente lo que estamos haciendo\n",
        "\n",
        "<div style=\"text-align:center;\">\n",
        "  <img src=\"Imagenes/evolucion_error_train_test.png\" alt=\"evolución de los errores de entrenamiento y test durente el entrenamiento de una red neuronal\", style=\"width:550px;height:425px;\">\n",
        "</div>\n",
        "\n",
        "Si durante el proceso de entrenamiento representamos el error de la red con los datos de entrenamiento y con los datos de validación obtendremos una gráfica como la anterior.\n",
        "\n",
        "En ella se puede ver como a medida que se entrena el error de la red con los datos de entrenamiento disminuye, lo cual tiene sentido ya que estamos haciendo que los pesos de la red sean los mejores para nuestro problema. Tambien vemos como este error cada vez varía menos, ya que llegarmos a un punto donde la mejora del error sera muy poca con cada cambio en los pesos\n",
        "\n",
        "También se puede ver que el error de la red con los datos de validación disminuye, hasta que llega un momento en el que empieza a aumentar, esto es porque estamos mejorando la red, haciendo que sea buena para nuestro problema, hasta que llega un momento en el que se está ajustando demasiado a nuestros datos de entrenamiento (imagen de la derecha de arriba), por lo que si se le meten datos nuevos (de validación) a la red que no ha visto no es capaz de generalizar bien, ya que se está amoldando demasiado a los datos de entrenamiento\n",
        "\n",
        "Por tanto entrenamos a la red haciendo que deje de estar en la zona de subentrenamiento, hasta que llega a un punto en el que la red es lo mejor posible para nuestros datos. A partir de aquí si seguimos entrenando, la red se amolda demasiado a los datos de entrenamiento, no es capaz de generalizar y entramos en la zona de sobreentrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Durante el entrenamiento de una red neuronal debemos ir monitorizando estos errores durante el proceso de entrenamiento y parar este cuando creamos que estamos entrando en la zona de sobreentrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Datos de test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cuando nos enfrentamos a un nuevo problema lo que se suele hacer es entrenar muchos tipos distintos de redes, modificando sus hiperparámetros como el learning rate, número de épocas, dimensiones de la red, etc. Hacemos esto siempre monitorizando los errores de entrenamiento y validación y parando antes de entrenar en la zona de sobreentrenamiento.\n",
        "\n",
        "Sin embargo si te fijas estamos haciendo con los datos de validación algo parecido a lo que hacemos con los datos de entrenamiento, entrenamos distintas redes con distintos hiperparámetros para obtener el mejor error de validación posible. Es decir, estamos modificando todo lo que podemos para obtener una red que tiene muy buenos resultados con los datos de validación, pero con tanto probar puede que estemos sobreentrenando a las redes frente a los datos de validación. Es decir, estamos consiguiendo redes que funcionan muy bien con los datos de entrenamiento y validación, pero nada nos dice que no se haya ajustado bien a estos dos conjuntos de datos y esté sobreentrenada en estos datos.\n",
        "\n",
        "Otra forma de verlo es como si juntásemos el conjunto de datos de entrenamiento y validación y consideremos todo datos de entrenamiento, de modo que podemos obtener redes sobreentrenadas con tanto ajuste"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para solucionar esto probamos unas cuantas redes que han obtenido buenos resultados sobre los datos de test, así podemos descartar que hayamos hecho sobreentrenamiento sobre el conjunto de datos de entrenamiento y validación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## División de datos en conjunto de datos de entrenamiento, test y validación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A día de hoy solemos tener una gran cantidad de datos para entrenar nuestras redes, estamos en la época del big data, por lo que se suelen separar los datos de manera que tengamos suficientes datos de test y validación, por ejemplo 1.000 datos para test y 1.000 para validación. Estos son números que dependen de cada caso, a lo mejor tenemos tantos que podemos separar en 100.000 y 100.000 es algo que se tiene que estudiar en cada problema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sin embargo si no tenemos muchos datos para entrenar nuestra red, lo que se puede hacer es separar estos en un 70% para entrenamiento, un 15% para test y un 15% para validación, o un 80%-10%-10%. Al igual que antes, depende de cada problema y hay que valorar cada caso en particular"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "d1c24abb23a313e1f9ae042292cd8e6e3c60c5818227ced3d46e3df2c65171ef"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
