{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Frameworks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como hemos visto cada vez que hemos creado una nueva arquitectura, ya sea un solo perceptron, varios, con o sin funciones de activación, hemos tenido que hacer todos los cálculos de derivadas y programarlos.\n",
        "\n",
        "Esto no es nada eficiente, ya que se pierde un montón de tiempo, da lugar a bugs que son muy difíciles de depurar y el código no está todo lo optimizado que debería.\n",
        "\n",
        "Por ello es necesario el uso de frameworks que nos evitan esto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora mismo hay dos frameworks por encime del resto [Pytorch](https://pytorch.org/) y [TensoFlow](https://www.tensorflow.org/). En ambos la implementación de redes neuronales y su entrenamiento se hace con unas pocas líneas de código y no tenemos que ser nosotros los que tengamos que codificar todo.\n",
        "\n",
        "Vamos a ver dos ejemplos donde se hace esto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Pytorch**\n",
        "\n",
        "``` python\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "import torch\n",
        "\n",
        "\n",
        "training_data = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "test_data = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "\n",
        "BS = 64\n",
        "train_dataloader = DataLoader(training_data, batch_size=BS, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=BS, shuffle=True)\n",
        "\n",
        "\n",
        "class NeuralNetworkFromScratch(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetworkFromScratch, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(3*32*32, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "model_scratch = NeuralNetworkFromScratch()\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model_scratch.to(device)\n",
        "\n",
        "\n",
        "LR = 1e-2\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model_scratch.parameters(), lr=LR)\n",
        "\n",
        "\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # X and y to device\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            # X and y to device\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            \n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "\n",
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model_scratch, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model_scratch, loss_fn)\n",
        "print(\"Done!\")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **TensorFlow**\n",
        "\n",
        "``` python\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "model.evaluate(x_test,  y_test, verbose=2)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como se puede ver con Pytorch se necesita mucho más código que con TensorFlow, esto es porque en realidad TensorFlow adoptó a Keras como una librería de alto nivel que actúa por encima y que reduce mucho el código. Por lo que para comparar realmente la cantidad de código deberíamos comparar una librería de más alto nivel sobre Pytorch con TensorFlow usando Keras. Sin embargo no hay una librería oficial por encima de Pytorch, las dos más populares son [fastai](https://www.fast.ai/) o [Pytorch Lightning](https://www.pytorchlightning.ai/).\n",
        "\n",
        "Vamos a ver un ejemplo sencillo con fastai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **FastAI**\n",
        "\n",
        "```python\n",
        "from fastai.vision.all import *\n",
        "path = untar_data(URLs.PETS)/'images'\n",
        "\n",
        "def is_cat(x): return x[0].isupper()\n",
        "dls = ImageDataLoaders.from_name_func(\n",
        "    path, get_image_files(path), valid_pct=0.2, seed=42,\n",
        "    label_func=is_cat, item_tfms=Resize(224))\n",
        "\n",
        "learn = cnn_learner(dls, resnet34, metrics=error_rate)\n",
        "learn.fine_tune(1)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como se puede ver, usando una librería por encima de Pytorch el código se reduce"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ¿Por qué elegir Pytorch frente a TensorFlow?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pytorch tiene muchas ventajas frente a tensorFlow. Como hemos visto antes no podemos compararlos por la cantidad de código que se genera con uno y con otro, porque vemos que no están a la misma altura. Si usamos una librería de alto nivel con Pytorch, la cantidad de lineas que necesitamos baja mucho"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Facilidad de uso"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pytorch se diseño para programarse muy parecido a como se programa en Python, sobre todo cómo se programa Python usando [Numpy](https://numpy.org/), que es una librería de cálculo matricial muy usada dentro del ecosistema Python. Por lo que si sabes usar Numpy, aprender Pytorch te será muy sencillo, ya que incluso muchas funciones se llaman igual, con la diferencia de que con Pytorch podemos hacer las operaciones en la GPU, lo cual se hace mucho más rápido"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Disponibilidad de redes preentrenadas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como ya se ha explicado hay redes como GPT-3 que tienen tantos parámetros que son imposibles de entrenar desde cero por cualquier persona, incluso empresa, por lo que poder utilizar modelos preentrenados de redes neuronales y ajustarlas a nuestro problema es esencial\n",
        "\n",
        "[HuggingFace](https://huggingface.co/) es una de las páginas más usadas para descargarse estos modelos preentrenados. En la siguiente imagen podemos ver como hay una gran cantidad de modelos disponibles solo para Pytorch, mientras que para TensorFlow o ambos son muchos menos. Por lo que a la hora de poderse descargar redes preentrenadas es mejor si estamos utilizando Pytorch.\n",
        "\n",
        "![Number-of-Models-on-HuggingFace](Imagenes/Number-of-Models-on-HuggingFace.png)\n",
        "\n",
        "Si analizamos los 30 modelos más populares podemos ver que todos están disponibles para Pytorch, mientras que solo unos dos tercios lo están para TensorFlow\n",
        "\n",
        "![Number-of-Top-30-Models-on-HuggingFace](Imagenes/Number-of-Top-30-Models-on-HuggingFace.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Investigación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Esta es una especialidad muy nueva, por lo que constantemente están surgiendo nuevos modelos. Implementarlos y entrenarlos desde cero supone una grán pérdida de tiempo, por lo que es mejor si podemos clonar un repositorio y usarlo. En la siguiente gráfica podemos ver el porcentaje de papers publicados con Pytorch y TensorFlow\n",
        "\n",
        "![Fraction-of-Papers-Using-PyTorch-vs.-TensorFlow](Imagenes/Fraction-of-Papers-Using-PyTorch-vs.-TensorFlow.png)\n",
        "\n",
        "Podemos ver como en pocos años Pytorch ha pasado de copar en torno al 7 % a que la mayoría de papers se publiquen con este framework\n",
        "\n",
        "En la siguiente imagen podemos ver el trasvase de investigadores de un framweork a otro\n",
        "\n",
        "![Sankey](Imagenes/Sankey.png)\n",
        "\n",
        "Podemos ver como la mitad de los investigadores han pasado de TensorFlow a Pytorch, mientras que al revés casi no sucede. Y esta imagen es el paso entre 2018 y 2019, ahora probablemente sea más favorable aun hacia Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[Papers with code](https://paperswithcode.com/) es una página también muy famosa donde podemos encontrar códigos de los últimos papers sobre deep learning con código, hecho por los propios investigadores y/o por otras personas. Podemos ver el porcentaje de repositorios hechos con Pytorch, TensorFlow u otro framework, y vemos como Pytorch ha evolucionado quedándose con un gran porcentaje, mientras que TensorFlow ha ido dismunuyendo\n",
        "\n",
        "![Percentage-of-Repositories-by-Framework](Imagenes/Percentage-of-Repositories-by-Framework.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Implementación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En aplicaciones a nivel industrial TensorFlow está más extendido, ya que este framework, desde sus inicios dio más herramientas para la implementación y despliegue. Pero Pytorch hace tiempo que se puso las pilas y creo las suyas, por lo que no se queda atrás con respecto a TensorFlow. A nivel personal me he encontrado pocas empresas que trabajen con TensorFlow, la mayoría lo hace con Pytorch\n",
        "\n",
        "Si entras en una empresa y trabajas con código ya hecho, es posible que te lo encuentre hecho con TensorFlow, pero para nuevas implementaciones es mejor Pytorch, ya que para nuevas implementaciones es mejor usar modelos más nuevos preentrenados, que como hemos visto, son más accesibles desde Pytorch. Al igual que antes, cada vez que quiero usar una red neuronal nueva, que tiene repositorio en GitHub, está implementada en Pytorch"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "d1c24abb23a313e1f9ae042292cd8e6e3c60c5818227ced3d46e3df2c65171ef"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
