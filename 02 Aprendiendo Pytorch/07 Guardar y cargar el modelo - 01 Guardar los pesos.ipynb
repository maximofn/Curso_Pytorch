{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Guardar y cargar el modelo - 01 Guardar los pesos"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Entrenamiento de la red"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos a hacer de manera rápida el entrenamiento de una red (creada desde cero) para el conjunto de datos `CIFAR-10`"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Descargamos y creamos el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Descargamos y creamos el dataset\n",
        "dataset_train = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "dataset_test = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataloader"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creamos un dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_dataloader = DataLoader(dataset_train, batch_size=BATCH_SIZE)\n",
        "test_dataloader = DataLoader(dataset_test, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Red"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creamos la red neuronal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "# Creamos la red neuronal desde cero\n",
        "class NeuralNetworkFromScratch(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetworkFromScratch, self).__init__()   # Se inicializa el módulo nn.Module\n",
        "        self.flatten = nn.Flatten()             # Se crea una primera capa que aplana la imagen de entrada\n",
        "        self.linear_relu_stack = nn.Sequential( # Se crea una módulo de arquitectura secuencial:\n",
        "            nn.Linear(3*32*32, 512),                # Se añade una primera capa lineal que está preparada \n",
        "                                                    # para que le entre un vector de 28*28 (784)\n",
        "                                                    # y sacará un vector de 512\n",
        "            nn.ReLU(),                              # Se añade una no linealidad\n",
        "            nn.Linear(512, 512),                    # Se añade una segunda capa lineal que le entran 512 \n",
        "                                                    # datos y saca 512 datos\n",
        "            nn.ReLU(),                              # Se añade una no linealidad\n",
        "            nn.Linear(512, 10)                      # Se añade una tercera capa lineal que le entran 512 \n",
        "                                                    # datos y saca un array de tamaño 10 (el número\n",
        "                                                    # de etiquetas)\n",
        "        )\n",
        "        #self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)                         # Se pasa la imagen por la capa de aplanado\n",
        "        logits = self.linear_relu_stack(x)          # Se pasa el vector resultante por la red\n",
        "        #probs = self.softmax(logits)\n",
        "        return logits\n",
        "\n",
        "model_scratch = NeuralNetworkFromScratch()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Función de pérdida"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optimizador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "LR = 1e-2\n",
        "\n",
        "optimizer = torch.optim.SGD(model_scratch.parameters(), lr=LR)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ciclo de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # X and y to device\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            # X and y to device\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            \n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "NeuralNetworkFromScratch(\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (linear_relu_stack): Sequential(\n",
              "    (0): Linear(in_features=3072, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))\n",
        "\n",
        "model_scratch.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.299271  [    0/50000]\n",
            "loss: 2.280225  [ 6400/50000]\n",
            "loss: 2.177648  [12800/50000]\n",
            "loss: 2.184654  [19200/50000]\n",
            "loss: 2.071022  [25600/50000]\n",
            "loss: 2.036963  [32000/50000]\n",
            "loss: 2.140847  [38400/50000]\n",
            "loss: 1.967930  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 29.8%, Avg loss: 1.957677 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.014007  [    0/50000]\n",
            "loss: 1.994665  [ 6400/50000]\n",
            "loss: 1.770970  [12800/50000]\n",
            "loss: 1.989187  [19200/50000]\n",
            "loss: 1.980051  [25600/50000]\n",
            "loss: 1.939532  [32000/50000]\n",
            "loss: 1.992241  [38400/50000]\n",
            "loss: 1.846072  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 33.9%, Avg loss: 1.857357 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.839857  [    0/50000]\n",
            "loss: 1.847155  [ 6400/50000]\n",
            "loss: 1.628356  [12800/50000]\n",
            "loss: 1.879081  [19200/50000]\n",
            "loss: 1.914935  [25600/50000]\n",
            "loss: 1.864616  [32000/50000]\n",
            "loss: 1.911577  [38400/50000]\n",
            "loss: 1.766933  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 36.2%, Avg loss: 1.788265 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.747958  [    0/50000]\n",
            "loss: 1.735296  [ 6400/50000]\n",
            "loss: 1.538137  [12800/50000]\n",
            "loss: 1.793341  [19200/50000]\n",
            "loss: 1.837967  [25600/50000]\n",
            "loss: 1.816956  [32000/50000]\n",
            "loss: 1.835309  [38400/50000]\n",
            "loss: 1.712601  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 37.9%, Avg loss: 1.741794 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.704689  [    0/50000]\n",
            "loss: 1.661915  [ 6400/50000]\n",
            "loss: 1.479871  [12800/50000]\n",
            "loss: 1.745563  [19200/50000]\n",
            "loss: 1.767140  [25600/50000]\n",
            "loss: 1.781919  [32000/50000]\n",
            "loss: 1.771199  [38400/50000]\n",
            "loss: 1.678551  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 38.6%, Avg loss: 1.716644 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.688324  [    0/50000]\n",
            "loss: 1.608738  [ 6400/50000]\n",
            "loss: 1.432038  [12800/50000]\n",
            "loss: 1.723426  [19200/50000]\n",
            "loss: 1.714391  [25600/50000]\n",
            "loss: 1.744789  [32000/50000]\n",
            "loss: 1.723130  [38400/50000]\n",
            "loss: 1.651956  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 38.5%, Avg loss: 1.714130 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.695532  [    0/50000]\n",
            "loss: 1.568822  [ 6400/50000]\n",
            "loss: 1.392478  [12800/50000]\n",
            "loss: 1.708172  [19200/50000]\n",
            "loss: 1.678460  [25600/50000]\n",
            "loss: 1.706309  [32000/50000]\n",
            "loss: 1.685870  [38400/50000]\n",
            "loss: 1.635061  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 37.1%, Avg loss: 1.729095 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 1.709623  [    0/50000]\n",
            "loss: 1.533369  [ 6400/50000]\n",
            "loss: 1.358640  [12800/50000]\n",
            "loss: 1.701959  [19200/50000]\n",
            "loss: 1.649788  [25600/50000]\n",
            "loss: 1.668327  [32000/50000]\n",
            "loss: 1.652874  [38400/50000]\n",
            "loss: 1.619160  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 37.0%, Avg loss: 1.736961 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 1.720896  [    0/50000]\n",
            "loss: 1.503845  [ 6400/50000]\n",
            "loss: 1.326119  [12800/50000]\n",
            "loss: 1.691490  [19200/50000]\n",
            "loss: 1.619294  [25600/50000]\n",
            "loss: 1.636960  [32000/50000]\n",
            "loss: 1.633466  [38400/50000]\n",
            "loss: 1.611323  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 37.4%, Avg loss: 1.730996 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 1.711156  [    0/50000]\n",
            "loss: 1.477624  [ 6400/50000]\n",
            "loss: 1.302359  [12800/50000]\n",
            "loss: 1.690812  [19200/50000]\n",
            "loss: 1.593102  [25600/50000]\n",
            "loss: 1.611022  [32000/50000]\n",
            "loss: 1.616387  [38400/50000]\n",
            "loss: 1.595635  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 37.6%, Avg loss: 1.731239 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model_scratch, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model_scratch, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Guardar los pesos del modelo"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Los modelos de PyTorch almacenan los parámetros aprendidos en un diccionario de estado interno, llamado ``state_dict``. Estos se pueden conservar a través del método ``torch.save``:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "path = \"data/pesos.pth\"\n",
        "torch.save(model_scratch.state_dict(), path)"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "d1c24abb23a313e1f9ae042292cd8e6e3c60c5818227ced3d46e3df2c65171ef"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
