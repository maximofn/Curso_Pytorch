{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Guardar y cargar el modelo - 03 Guardar el modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Entrenamiento de la red"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos a hacer de manera rápida el entrenamiento de una red (creada desde cero) para el conjunto de datos `CIFAR-10`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Descargamos y creamos el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Descargamos y creamos el dataset\n",
        "dataset_train = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "dataset_test = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creamos un dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_dataloader = DataLoader(dataset_train, batch_size=BATCH_SIZE)\n",
        "test_dataloader = DataLoader(dataset_test, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Red"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creamos la red neuronal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "# Creamos la red neuronal desde cero\n",
        "class NeuralNetworkFromScratch(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetworkFromScratch, self).__init__()   # Se inicializa el módulo nn.Module\n",
        "        self.flatten = nn.Flatten()             # Se crea una primera capa que aplana la imagen de entrada\n",
        "        self.linear_relu_stack = nn.Sequential( # Se crea una módulo de arquitectura secuencial:\n",
        "            nn.Linear(3*32*32, 512),                # Se añade una primera capa lineal que está preparada \n",
        "                                                    # para que le entre un vector de 28*28 (784)\n",
        "                                                    # y sacará un vector de 512\n",
        "            nn.ReLU(),                              # Se añade una no linealidad\n",
        "            nn.Linear(512, 512),                    # Se añade una segunda capa lineal que le entran 512 \n",
        "                                                    # datos y saca 512 datos\n",
        "            nn.ReLU(),                              # Se añade una no linealidad\n",
        "            nn.Linear(512, 10)                      # Se añade una tercera capa lineal que le entran 512 \n",
        "                                                    # datos y saca un array de tamaño 10 (el número\n",
        "                                                    # de etiquetas)\n",
        "        )\n",
        "        #self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)                         # Se pasa la imagen por la capa de aplanado\n",
        "        logits = self.linear_relu_stack(x)          # Se pasa el vector resultante por la red\n",
        "        #probs = self.softmax(logits)\n",
        "        return logits\n",
        "\n",
        "model_scratch = NeuralNetworkFromScratch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Función de pérdida"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optimizador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "LR = 1e-2\n",
        "\n",
        "optimizer = torch.optim.SGD(model_scratch.parameters(), lr=LR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ciclo de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # X and y to device\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            # X and y to device\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            \n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "NeuralNetworkFromScratch(\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (linear_relu_stack): Sequential(\n",
              "    (0): Linear(in_features=3072, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))\n",
        "\n",
        "model_scratch.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.305923  [    0/50000]\n",
            "loss: 2.279934  [ 6400/50000]\n",
            "loss: 2.176818  [12800/50000]\n",
            "loss: 2.198303  [19200/50000]\n",
            "loss: 2.064588  [25600/50000]\n",
            "loss: 2.049512  [32000/50000]\n",
            "loss: 2.140765  [38400/50000]\n",
            "loss: 1.978731  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 29.8%, Avg loss: 1.962312 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.020223  [    0/50000]\n",
            "loss: 1.996938  [ 6400/50000]\n",
            "loss: 1.771149  [12800/50000]\n",
            "loss: 1.998021  [19200/50000]\n",
            "loss: 1.960991  [25600/50000]\n",
            "loss: 1.951058  [32000/50000]\n",
            "loss: 1.997114  [38400/50000]\n",
            "loss: 1.846776  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 34.1%, Avg loss: 1.856662 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.833241  [    0/50000]\n",
            "loss: 1.846549  [ 6400/50000]\n",
            "loss: 1.619731  [12800/50000]\n",
            "loss: 1.874988  [19200/50000]\n",
            "loss: 1.893247  [25600/50000]\n",
            "loss: 1.868355  [32000/50000]\n",
            "loss: 1.913862  [38400/50000]\n",
            "loss: 1.758889  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 36.6%, Avg loss: 1.783662 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.737496  [    0/50000]\n",
            "loss: 1.731622  [ 6400/50000]\n",
            "loss: 1.527850  [12800/50000]\n",
            "loss: 1.787065  [19200/50000]\n",
            "loss: 1.808828  [25600/50000]\n",
            "loss: 1.813776  [32000/50000]\n",
            "loss: 1.834336  [38400/50000]\n",
            "loss: 1.695289  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 37.7%, Avg loss: 1.741700 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.702779  [    0/50000]\n",
            "loss: 1.655743  [ 6400/50000]\n",
            "loss: 1.468475  [12800/50000]\n",
            "loss: 1.745061  [19200/50000]\n",
            "loss: 1.732691  [25600/50000]\n",
            "loss: 1.780351  [32000/50000]\n",
            "loss: 1.768757  [38400/50000]\n",
            "loss: 1.648932  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 37.5%, Avg loss: 1.734723 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.707888  [    0/50000]\n",
            "loss: 1.598898  [ 6400/50000]\n",
            "loss: 1.419580  [12800/50000]\n",
            "loss: 1.730801  [19200/50000]\n",
            "loss: 1.681372  [25600/50000]\n",
            "loss: 1.741595  [32000/50000]\n",
            "loss: 1.719327  [38400/50000]\n",
            "loss: 1.616333  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 36.2%, Avg loss: 1.760197 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.741681  [    0/50000]\n",
            "loss: 1.555838  [ 6400/50000]\n",
            "loss: 1.377528  [12800/50000]\n",
            "loss: 1.731336  [19200/50000]\n",
            "loss: 1.652944  [25600/50000]\n",
            "loss: 1.701522  [32000/50000]\n",
            "loss: 1.681156  [38400/50000]\n",
            "loss: 1.590816  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 35.9%, Avg loss: 1.760239 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 1.752081  [    0/50000]\n",
            "loss: 1.515484  [ 6400/50000]\n",
            "loss: 1.338967  [12800/50000]\n",
            "loss: 1.733063  [19200/50000]\n",
            "loss: 1.625309  [25600/50000]\n",
            "loss: 1.665290  [32000/50000]\n",
            "loss: 1.651867  [38400/50000]\n",
            "loss: 1.573547  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 35.5%, Avg loss: 1.781579 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 1.782564  [    0/50000]\n",
            "loss: 1.485063  [ 6400/50000]\n",
            "loss: 1.304868  [12800/50000]\n",
            "loss: 1.734769  [19200/50000]\n",
            "loss: 1.601535  [25600/50000]\n",
            "loss: 1.639245  [32000/50000]\n",
            "loss: 1.625263  [38400/50000]\n",
            "loss: 1.559711  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 36.0%, Avg loss: 1.775680 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 1.777505  [    0/50000]\n",
            "loss: 1.452320  [ 6400/50000]\n",
            "loss: 1.274918  [12800/50000]\n",
            "loss: 1.723788  [19200/50000]\n",
            "loss: 1.571116  [25600/50000]\n",
            "loss: 1.621120  [32000/50000]\n",
            "loss: 1.609584  [38400/50000]\n",
            "loss: 1.552480  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 36.7%, Avg loss: 1.760111 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model_scratch, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model_scratch, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Guardar el modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Al cargar pesos de modelo, necesitábamos crear una instancia de la clase de modelo primero, porque la clase define la estructura de una red. Es posible que deseemos guardar la estructura de esta clase junto con el modelo, en cuyo caso podemos pasar ``model`` (y no ''model.state_dict()'') a la función de guardar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "path = \"data/modelo.pth\"\n",
        "torch.save(model_scratch, path)"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "d1c24abb23a313e1f9ae042292cd8e6e3c60c5818227ced3d46e3df2c65171ef"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
