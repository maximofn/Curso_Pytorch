{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Guardar y cargar el modelo - 05 Guardar zip"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Entrenamiento de la red"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos a hacer de manera rápida el entrenamiento de una red (creada desde cero) para el conjunto de datos `CIFAR-10`"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Descargamos y creamos el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Descargamos y creamos el dataset\n",
        "dataset_train = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "dataset_test = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataloader"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creamos un dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_dataloader = DataLoader(dataset_train, batch_size=BATCH_SIZE)\n",
        "test_dataloader = DataLoader(dataset_test, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Red"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creamos la red neuronal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "# Creamos la red neuronal desde cero\n",
        "class NeuralNetworkFromScratch(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetworkFromScratch, self).__init__()   # Se inicializa el módulo nn.Module\n",
        "        self.flatten = nn.Flatten()             # Se crea una primera capa que aplana la imagen de entrada\n",
        "        self.linear_relu_stack = nn.Sequential( # Se crea una módulo de arquitectura secuencial:\n",
        "            nn.Linear(3*32*32, 512),                # Se añade una primera capa lineal que está preparada \n",
        "                                                    # para que le entre un vector de 28*28 (784)\n",
        "                                                    # y sacará un vector de 512\n",
        "            nn.ReLU(),                              # Se añade una no linealidad\n",
        "            nn.Linear(512, 512),                    # Se añade una segunda capa lineal que le entran 512 \n",
        "                                                    # datos y saca 512 datos\n",
        "            nn.ReLU(),                              # Se añade una no linealidad\n",
        "            nn.Linear(512, 10)                      # Se añade una tercera capa lineal que le entran 512 \n",
        "                                                    # datos y saca un array de tamaño 10 (el número\n",
        "                                                    # de etiquetas)\n",
        "        )\n",
        "        #self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)                         # Se pasa la imagen por la capa de aplanado\n",
        "        logits = self.linear_relu_stack(x)          # Se pasa el vector resultante por la red\n",
        "        #probs = self.softmax(logits)\n",
        "        return logits\n",
        "\n",
        "model_scratch = NeuralNetworkFromScratch()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Función de pérdida"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optimizador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "LR = 1e-2\n",
        "\n",
        "optimizer = torch.optim.SGD(model_scratch.parameters(), lr=LR)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ciclo de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # X and y to device\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            # X and y to device\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            \n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "NeuralNetworkFromScratch(\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (linear_relu_stack): Sequential(\n",
              "    (0): Linear(in_features=3072, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))\n",
        "\n",
        "model_scratch.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.294234  [    0/50000]\n",
            "loss: 2.276395  [ 6400/50000]\n",
            "loss: 2.177299  [12800/50000]\n",
            "loss: 2.198840  [19200/50000]\n",
            "loss: 2.084385  [25600/50000]\n",
            "loss: 2.032702  [32000/50000]\n",
            "loss: 2.141281  [38400/50000]\n",
            "loss: 1.970459  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 29.8%, Avg loss: 1.958674 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.003172  [    0/50000]\n",
            "loss: 1.987852  [ 6400/50000]\n",
            "loss: 1.759240  [12800/50000]\n",
            "loss: 2.010041  [19200/50000]\n",
            "loss: 1.979481  [25600/50000]\n",
            "loss: 1.923347  [32000/50000]\n",
            "loss: 1.981188  [38400/50000]\n",
            "loss: 1.848161  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 34.2%, Avg loss: 1.855866 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.829209  [    0/50000]\n",
            "loss: 1.834715  [ 6400/50000]\n",
            "loss: 1.616591  [12800/50000]\n",
            "loss: 1.883856  [19200/50000]\n",
            "loss: 1.911470  [25600/50000]\n",
            "loss: 1.843929  [32000/50000]\n",
            "loss: 1.896134  [38400/50000]\n",
            "loss: 1.776198  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 36.4%, Avg loss: 1.788676 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.745211  [    0/50000]\n",
            "loss: 1.732765  [ 6400/50000]\n",
            "loss: 1.532976  [12800/50000]\n",
            "loss: 1.801638  [19200/50000]\n",
            "loss: 1.834358  [25600/50000]\n",
            "loss: 1.800336  [32000/50000]\n",
            "loss: 1.822999  [38400/50000]\n",
            "loss: 1.724398  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 37.8%, Avg loss: 1.742135 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.705886  [    0/50000]\n",
            "loss: 1.667481  [ 6400/50000]\n",
            "loss: 1.475258  [12800/50000]\n",
            "loss: 1.760688  [19200/50000]\n",
            "loss: 1.758161  [25600/50000]\n",
            "loss: 1.766274  [32000/50000]\n",
            "loss: 1.757722  [38400/50000]\n",
            "loss: 1.681392  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 38.2%, Avg loss: 1.721953 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.695797  [    0/50000]\n",
            "loss: 1.617172  [ 6400/50000]\n",
            "loss: 1.426801  [12800/50000]\n",
            "loss: 1.740232  [19200/50000]\n",
            "loss: 1.705691  [25600/50000]\n",
            "loss: 1.735454  [32000/50000]\n",
            "loss: 1.704702  [38400/50000]\n",
            "loss: 1.649906  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 37.2%, Avg loss: 1.735572 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.716034  [    0/50000]\n",
            "loss: 1.576472  [ 6400/50000]\n",
            "loss: 1.382427  [12800/50000]\n",
            "loss: 1.726451  [19200/50000]\n",
            "loss: 1.667853  [25600/50000]\n",
            "loss: 1.699731  [32000/50000]\n",
            "loss: 1.659016  [38400/50000]\n",
            "loss: 1.620742  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 36.6%, Avg loss: 1.749487 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 1.733630  [    0/50000]\n",
            "loss: 1.542320  [ 6400/50000]\n",
            "loss: 1.346497  [12800/50000]\n",
            "loss: 1.714242  [19200/50000]\n",
            "loss: 1.634646  [25600/50000]\n",
            "loss: 1.667264  [32000/50000]\n",
            "loss: 1.628795  [38400/50000]\n",
            "loss: 1.597428  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 35.5%, Avg loss: 1.781796 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 1.756124  [    0/50000]\n",
            "loss: 1.506677  [ 6400/50000]\n",
            "loss: 1.315899  [12800/50000]\n",
            "loss: 1.705123  [19200/50000]\n",
            "loss: 1.601237  [25600/50000]\n",
            "loss: 1.641786  [32000/50000]\n",
            "loss: 1.608054  [38400/50000]\n",
            "loss: 1.576392  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 35.7%, Avg loss: 1.790193 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 1.767100  [    0/50000]\n",
            "loss: 1.480167  [ 6400/50000]\n",
            "loss: 1.289160  [12800/50000]\n",
            "loss: 1.689454  [19200/50000]\n",
            "loss: 1.577046  [25600/50000]\n",
            "loss: 1.612340  [32000/50000]\n",
            "loss: 1.590460  [38400/50000]\n",
            "loss: 1.560599  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 37.7%, Avg loss: 1.739344 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model_scratch, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model_scratch, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Guardar el modelo"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora guardamos el modelo mediante TorchScript, que es una manera que da Pytorch de guardar los modelos más orientada a producción"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "path = \"data/modelo.zip\"\n",
        "torch.jit.save(torch.jit.script(model_scratch.cpu()), path)"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "2da05e9852e3725e6cd29dd2f3d6ebaa07dda6697715ddc2b5ea77aa5959f695"
    },
    "kernelspec": {
      "display_name": "Python 3.8.11 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
