{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación binaria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro tipo de problema que se suele resolver con redes neuronales es el de clasificación binaria. Ahora no tenemos un valor que predecir, sino que en función de las entradas tenemos que clasificar los datos en dos clases distintas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos la base de datos de tipos de cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "cancer = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver qué trae esta base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "print(cancer['target_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La llave `DESCR` es una descripción de la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "print(cancer['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además tiene las llaves `data` y `target` donde se encuentran los datos anteriormente descritos. La llave `feature_names` contiene los numbres de cada una de las características\n",
    "\n",
    "Así que creamos un dataframe con los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  type  \n",
       "0          0.4601                  0.11890     0  \n",
       "1          0.2750                  0.08902     0  \n",
       "2          0.3613                  0.08758     0  \n",
       "3          0.6638                  0.17300     0  \n",
       "4          0.2364                  0.07678     0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cancer_df = pd.DataFrame(cancer['data'], columns=cancer['feature_names'])\n",
    "cancer_df['type'] = cancer['target']\n",
    "cancer_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos las posibles clases que hay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "print(cancer.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos cuantos elementos hay de cada clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "1    357\n",
       "0    212\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df['type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último vemos si hay algún dato faltante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean radius                0\n",
       "mean texture               0\n",
       "mean perimeter             0\n",
       "mean area                  0\n",
       "mean smoothness            0\n",
       "mean compactness           0\n",
       "mean concavity             0\n",
       "mean concave points        0\n",
       "mean symmetry              0\n",
       "mean fractal dimension     0\n",
       "radius error               0\n",
       "texture error              0\n",
       "perimeter error            0\n",
       "area error                 0\n",
       "smoothness error           0\n",
       "compactness error          0\n",
       "concavity error            0\n",
       "concave points error       0\n",
       "symmetry error             0\n",
       "fractal dimension error    0\n",
       "worst radius               0\n",
       "worst texture              0\n",
       "worst perimeter            0\n",
       "worst area                 0\n",
       "worst smoothness           0\n",
       "worst compactness          0\n",
       "worst concavity            0\n",
       "worst concave points       0\n",
       "worst symmetry             0\n",
       "worst fractal dimension    0\n",
       "type                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset y Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class CancerDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        cols = [col for col in dataframe.columns if col != 'target']\n",
    "        self.parameters = torch.from_numpy(dataframe[cols].values).type(torch.float32)\n",
    "        self.targets = torch.from_numpy(dataframe['type'].values).type(torch.float32)\n",
    "        self.targets = self.targets.reshape((len(self.targets), 1))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.parameters)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        parameters = self.parameters[idx]\n",
    "        target = self.targets[idx]\n",
    "        return parameters, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 569)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = CancerDataset(cancer_df)\n",
    "len(ds), len(cancer_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder entrenar hemos visto que necesitamos dividir los datos en un conjunto de datos de entrenamiento y en un conjunto de datos de validación. Así que dividimos nuestros datos en estos dos conjuntos.\n",
    "\n",
    "Como no tenemos muchos datos vamos a dividir el conjunto de datos en un 80% para entrenamiento entrenamiento y un 20% para validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 114, 569)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds, valid_ds = torch.utils.data.random_split(ds, [int(0.8*len(ds)), len(ds) - int(0.8*len(ds))], generator=torch.Generator().manual_seed(42))\n",
    "len(train_ds), len(valid_ds), len(train_ds) + len(valid_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver una muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(sample): 2\n",
      "parameters: tensor([1.1420e+01, 2.0380e+01, 7.7580e+01, 3.8610e+02, 1.4250e-01, 2.8390e-01,\n",
      "        2.4140e-01, 1.0520e-01, 2.5970e-01, 9.7440e-02, 4.9560e-01, 1.1560e+00,\n",
      "        3.4450e+00, 2.7230e+01, 9.1100e-03, 7.4580e-02, 5.6610e-02, 1.8670e-02,\n",
      "        5.9630e-02, 9.2080e-03, 1.4910e+01, 2.6500e+01, 9.8870e+01, 5.6770e+02,\n",
      "        2.0980e-01, 8.6630e-01, 6.8690e-01, 2.5750e-01, 6.6380e-01, 1.7300e-01,\n",
      "        0.0000e+00])\n",
      "type parameters: <class 'torch.Tensor'>\n",
      "parameters.dtype: torch.float32\n",
      "parameters.shape: torch.Size([31])\n",
      "\n",
      "\n",
      "target: tensor([0.]), type target: <class 'torch.Tensor'>, target.dtype: torch.float32, target.shape: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "sample = train_ds[0]\n",
    "print(f\"len(sample): {len(sample)}\")\n",
    "\n",
    "parameters, target = sample\n",
    "print(f\"parameters: {parameters}\\ntype parameters: {type(parameters)}\\nparameters.dtype: {parameters.dtype}\\nparameters.shape: {parameters.shape}\\n\\n\")\n",
    "print(f\"target: {target}, type target: {type(target)}, target.dtype: {target.dtype}, target.shape: {target.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos ahora el dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BS_train = 64\n",
    "BS_val = 128 # Solo hay 114 datos de validación, por lo que no se puede dividir en batches\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=BS_train, shuffle=True)\n",
    "val_dl = DataLoader(valid_ds, batch_size=BS_val, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos un batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor,\n",
       " torch.float32,\n",
       " torch.Size([64, 31]),\n",
       " torch.Tensor,\n",
       " torch.Size([64, 1]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_dl))\n",
    "parameters, target = batch[0], batch[1]\n",
    "type(parameters), parameters.dtype, parameters.shape, type(target), target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red Neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una red neuronal para entrenarla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora en la última capa de la red neuronal ponemos una capa con una función de activación, en concreto la función `sigmoid`. ¿Esto por qué? Como ya hemos visto antes, la salida de la función `sigmoid` tiene valores entre 0 y 1\n",
    "\n",
    "![sigmoid](Imagenes/sigmoid.png)\n",
    "\n",
    "Como estamos en un problema de clasificación binaria, a la salida queremos que la red nos de valores entre 0 y 1, por lo que esta función es perfecta para esto. Otra opción es usar una función escalón, con la cual si a la entrada se tiene un valor menos que x a la salida se tendrá un 0, y si es mayor se tendrá un 1. Pero como necesitamos poder derivar todo para poder calcular los gradientes, para el entrenamiento, es mejor usar la función `sigmoid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class CancerNeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs, hidden_layers=[100, 50, 20]):\n",
    "        super().__init__()\n",
    "        self.network = torch.nn.Sequential(\n",
    "            torch.nn.Linear(num_inputs, hidden_layers[0]),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_layers[0], hidden_layers[1]),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_layers[1], hidden_layers[2]),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_layers[2], num_outputs),\n",
    "        )\n",
    "        self.activation = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.network(x)\n",
    "        probs = self.activation(logits)\n",
    "        return logits, probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función `sigmoid` da un 0 a la salida si su entrada tiene un valor muy pequeño (o muy negativo, como se entienda mejor) y da un 1 a la salida cuando a la entrada se tiene un valor muy grande. Mientras que si a la entrada se tienen valores cercanos a 0, a la salida no se tendrá un 0 o 1 claro. Por lo que durante el entrenamiento la red intentará ajustar los pesos de las capas anteriores, para que a la última capa, la `sigmoid`, le entren o valores muy pequeños (o muy negativos) o valores muy grandes. Es decir, intentará que los valores de logits sean muy pequeños (o muy negativos) o sean muy grandes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que antes hemos definido una red genérica a la que hay que meterle los tamaños de entrada, de salida, y opcionalmente los tamaños de la capa oculta. Vamos a ver qué tamaño necesitamos a la entrada y a la salida de la red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un batch tiene unos parámetros con este tamaño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 31])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos una matriz de tamaño 64x31. 64 es el tamaño del batch size, mientras que 31 es el número de parámetros, por lo que **a la entrada necesitamos 31 neuronas**\n",
    "\n",
    "Otra forma de verlo es que como se tiene que hacer una multiplicación matricial de las entradas con la primera capa de la red, si la matriz de entradas tiene un tamaño de 64x31, la matriz que representa las neuronas de la primera capa tiene que tener un tamaño de 31xM. Ya que en una multiplicación matricial, el tamaño de las matrices que se multiplican tienen que ser AxB y BxC, es decir, la dimensión de en medio de las dos matrices tiene que ser la misma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otro lado, el mismo batch a la salida tiene un target con este tamaño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "64 es el tamaño del batch size, pero hay 1 clase, por lo que **a la salida queremos que haya 1 neurona**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CancerNeuralNetwork(\n",
       "  (network): Sequential(\n",
       "    (0): Linear(in_features=31, out_features=100, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=50, out_features=20, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=20, out_features=1, bias=True)\n",
       "  )\n",
       "  (activation): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_inputs = parameters.shape[1]\n",
    "num_outputs = target.shape[1]\n",
    "model = CancerNeuralNetwork(num_inputs, num_outputs)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero cogemos un batch del dataloader y se lo metemos a la red a ver si funciona y la hemos definido bien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1]), torch.Size([64, 1]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits, probs = model(parameters)\n",
    "logits.shape, probs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si se puede se manda la red a la GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CancerNeuralNetwork(\n",
       "  (network): Sequential(\n",
       "    (0): Linear(in_features=31, out_features=100, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=50, out_features=20, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=20, out_features=1, bias=True)\n",
       "  )\n",
       "  (activation): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora volvemos a probar a meterle un batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1]), torch.Size([64, 1]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_gpu = parameters.to(device)\n",
    "logits, probs = model(parameters_gpu)\n",
    "logits.shape, probs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de pérdida y optimizador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una función de pérdida y un optimizador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este tipo de problemas no debemos usar como función de pérdida el `MSE`, ya que a la salida vamos a tener 1s y 0s. El MSE mide la distancia entre lo predicho por la red y la realidad, pero en este problema la distancia siempre va a ser de 1 en caso de que la predicción sea mala o 0 en caso de que la predicción sea buena.\n",
    "\n",
    "Como hemos visto en el tema de Funciones de activación, debemos usar `BCE`. Ya que se usa para problemas de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-3\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ciclo de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_prints = 4\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # X and y to device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction and loss\n",
    "        _, probs = model(X)\n",
    "        loss = loss_fn(probs, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % int(len(dataloader)/num_prints) == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def val_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            # X and y to device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            _, probs = model(X)\n",
    "            test_loss += loss_fn(probs, y).item()\n",
    "            correct += (probs.round() == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.104998  [    0/  455]\n",
      "loss: 4.165802  [  128/  455]\n",
      "loss: 0.672075  [  256/  455]\n",
      "loss: 0.624762  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 40.4%, Avg loss: 0.780051 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.830134  [    0/  455]\n",
      "loss: 0.526276  [  128/  455]\n",
      "loss: 0.947459  [  256/  455]\n",
      "loss: 0.829670  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 40.4%, Avg loss: 0.801540 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.923409  [    0/  455]\n",
      "loss: 0.807727  [  128/  455]\n",
      "loss: 0.741083  [  256/  455]\n",
      "loss: 0.568708  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.553853 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.563830  [    0/  455]\n",
      "loss: 0.595183  [  128/  455]\n",
      "loss: 0.524305  [  256/  455]\n",
      "loss: 0.523095  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 60.5%, Avg loss: 0.782228 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.793078  [    0/  455]\n",
      "loss: 0.575853  [  128/  455]\n",
      "loss: 0.521104  [  256/  455]\n",
      "loss: 0.541925  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 0.557699 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.615224  [    0/  455]\n",
      "loss: 0.654992  [  128/  455]\n",
      "loss: 0.548069  [  256/  455]\n",
      "loss: 0.533602  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 67.5%, Avg loss: 0.621984 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.653063  [    0/  455]\n",
      "loss: 0.487342  [  128/  455]\n",
      "loss: 0.479420  [  256/  455]\n",
      "loss: 0.549125  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 60.5%, Avg loss: 0.957986 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.935008  [    0/  455]\n",
      "loss: 0.448304  [  128/  455]\n",
      "loss: 0.494540  [  256/  455]\n",
      "loss: 0.402640  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.423024 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.424309  [    0/  455]\n",
      "loss: 0.462447  [  128/  455]\n",
      "loss: 0.414960  [  256/  455]\n",
      "loss: 0.504472  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 40.4%, Avg loss: 1.042761 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.111332  [    0/  455]\n",
      "loss: 0.547426  [  128/  455]\n",
      "loss: 0.484831  [  256/  455]\n",
      "loss: 0.450403  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 60.5%, Avg loss: 0.855616 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.793103  [    0/  455]\n",
      "loss: 0.552897  [  128/  455]\n",
      "loss: 0.501814  [  256/  455]\n",
      "loss: 0.505203  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.457299 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.542931  [    0/  455]\n",
      "loss: 0.462914  [  128/  455]\n",
      "loss: 0.448223  [  256/  455]\n",
      "loss: 0.470521  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 0.488577 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.537595  [    0/  455]\n",
      "loss: 0.782848  [  128/  455]\n",
      "loss: 0.432530  [  256/  455]\n",
      "loss: 0.377336  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 40.4%, Avg loss: 1.000635 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 13\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dl, model, loss_fn, optimizer)\n",
    "    val_loop(val_dl, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Función de pérdida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hemos visto en el tema de funciones de pérdida, es mejor usar la función `BCEWithLogitsLoss` que `BCELoss`, ya que es más estable numéricamente. Así que ahora, en vez de quedarnos con las probabilidades de la red calculadas mediante la función `Sigmoid`, lo que vamos a hacer es quedarnos con los logits y `BCEWithLogitsLoss` hará el cálculo del la `Sigmoid` y `BCELoss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CancerNeuralNetwork(\n",
       "  (network): Sequential(\n",
       "    (0): Linear(in_features=31, out_features=100, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=50, out_features=20, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=20, out_features=1, bias=True)\n",
       "  )\n",
       "  (activation): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CancerNeuralNetwork(num_inputs, num_outputs)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-3\n",
    "\n",
    "loss_fn2 = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tenemos que redefinir las funciones de entrenamiento y validación, para quedarnos con los logits de la red y no las probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_prints = 4\n",
    "\n",
    "def train_loop2(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # X and y to device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction and loss\n",
    "        logits, _ = model(X)\n",
    "        loss = loss_fn2(logits, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % int(len(dataloader)/num_prints) == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def val_loop2(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            # X and y to device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            logits, probs = model(X)\n",
    "            test_loss += loss_fn2(logits, y).item()\n",
    "            correct += (probs.round() == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver en el bucle de entrenamiento ya no nos quedamos con las probabilidades, sino con los logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.670341  [    0/  455]\n",
      "loss: 0.966830  [  128/  455]\n",
      "loss: 0.698714  [  256/  455]\n",
      "loss: 0.578295  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 40.4%, Avg loss: 0.932089 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.180747  [    0/  455]\n",
      "loss: 0.557286  [  128/  455]\n",
      "loss: 0.547688  [  256/  455]\n",
      "loss: 0.454823  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.554421 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.556460  [    0/  455]\n",
      "loss: 0.479203  [  128/  455]\n",
      "loss: 0.466049  [  256/  455]\n",
      "loss: 0.568023  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 0.539169 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.607195  [    0/  455]\n",
      "loss: 0.474415  [  128/  455]\n",
      "loss: 0.507968  [  256/  455]\n",
      "loss: 0.517431  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 65.8%, Avg loss: 0.640143 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.558246  [    0/  455]\n",
      "loss: 0.414196  [  128/  455]\n",
      "loss: 0.533811  [  256/  455]\n",
      "loss: 0.468989  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 72.8%, Avg loss: 0.576586 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.493952  [    0/  455]\n",
      "loss: 0.446407  [  128/  455]\n",
      "loss: 0.508493  [  256/  455]\n",
      "loss: 0.397049  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.499189 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.481897  [    0/  455]\n",
      "loss: 0.457315  [  128/  455]\n",
      "loss: 0.478060  [  256/  455]\n",
      "loss: 0.510412  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.448309 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.494440  [    0/  455]\n",
      "loss: 0.517064  [  128/  455]\n",
      "loss: 0.571935  [  256/  455]\n",
      "loss: 0.437985  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.409416 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.375108  [    0/  455]\n",
      "loss: 0.535860  [  128/  455]\n",
      "loss: 0.373891  [  256/  455]\n",
      "loss: 0.435602  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.422840 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.439938  [    0/  455]\n",
      "loss: 0.513520  [  128/  455]\n",
      "loss: 0.405309  [  256/  455]\n",
      "loss: 0.422430  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.419686 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.378999  [    0/  455]\n",
      "loss: 0.431279  [  128/  455]\n",
      "loss: 0.395237  [  256/  455]\n",
      "loss: 0.335724  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.481683 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.510404  [    0/  455]\n",
      "loss: 0.662106  [  128/  455]\n",
      "loss: 0.378686  [  256/  455]\n",
      "loss: 0.424093  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.398866 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.388227  [    0/  455]\n",
      "loss: 0.459619  [  128/  455]\n",
      "loss: 0.415409  [  256/  455]\n",
      "loss: 0.426007  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 45.6%, Avg loss: 0.774498 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.868085  [    0/  455]\n",
      "loss: 0.401139  [  128/  455]\n",
      "loss: 0.383164  [  256/  455]\n",
      "loss: 0.425075  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.403533 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 14\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop2(train_dl, model, loss_fn2, optimizer)\n",
    "    val_loop2(val_dl, model, loss_fn2)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a meterle un dato del dataset de validación a ver qué tal lo hace la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_parameters, valid_target = next(iter(val_dl))\n",
    "\n",
    "predictions = model(valid_parameters.to(device))\n",
    "predictions_logits, predictions_probs = predictions[0], predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([114, 1]), torch.Size([114, 1]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_target.shape, predictions_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "para todo el batch de validación\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 0, y se ha predicho: 0 - OK\n",
      "\t se esperaba target: 0, y se ha predicho: 0 - OK\n",
      "\t se esperaba target: 0, y se ha predicho: 1 - ERROR\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 0, y se ha predicho: 1 - ERROR\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 0, y se ha predicho: 1 - ERROR\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 0, y se ha predicho: 1 - ERROR\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 0, y se ha predicho: 1 - ERROR\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 0, y se ha predicho: 0 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 0, y se ha predicho: 0 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 0, y se ha predicho: 1 - ERROR\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 0, y se ha predicho: 1 - ERROR\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 0, y se ha predicho: 1 - ERROR\n",
      "\t se esperaba target: 0, y se ha predicho: 0 - OK\n",
      "\t se esperaba target: 0, y se ha predicho: 0 - OK\n",
      "\t se esperaba target: 0, y se ha predicho: 1 - ERROR\n",
      "\t se esperaba target: 0, y se ha predicho: 1 - ERROR\n",
      "\t se esperaba target: 0, y se ha predicho: 0 - OK\n",
      "\t se esperaba target: 0, y se ha predicho: 0 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 0, y se ha predicho: 1 - ERROR\n",
      "\t se esperaba target: 0, y se ha predicho: 1 - ERROR\n",
      "\t se esperaba target: 0, y se ha predicho: 0 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 0, y se ha predicho: 1 - ERROR\n",
      "\t se esperaba target: 0, y se ha predicho: 0 - OK\n",
      "\t se esperaba target: 0, y se ha predicho: 1 - ERROR\n",
      "\t se esperaba target: 0, y se ha predicho: 0 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 0 - ERROR\n",
      "\t se esperaba target: 0, y se ha predicho: 0 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 0, y se ha predicho: 0 - OK\n",
      "\t se esperaba target: 0, y se ha predicho: 0 - OK\n",
      "\t se esperaba target: 0, y se ha predicho: 0 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 0, y se ha predicho: 0 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 0, y se ha predicho: 0 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 0, y se ha predicho: 1 - ERROR\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 0, y se ha predicho: 1 - ERROR\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 0, y se ha predicho: 0 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 0, y se ha predicho: 1 - ERROR\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 0, y se ha predicho: 0 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 0, y se ha predicho: 0 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 0, y se ha predicho: 0 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 0, y se ha predicho: 1 - ERROR\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 0, y se ha predicho: 0 - OK\n",
      "\t se esperaba target: 0, y se ha predicho: 0 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 0, y se ha predicho: 1 - ERROR\n",
      "\t se esperaba target: 0, y se ha predicho: 1 - ERROR\n",
      "\t se esperaba target: 1, y se ha predicho: 1 - OK\n",
      "\t se esperaba target: 0, y se ha predicho: 1 - ERROR\n",
      "\t se esperaba target: 0, y se ha predicho: 1 - ERROR\n",
      "\t se esperaba target: 0, y se ha predicho: 0 - OK\n"
     ]
    }
   ],
   "source": [
    "print(f\"para todo el batch de validación\")\n",
    "for i in range(len(valid_target)):\n",
    "    if int(valid_target[i].item()) == int(predictions_probs[i].round().item()):\n",
    "        string = \"OK\"\n",
    "    else:\n",
    "        string = \"ERROR\"\n",
    "    print(f\"\\t se esperaba target: {int(valid_target[i].item())}, y se ha predicho: {int(predictions_probs[i].round().item())} - {string}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predice bastantes bien"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
