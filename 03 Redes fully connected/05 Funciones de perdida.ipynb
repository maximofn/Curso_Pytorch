{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones de pérdida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque hay muchas más, vamos a ver las funciones de pérdida incluidas dentro de Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "torch.nn.L1loss(size_average=None, reduce=None, reduction='mean')\n",
    "```\n",
    "\n",
    "Calcula el error absoluto\n",
    "\n",
    "$ l\\left(x,y\\right) = \\left[l_1,...,l_N\\right]^T $, donde $l = \\left|x_n-y_n\\right|$\n",
    "\n",
    "`reduction` usa por defecto ``'mean'``, pero puede también usar ``'sum'`` y ``'none'``. Los parámetros ``size_average`` y ``reduce`` están obsoletos y Pytorch recomienda no usarlos y solo usar ``reduction``\n",
    "\n",
    "Cuando en ``reduction`` se usa ``'mean'`` se hace una media de todos los errores, cuando se usa ``'sum'`` se hace la suma de todos los errores y cuando se usa ``'none'`` no se hace nada\n",
    "\n",
    "Vamos a verlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos lo que sería la predicción de la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1499, 0.7838, 0.6332, 0.4235, 0.5981],\n",
       "        [0.7691, 0.4440, 0.9998, 0.1718, 0.0864],\n",
       "        [0.3246, 0.6581, 0.2118, 0.6618, 0.8150]], requires_grad=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "preds = torch.rand(3, 5, requires_grad=True)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos lo que sería la verdadera salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9842, 0.0592, 0.1925, 0.2206, 0.8483],\n",
       "        [0.9688, 0.5489, 0.5241, 0.3715, 0.6758],\n",
       "        [0.7450, 0.4149, 0.6630, 0.8465, 0.8706]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.rand(3, 5)\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la función de coste con `reduction` con su valor predeterminado, es decir, `mean` y comparamos lo que da la función de coste con hacer nosotros la operación que dice la teoría"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3584846556186676, 0.3584846556186676)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.nn.L1Loss(size_average=None, reduce=None, reduction='mean') # Predeterminado\n",
    "\n",
    "loss_fn = loss(preds, target)\n",
    "my_loss = abs(preds - target).mean()\n",
    "\n",
    "loss_fn.item(), my_loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la función de coste ahora con `reduction` con valor `sum` y comparamos lo que da la función de coste con hacer nosotros la operación que dice la teoría"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.377269744873047, 5.377269744873047)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.nn.L1Loss(size_average=None, reduce=None, reduction='sum')\n",
    "\n",
    "loss_fn = loss(preds, target)\n",
    "my_loss = abs(preds - target).sum()\n",
    "\n",
    "loss_fn.item(), my_loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la función de coste ahora con `reduction` con valor `none` y comparamos lo que da la función de coste con hacer nosotros la operación que dice la teoría"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.8343, 0.7246, 0.4406, 0.2028, 0.2503],\n",
       "         [0.1998, 0.1049, 0.4757, 0.1997, 0.5894],\n",
       "         [0.4204, 0.2432, 0.4513, 0.1847, 0.0557]], grad_fn=<L1LossBackward0>),\n",
       " tensor([[0.8343, 0.7246, 0.4406, 0.2028, 0.2503],\n",
       "         [0.1998, 0.1049, 0.4757, 0.1997, 0.5894],\n",
       "         [0.4204, 0.2432, 0.4513, 0.1847, 0.0557]], grad_fn=<AbsBackward0>))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.nn.L1Loss(size_average=None, reduce=None, reduction='none')\n",
    "\n",
    "loss_fn = loss(preds, target)\n",
    "my_loss = abs(preds - target)\n",
    "\n",
    "loss_fn, my_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "torch.nn.MSELoss(size_average=None, reduce=None, reduction='mean')\n",
    "```\n",
    "\n",
    "Calcula el error cuadrático\n",
    "\n",
    "$ l\\left(x,y\\right) = \\left[l_1,...,l_N\\right]^T $, donde $l = \\left(x_n-y_n\\right)^2$\n",
    "\n",
    "`reduction` usa por defecto ``'mean'``, pero puede también usar ``'sum'`` y ``'none'``. Los parámetros ``size_average`` y ``reduce`` están obsoletos y Pytorch recomienda no usarlos y solo usar ``reduction``\n",
    "\n",
    "Cuando en ``reduction`` se usa ``'mean'`` se hace una media de todos los errores, cuando se usa ``'sum'`` se hace la suma de todos los errores y cuando se usa ``'none'`` no se hace nada\n",
    "\n",
    "Vamos a verlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos lo que sería la predicción de la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5684, 0.4625, 0.5211, 0.9668, 0.8776],\n",
       "        [0.7379, 0.9137, 0.6533, 0.5459, 0.2191],\n",
       "        [0.5523, 0.9015, 0.8059, 0.8893, 0.3489]], requires_grad=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "preds = torch.rand(3, 5, requires_grad=True)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos lo que sería la verdadera salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8533, 0.8784, 0.0505, 0.9376, 0.2134],\n",
       "        [0.2214, 0.6986, 0.1518, 0.2798, 0.2936],\n",
       "        [0.5170, 0.2116, 0.8899, 0.6630, 0.0535]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.rand(3, 5)\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la función de coste con `reduction` con su valor predeterminado, es decir, `mean` y comparamos lo que da la función de coste con hacer nosotros la operación que dice la teoría"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1454271823167801, 0.10110653936862946)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.nn.MSELoss(size_average=None, reduce=None, reduction='mean') # Predeterminado\n",
    "\n",
    "loss_fn = loss(preds, target)\n",
    "my_loss = (abs(preds - target).mean())**2\n",
    "\n",
    "loss_fn.item(), my_loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la función de coste ahora con `reduction` con valor `sum` y comparamos lo que da la función de coste con hacer nosotros la operación que dice la teoría"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.1814076900482178, 2.1814076900482178)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.nn.MSELoss(size_average=None, reduce=None, reduction='sum')\n",
    "\n",
    "loss_fn = loss(preds, target)\n",
    "my_loss = ((preds - target)**2).sum()\n",
    "\n",
    "loss_fn.item(), my_loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la función de coste ahora con `reduction` con valor `none` y comparamos lo que da la función de coste con hacer nosotros la operación que dice la teoría"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0812, 0.1730, 0.2215, 0.0009, 0.4411],\n",
       "         [0.2669, 0.0463, 0.2515, 0.0708, 0.0056],\n",
       "         [0.0012, 0.4759, 0.0071, 0.0512, 0.0873]], grad_fn=<MseLossBackward0>),\n",
       " tensor([[0.0812, 0.1730, 0.2215, 0.0009, 0.4411],\n",
       "         [0.2669, 0.0463, 0.2515, 0.0708, 0.0056],\n",
       "         [0.0012, 0.4759, 0.0071, 0.0512, 0.0873]], grad_fn=<PowBackward0>))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.nn.MSELoss(size_average=None, reduce=None, reduction='none')\n",
    "\n",
    "loss_fn = loss(preds, target)\n",
    "my_loss = (preds - target)**2\n",
    "\n",
    "loss_fn, my_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "torch.nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=- 100, reduce=None, reduction='mean', label_smoothing=0.0)\n",
    "```\n",
    "\n",
    "Calcula el error cuadrático\n",
    "\n",
    "$ l\\left(x,y\\right) = \\left[l_1,...,l_N\\right]^T $, donde $l = \\left(x_n-y_n\\right)^2$\n",
    "\n",
    "`reduction` usa por defecto ``'mean'``, pero puede también usar ``'sum'`` y ``'none'``. Los parámetros ``size_average`` y ``reduce`` están obsoletos y Pytorch recomienda no usarlos y solo usar ``reduction``\n",
    "\n",
    "Cuando en ``reduction`` se usa ``'mean'`` se hace una media de todos los errores, cuando se usa ``'sum'`` se hace la suma de todos los errores y cuando se usa ``'none'`` no se hace nada\n",
    "\n",
    "Vamos a verlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos lo que sería la predicción de la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5684, 0.4625, 0.5211, 0.9668, 0.8776],\n",
       "        [0.7379, 0.9137, 0.6533, 0.5459, 0.2191],\n",
       "        [0.5523, 0.9015, 0.8059, 0.8893, 0.3489]], requires_grad=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "preds = torch.rand(3, 5, requires_grad=True)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos lo que sería la verdadera salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8533, 0.8784, 0.0505, 0.9376, 0.2134],\n",
       "        [0.2214, 0.6986, 0.1518, 0.2798, 0.2936],\n",
       "        [0.5170, 0.2116, 0.8899, 0.6630, 0.0535]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target = torch.rand(3, 5)\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la función de coste con `reduction` con su valor predeterminado, es decir, `mean` y comparamos lo que da la función de coste con hacer nosotros la operación que dice la teoría"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1454271823167801, 0.10110653936862946)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = torch.nn.MSELoss(size_average=None, reduce=None, reduction='mean') # Predeterminado\n",
    "\n",
    "loss_fn = loss(preds, target)\n",
    "my_loss = (abs(preds - target).mean())**2\n",
    "\n",
    "loss_fn.item(), my_loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la función de coste ahora con `reduction` con valor `sum` y comparamos lo que da la función de coste con hacer nosotros la operación que dice la teoría"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.1814076900482178, 2.1814076900482178)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = torch.nn.MSELoss(size_average=None, reduce=None, reduction='sum')\n",
    "\n",
    "loss_fn = loss(preds, target)\n",
    "my_loss = ((preds - target)**2).sum()\n",
    "\n",
    "loss_fn.item(), my_loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la función de coste ahora con `reduction` con valor `none` y comparamos lo que da la función de coste con hacer nosotros la operación que dice la teoría"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0812, 0.1730, 0.2215, 0.0009, 0.4411],\n",
       "         [0.2669, 0.0463, 0.2515, 0.0708, 0.0056],\n",
       "         [0.0012, 0.4759, 0.0071, 0.0512, 0.0873]], grad_fn=<MseLossBackward0>),\n",
       " tensor([[0.0812, 0.1730, 0.2215, 0.0009, 0.4411],\n",
       "         [0.2669, 0.0463, 0.2515, 0.0708, 0.0056],\n",
       "         [0.0012, 0.4759, 0.0071, 0.0512, 0.0873]], grad_fn=<PowBackward0>))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = torch.nn.MSELoss(size_average=None, reduce=None, reduction='none')\n",
    "\n",
    "loss_fn = loss(preds, target)\n",
    "my_loss = (preds - target)**2\n",
    "\n",
    "loss_fn, my_loss"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8e4d58f53b4b3ced286559ef92073773937aa87eedd0536c036fd264999b02c5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
