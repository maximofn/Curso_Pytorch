{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning rate decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una cosa que se puede hacer para mejorar el entrenamiento es ir disminuyendo el valor del learning rate a medida que entrenamos. Veamos por qué"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vemos el efecto de entrenar con un valor de learning rate de 0.01 en el ejemplo anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter imagemagick unavailable; using Pillow instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento para lr = 0.025\n",
      "i=10: error=3.5332415076132806, gradiente=4.434751401390874, a=1.945937013155588\n",
      "i=20: error=3.463169558318404, gradiente=0.11728176690111386, a=1.990209371273261\n",
      "i=30: error=3.46312055035669, gradiente=0.0031016423701155796, a=1.9913802013638249\n",
      "i=40: error=3.463120516080773, gradiente=8.202626584997337e-05, a=1.991411165223878\n",
      "i=50: error=3.4631205160568, gradiente=2.1692727570984022e-06, a=1.9914119840964342\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "x = np.array( [ 0.        ,  0.34482759,  0.68965517,  1.03448276,  1.37931034,\n",
    "        1.72413793,  2.06896552,  2.4137931 ,  2.75862069,  3.10344828,\n",
    "        3.44827586,  3.79310345,  4.13793103,  4.48275862,  4.82758621,\n",
    "        5.17241379,  5.51724138,  5.86206897,  6.20689655,  6.55172414,\n",
    "        6.89655172,  7.24137931,  7.5862069 ,  7.93103448,  8.27586207,\n",
    "        8.62068966,  8.96551724,  9.31034483,  9.65517241, 10.        ])\n",
    "\n",
    "y = np.array( [-0.16281253,  1.88707606,  0.39649312,  0.03857752,  4.0148778 ,\n",
    "        0.58866234,  3.35711859,  1.94314906,  6.96106424,  5.89792585,\n",
    "        8.47226615,  3.67698542, 12.05958678,  9.85234481,  9.82181679,\n",
    "        6.07652248, 14.17536744, 12.67825433, 12.97499286, 11.76098542,\n",
    "       12.7843083 , 16.42241036, 13.67913705, 15.55066478, 17.45979602,\n",
    "       16.41982806, 17.01977617, 20.28151197, 19.38148414, 19.41029831])\n",
    "\n",
    "random.seed(45)\n",
    "a = random.random()\n",
    "\n",
    "def loss_fn(y, z):\n",
    "    n = len(y)\n",
    "    loss = np.sum((z-y) ** 2) / n\n",
    "    return loss\n",
    "\n",
    "posibles_a = np.linspace(0, 4, 300)\n",
    "perdidas = np.empty_like(posibles_a)\n",
    "\n",
    "for i in range (len(posibles_a)):\n",
    "    z = posibles_a[i]*x\n",
    "    perdidas[i] = loss_fn(y, z)\n",
    "\n",
    "def gradiente (a, x, y):\n",
    "    # Función que calcula el valor de una derivada en un punto\n",
    "    n = len(y)\n",
    "    return 2*np.sum((a*x - y)*x)/n\n",
    "\n",
    "def gradiente_linea (i, a=None, error=None, gradiente=None, posibles_w=None, \n",
    "    losses=None, gradientes=None):\n",
    "    # Función que devuleve los puntos de la linea que supone la derivada de una \n",
    "    # función en un punto dado\n",
    "    if a is None:\n",
    "        x1 = posibles_w[i]-0.7\n",
    "        x2 = posibles_w[i]\n",
    "        x3 = posibles_w[i]+0.7\n",
    "\n",
    "        b = losses[i] - gradientes[i]*posibles_w[i]\n",
    "\n",
    "        y1 = gradientes[i]*x1 + b\n",
    "        y2 = losses[i]\n",
    "        y3 = gradientes[i]*x3 + b\n",
    "    else:\n",
    "        x1 = a-0.7\n",
    "        x2 = a\n",
    "        x3 = a+0.7\n",
    "\n",
    "        b = error - gradiente*a\n",
    "\n",
    "        y1 = gradiente*x1 + b\n",
    "        y2 = error\n",
    "        y3 = gradiente*x3 + b\n",
    "\n",
    "    x_linea = np.array([x1, x2, x3])\n",
    "    y_linea = np.array([y1, y2, y3])\n",
    "\n",
    "    return x_linea, y_linea\n",
    "\n",
    "LRs = [2.5e-2]    # Tasa de aprendizaje o learning rate\n",
    "steps = 50  # Numero de veces que se realiza el bucle de enrtenamiento\n",
    "\n",
    "# Matrices donde se guardarán los datos para luego ver la evolución del entrenamiento en una gráfica\n",
    "Zs = np.empty([len(LRs), steps, len(x)])\n",
    "Xs_linea_gradiente = np.empty([len(LRs), steps, 3])\n",
    "Ys_linea_gradiente = np.empty([len(LRs), steps, 3])\n",
    "As = np.empty([len(LRs), steps])\n",
    "Errores = np.empty([len(LRs), steps])\n",
    "\n",
    "for l, lr in enumerate(LRs):\n",
    "    # Inicialización aleatoria de a\n",
    "    random.seed(45)\n",
    "    a = random.random()\n",
    "    \n",
    "    print(f\"Entrenamiento para lr = {lr}\")\n",
    "    for i in range(steps):\n",
    "        # Calculamos el gradiente\n",
    "        dl = gradiente(a, x, y)\n",
    "\n",
    "        # Corregimos el valor de a\n",
    "        a = a - lr*dl\n",
    "\n",
    "        # Calculamos los valores que obtiene la red neuronal\n",
    "        z = a*x\n",
    "\n",
    "        # Obtenemos el error\n",
    "        error = loss_fn(y, z)\n",
    "\n",
    "        # Obtenemos las rectas de los gradientes para representarlas\n",
    "        x_linea_gradiente, y_linea_gradiente = gradiente_linea(3, a=a, error=error, gradiente=dl)\n",
    "\n",
    "        # Guardamos los valores para luego ver la evolución del entrenamiento en una gráfica\n",
    "        As[l][i] = a\n",
    "        Zs[l][i] = z\n",
    "        Errores[l][i] = error\n",
    "        Xs_linea_gradiente[l][i] = x_linea_gradiente\n",
    "        Ys_linea_gradiente[l][i] = y_linea_gradiente\n",
    "\n",
    "        # Imprimimos la evolución del entrenamiento\n",
    "        if (i+1)%10 == 0:\n",
    "            print(f\"i={i+1}: error={error}, gradiente={dl}, a={a}\")\n",
    "\n",
    "\n",
    "# Creamos GIF con la evolución del entrenamiento\n",
    "rectas = []\n",
    "gradientes = []\n",
    "puntos = []\n",
    "a_texts = []\n",
    "error_texts = []\n",
    "lr_texts = []\n",
    "\n",
    "fontsize = 12\n",
    "\n",
    "# Creamos la gráfica inicial\n",
    "fig, ax = plt.subplots(len(LRs),2, figsize=(15, 5*len(LRs)))\n",
    "ax = ax.reshape(len(LRs),ax.shape[0])\n",
    "fig.set_tight_layout(True)\n",
    "for i in range(len(LRs)):\n",
    "    ax[i][0].set_xlabel('X')\n",
    "    ax[i][0].set_ylabel('Y  ', rotation=0)\n",
    "    ax[i][1].set_xlabel('a')\n",
    "    ax[i][1].set_ylabel('loss  ', rotation=0)\n",
    "    ax[i][0].set_xlim(-0.5, 10.5)\n",
    "    ax[i][0].set_ylim(-0.5, 20.5)\n",
    "    ax[i][1].set_xlim(-0.5, 4.5)\n",
    "    ax[i][1].set_ylim(-0.5, 140.5)\n",
    "\n",
    "    # Se dibujan los datos que persistiran en toda la evolución de la gráfica\n",
    "    ax[i][0].scatter(x, y)\n",
    "    ax[i][1].plot(posibles_a, perdidas, linewidth = 3)\n",
    "\n",
    "    # Se dibuja el resto de lineas que irán cambiando durante el entrenamiento\n",
    "    line1, = ax[i][0].plot(x, Zs[i][0], 'k', linewidth=2)                             # Recta generada con la pendiente a aprendida\n",
    "    line2, = ax[i][1].plot(Xs_linea_gradiente[i][0], Ys_linea_gradiente[i][0], 'g')   # Gradiente de la función de error\n",
    "    punto, = ax[i][1].plot(As[i][0], Errores[i][0], 'r*')                             # Punto donde se calcula el gradiente\n",
    "    rectas.append(line1)\n",
    "    gradientes.append(line2)\n",
    "    puntos.append(punto)\n",
    "\n",
    "    # Se dibujan textos dentro de la segunda figura del subplot\n",
    "    lr_text = ax[i][1].text(1, 100, f'lr = {LRs[i]}', fontsize = fontsize)\n",
    "    a_text = ax[i][1].text(1, 90, f'pesos = {As[i][0]:.5f}', fontsize = fontsize)\n",
    "    error_text = ax[i][1].text(1, 80, f'loss = {Errores[i][0]:.5f}', fontsize = fontsize)\n",
    "    a_texts.append(a_text)\n",
    "    error_texts.append(error_text)\n",
    "    lr_texts.append(lr_text)\n",
    "    \n",
    "# Se dibuja un título\n",
    "titulo = fig.suptitle(f'step: {0}', fontsize=fontsize)\n",
    "\n",
    "# Se define la función que va a modificar la gráfica con la evolución del entrenamiento\n",
    "def update(i):\n",
    "\n",
    "    for l, _ in enumerate(LRs):\n",
    "        # Se actualiza la recta generada con la pendiente a aprendida\n",
    "        rectas[l].set_ydata(Zs[l][i])\n",
    "\n",
    "        # Se actualiza el gradiente de la función de error\n",
    "        gradientes[l].set_xdata(Xs_linea_gradiente[l][i])\n",
    "        gradientes[l].set_ydata(Ys_linea_gradiente[l][i])\n",
    "\n",
    "        # Se actualiza el punto 2. Punto donde se calcula el gradiente\n",
    "        puntos[l].set_xdata(As[l][i])\n",
    "        puntos[l].set_ydata(Errores[l][i])\n",
    "\n",
    "        # Se actualizan los textos\n",
    "        a_texts[l].set_text(f'pesos = {As[l][i]:.5f}')\n",
    "        error_texts[l].set_text(f'loss = {Errores[l][i]:.5f}')\n",
    "        lr_texts[l].set_text(f'lr = {LRs[l]}')\n",
    "    \n",
    "    titulo.set_text(f'step: {i}')\n",
    "\n",
    "    return line1, # ax1, #line2, punto2, ax2, a_text, error_text\n",
    "\n",
    "# Se crea la animación con un refresco cada 200 ms\n",
    "interval = 500 # ms\n",
    "anim = FuncAnimation(fig, update, frames=np.arange(0, steps), interval=interval)\n",
    "\n",
    "# Se guarda en un GIF\n",
    "gif_name = \"GIFs/LR_noDecay.gif\"\n",
    "anim.save(gif_name, dpi=80, writer='imagemagick')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LR sin decaimiento](GIFs/LR_noDecay.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver desde el step 4 el error no cambia mucho, en 4 steps se ha llegado a la mejor solución posible, pero vamos a ver si hacemos zoom en la zona del mínimo error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter imagemagick unavailable; using Pillow instead.\n"
     ]
    }
   ],
   "source": [
    "# Creamos GIF con la evolución del entrenamiento\n",
    "rectas = []\n",
    "gradientes1 = []\n",
    "gradientes2 = []\n",
    "puntos1 = []\n",
    "puntos2 = []\n",
    "a_texts1 = []\n",
    "a_texts2 = []\n",
    "error_texts1 = []\n",
    "error_texts2 = []\n",
    "lr_texts1 = []\n",
    "lr_texts2 = []\n",
    "\n",
    "\n",
    "fontsize = 12\n",
    "\n",
    "# Creamos la gráfica inicial\n",
    "fig, ax = plt.subplots(len(LRs),3, figsize=(15, 5*len(LRs)))\n",
    "ax = ax.reshape(len(LRs),ax.shape[0])\n",
    "fig.set_tight_layout(True)\n",
    "for i in range(len(LRs)):\n",
    "    ax[i][0].set_xlabel('X')\n",
    "    ax[i][0].set_ylabel('Y  ', rotation=0)\n",
    "    ax[i][1].set_xlabel('a')\n",
    "    ax[i][1].set_ylabel('loss  ', rotation=0)\n",
    "    ax[i][2].set_xlabel('a')\n",
    "    ax[i][2].set_ylabel('loss  ', rotation=0)\n",
    "    ax[i][0].set_xlim(-0.5, 10.5)\n",
    "    ax[i][0].set_ylim(-0.5, 20.5)\n",
    "    ax[i][1].set_xlim(-0.5, 4.5)\n",
    "    ax[i][1].set_ylim(-0.5, 140.5)\n",
    "    ax[i][2].set_xlim(1.8, 2.2)\n",
    "    ax[i][2].set_ylim(3, 5.0)\n",
    "\n",
    "    # Se dibujan los datos que persistiran en toda la evolución de la gráfica\n",
    "    ax[i][0].scatter(x, y)\n",
    "    ax[i][1].plot(posibles_a, perdidas, linewidth = 3)\n",
    "    ax[i][2].plot(posibles_a, perdidas, linewidth = 3)\n",
    "\n",
    "    # Se dibuja el resto de lineas que irán cambiando durante el entrenamiento\n",
    "    recta, = ax[i][0].plot(x, Zs[i][0], 'k', linewidth=2)                             # Recta generada con la pendiente a aprendida\n",
    "    gradiente1, = ax[i][1].plot(Xs_linea_gradiente[i][0], Ys_linea_gradiente[i][0], 'g')   # Gradiente de la función de error\n",
    "    gradiente2, = ax[i][2].plot(Xs_linea_gradiente[i][0], Ys_linea_gradiente[i][0], 'g')   # Gradiente de la función de error\n",
    "    punto1, = ax[i][1].plot(As[i][0], Errores[i][0], 'r*')                             # Punto donde se calcula el gradiente\n",
    "    punto2, = ax[i][2].plot(As[i][0], Errores[i][0], 'r*')                             # Punto donde se calcula el gradiente\n",
    "    rectas.append(recta)\n",
    "    gradientes1.append(gradiente1)\n",
    "    gradientes2.append(gradiente2)\n",
    "    puntos1.append(punto1)\n",
    "    puntos2.append(punto2)\n",
    "\n",
    "    # Se dibujan textos dentro de la segunda figura del subplot\n",
    "    lr_text1 = ax[i][1].text(1, 100, f'lr = {LRs[i]}', fontsize = fontsize)\n",
    "    lr_text2 = ax[i][2].text(1.9, 4.75, f'lr = {LRs[i]}', fontsize = fontsize)\n",
    "    a_text1 = ax[i][1].text(1, 90, f'pesos = {As[i][0]:.5f}', fontsize = fontsize)\n",
    "    a_text2 = ax[i][2].text(1.9, 4.65, f'pesos = {As[i][0]:.5f}', fontsize = fontsize)\n",
    "    error_text1 = ax[i][1].text(1, 80, f'loss = {Errores[i][0]:.5f}', fontsize = fontsize)\n",
    "    error_text2 = ax[i][2].text(1.9, 4.55, f'loss = {Errores[i][0]:.5f}', fontsize = fontsize)\n",
    "    a_texts1.append(a_text1)\n",
    "    a_texts2.append(a_text2)\n",
    "    error_texts1.append(error_text1)\n",
    "    error_texts2.append(error_text2)\n",
    "    lr_texts1.append(lr_text1)\n",
    "    lr_texts2.append(lr_text2)\n",
    "    \n",
    "# Se dibuja un título\n",
    "titulo = fig.suptitle(f'step: {0}', fontsize=fontsize)\n",
    "\n",
    "# Se define la función que va a modificar la gráfica con la evolución del entrenamiento\n",
    "def update(i):\n",
    "\n",
    "    for l, _ in enumerate(LRs):\n",
    "        # Se actualiza la recta generada con la pendiente a aprendida\n",
    "        rectas[l].set_ydata(Zs[l][i])\n",
    "\n",
    "        # Se actualiza el gradiente de la función de error\n",
    "        gradientes1[l].set_xdata(Xs_linea_gradiente[l][i])\n",
    "        gradientes1[l].set_ydata(Ys_linea_gradiente[l][i])\n",
    "        gradientes2[l].set_xdata(Xs_linea_gradiente[l][i])\n",
    "        gradientes2[l].set_ydata(Ys_linea_gradiente[l][i])\n",
    "\n",
    "        # Se actualiza el punto 2. Punto donde se calcula el gradiente\n",
    "        puntos1[l].set_xdata(As[l][i])\n",
    "        puntos1[l].set_ydata(Errores[l][i])\n",
    "        puntos2[l].set_xdata(As[l][i])\n",
    "        puntos2[l].set_ydata(Errores[l][i])\n",
    "\n",
    "        # Se actualizan los textos\n",
    "        a_texts1[l].set_text(f'pesos = {As[l][i]:.5f}')\n",
    "        a_texts2[l].set_text(f'pesos = {As[l][i]:.5f}')\n",
    "        error_texts1[l].set_text(f'loss = {Errores[l][i]:.5f}')\n",
    "        error_texts2[l].set_text(f'loss = {Errores[l][i]:.5f}')\n",
    "        lr_texts1[l].set_text(f'lr = {LRs[l]}')\n",
    "        lr_texts2[l].set_text(f'lr = {LRs[l]}')\n",
    "    \n",
    "    titulo.set_text(f'step: {i}')\n",
    "\n",
    "    return line1, # ax1, #line2, punto2, ax2, a_text, error_text\n",
    "\n",
    "# Se crea la animación con un refresco cada 200 ms\n",
    "interval = 500 # ms\n",
    "anim = FuncAnimation(fig, update, frames=np.arange(0, steps), interval=interval)\n",
    "\n",
    "# Se guarda en un GIF\n",
    "gif_name = \"GIFs/LR_noDecay_zoom.gif\"\n",
    "anim.save(gif_name, dpi=80, writer='imagemagick')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LR sin decaimiento](GIFs/LR_noDecay_zoom.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver, si se hace zoom, el punto va dando saltos al rededor del mínimo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos qué pasa si vamos disminuyendo el valor del learning rate a medida que vamos entrenando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter imagemagick unavailable; using Pillow instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento para lr = 0.025\n",
      "i=10: error=3.5332415076132806, gradiente=4.434751401390874, a=1.945937013155588\n",
      "i=20: error=3.463169558318404, gradiente=0.11728176690111386, a=1.990209371273261\n",
      "\n",
      "Entrenamiento para lr = 0.025\n",
      "i=10: error=3.46312053385814, gradiente=0.010202610187635781, a=1.9914349189821918\n",
      "i=20: error=3.4631205160568017, gradiente=2.662718301434571e-06, a=1.9914120289624948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LRs = [2.5e-2, 2.5e-2]    # Tasa de aprendizaje o learning rate\n",
    "steps = 20  # Numero de veces que se realiza el bucle de enrtenamiento\n",
    "\n",
    "# Matrices donde se guardarán los datos para luego ver la evolución del entrenamiento en una gráfica\n",
    "Zs = np.empty([len(LRs), steps, len(x)])\n",
    "Xs_linea_gradiente = np.empty([len(LRs), steps, 3])\n",
    "Ys_linea_gradiente = np.empty([len(LRs), steps, 3])\n",
    "As = np.empty([len(LRs), steps])\n",
    "Errores = np.empty([len(LRs), steps])\n",
    "LR_values = np.empty([len(LRs), steps])\n",
    "lr_decay = 0\n",
    "\n",
    "for l, lr in enumerate(LRs):\n",
    "    # Inicialización aleatoria de a\n",
    "    random.seed(45)\n",
    "    a = random.random()\n",
    "    \n",
    "    print(f\"Entrenamiento para lr = {lr}\")\n",
    "    for i in range(steps):\n",
    "        # Calculamos el gradiente\n",
    "        dl = gradiente(a, x, y)\n",
    "\n",
    "        # Corregimos el valor de a\n",
    "        if l == 0:\n",
    "            lr_decay = lr\n",
    "            a -= lr * dl\n",
    "        else:\n",
    "            if i >= 0 and i < 5:\n",
    "                lr_decay = lr\n",
    "            elif i >= 5 and i < 10:\n",
    "                lr_decay = lr/2\n",
    "            elif i >= 10 and i < 15:\n",
    "                lr_decay = lr/3\n",
    "            elif i >= 15 and i < 20:\n",
    "                lr_decay = lr/4\n",
    "            a = a - lr_decay*dl\n",
    "\n",
    "        # Calculamos los valores que obtiene la red neuronal\n",
    "        z = a*x\n",
    "\n",
    "        # Obtenemos el error\n",
    "        error = loss_fn(y, z)\n",
    "\n",
    "        # Obtenemos las rectas de los gradientes para representarlas\n",
    "        x_linea_gradiente, y_linea_gradiente = gradiente_linea(3, a=a, error=error, gradiente=dl)\n",
    "\n",
    "        # Guardamos los valores para luego ver la evolución del entrenamiento en una gráfica\n",
    "        As[l][i] = a\n",
    "        Zs[l][i] = z\n",
    "        Errores[l][i] = error\n",
    "        Xs_linea_gradiente[l][i] = x_linea_gradiente\n",
    "        Ys_linea_gradiente[l][i] = y_linea_gradiente\n",
    "        LR_values[l][i] = lr_decay\n",
    "\n",
    "        # Imprimimos la evolución del entrenamiento\n",
    "        if (i+1)%10 == 0:\n",
    "            print(f\"i={i+1}: error={error}, gradiente={dl}, a={a}\")\n",
    "        \n",
    "    print()\n",
    "\n",
    "\n",
    "\n",
    "# Creamos GIF con la evolución del entrenamiento\n",
    "rectas = []\n",
    "gradientes1 = []\n",
    "gradientes2 = []\n",
    "puntos1 = []\n",
    "puntos2 = []\n",
    "a_texts1 = []\n",
    "a_texts2 = []\n",
    "error_texts1 = []\n",
    "error_texts2 = []\n",
    "lr_texts1 = []\n",
    "lr_texts2 = []\n",
    "\n",
    "\n",
    "fontsize = 12\n",
    "\n",
    "# Creamos la gráfica inicial\n",
    "fig, ax = plt.subplots(len(LRs),3, figsize=(15, 5*len(LRs)))\n",
    "fig.set_tight_layout(True)\n",
    "for i in range(len(LRs)):\n",
    "    ax[i][0].set_xlabel('X')\n",
    "    ax[i][0].set_ylabel('Y  ', rotation=0)\n",
    "    ax[i][1].set_xlabel('a')\n",
    "    ax[i][1].set_ylabel('loss  ', rotation=0)\n",
    "    ax[i][2].set_xlabel('a')\n",
    "    ax[i][2].set_ylabel('loss  ', rotation=0)\n",
    "    ax[i][0].set_xlim(-0.5, 10.5)\n",
    "    ax[i][0].set_ylim(-0.5, 20.5)\n",
    "    ax[i][1].set_xlim(-0.5, 4.5)\n",
    "    ax[i][1].set_ylim(-0.5, 140.5)\n",
    "    ax[i][2].set_xlim(1.8, 2.2)\n",
    "    ax[i][2].set_ylim(3, 5.0)\n",
    "\n",
    "    # Se dibujan los datos que persistiran en toda la evolución de la gráfica\n",
    "    ax[i][0].scatter(x, y)\n",
    "    ax[i][1].plot(posibles_a, perdidas, linewidth = 3)\n",
    "    ax[i][2].plot(posibles_a, perdidas, linewidth = 3)\n",
    "\n",
    "    # Se dibuja el resto de lineas que irán cambiando durante el entrenamiento\n",
    "    recta, = ax[i][0].plot(x, Zs[i][0], 'k', linewidth=2)                             # Recta generada con la pendiente a aprendida\n",
    "    gradiente1, = ax[i][1].plot(Xs_linea_gradiente[i][0], Ys_linea_gradiente[i][0], 'g')   # Gradiente de la función de error\n",
    "    gradiente2, = ax[i][2].plot(Xs_linea_gradiente[i][0], Ys_linea_gradiente[i][0], 'g')   # Gradiente de la función de error\n",
    "    punto1, = ax[i][1].plot(As[i][0], Errores[i][0], 'r*')                             # Punto donde se calcula el gradiente\n",
    "    punto2, = ax[i][2].plot(As[i][0], Errores[i][0], 'r*')                             # Punto donde se calcula el gradiente\n",
    "    rectas.append(recta)\n",
    "    gradientes1.append(gradiente1)\n",
    "    gradientes2.append(gradiente2)\n",
    "    puntos1.append(punto1)\n",
    "    puntos2.append(punto2)\n",
    "\n",
    "    # Se dibujan textos dentro de la segunda figura del subplot\n",
    "    lr_text1 = ax[i][1].text(1, 100, f'lr = {LR_values[i][0]:.5f}', fontsize = fontsize)\n",
    "    lr_text2 = ax[i][2].text(1.9, 4.75, f'lr = {LR_values[i][0]:.5f}', fontsize = fontsize)\n",
    "    a_text1 = ax[i][1].text(1, 90, f'pesos = {As[i][0]:.5f}', fontsize = fontsize)\n",
    "    a_text2 = ax[i][2].text(1.9, 4.65, f'pesos = {As[i][0]:.5f}', fontsize = fontsize)\n",
    "    error_text1 = ax[i][1].text(1, 80, f'loss = {Errores[i][0]:.5f}', fontsize = fontsize)\n",
    "    error_text2 = ax[i][2].text(1.9, 4.55, f'loss = {Errores[i][0]:.5f}', fontsize = fontsize)\n",
    "    a_texts1.append(a_text1)\n",
    "    a_texts2.append(a_text2)\n",
    "    error_texts1.append(error_text1)\n",
    "    error_texts2.append(error_text2)\n",
    "    lr_texts1.append(lr_text1)\n",
    "    lr_texts2.append(lr_text2)\n",
    "    \n",
    "# Se dibuja un título\n",
    "titulo = fig.suptitle(f'step: {0}', fontsize=fontsize)\n",
    "\n",
    "# Se define la función que va a modificar la gráfica con la evolución del entrenamiento\n",
    "def update(i):\n",
    "\n",
    "    for l, _ in enumerate(LRs):\n",
    "        # Se actualiza la recta generada con la pendiente a aprendida\n",
    "        rectas[l].set_ydata(Zs[l][i])\n",
    "\n",
    "        # Se actualiza el gradiente de la función de error\n",
    "        gradientes1[l].set_xdata(Xs_linea_gradiente[l][i])\n",
    "        gradientes1[l].set_ydata(Ys_linea_gradiente[l][i])\n",
    "        gradientes2[l].set_xdata(Xs_linea_gradiente[l][i])\n",
    "        gradientes2[l].set_ydata(Ys_linea_gradiente[l][i])\n",
    "\n",
    "        # Se actualiza el punto 2. Punto donde se calcula el gradiente\n",
    "        puntos1[l].set_xdata(As[l][i])\n",
    "        puntos1[l].set_ydata(Errores[l][i])\n",
    "        puntos2[l].set_xdata(As[l][i])\n",
    "        puntos2[l].set_ydata(Errores[l][i])\n",
    "\n",
    "        # Se actualizan los textos\n",
    "        a_texts1[l].set_text(f'pesos = {As[l][i]:.5f}')\n",
    "        a_texts2[l].set_text(f'pesos = {As[l][i]:.5f}')\n",
    "        error_texts1[l].set_text(f'loss = {Errores[l][i]:.5f}')\n",
    "        error_texts2[l].set_text(f'loss = {Errores[l][i]:.5f}')\n",
    "        lr_texts1[l].set_text(f'lr = {LR_values[l][i]:.5f}')\n",
    "        lr_texts2[l].set_text(f'lr = {LR_values[l][i]:.5f}')\n",
    "    \n",
    "    titulo.set_text(f'step: {i}')\n",
    "\n",
    "    return line1, # ax1, #line2, punto2, ax2, a_text, error_text\n",
    "\n",
    "# Se crea la animación con un refresco cada 200 ms\n",
    "interval = 500 # ms\n",
    "anim = FuncAnimation(fig, update, frames=np.arange(0, steps), interval=interval)\n",
    "\n",
    "# Se guarda en un GIF\n",
    "gif_name = \"GIFs/LR_decay.gif\"\n",
    "anim.save(gif_name, dpi=80, writer='imagemagick')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LR sin decaimiento](GIFs/LR_decay.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver, cuando estamos cerca del mínimo error, es buena idea ir disminuyendo el valor del learning rate para que se ajuste mejor al problema.\n",
    "\n",
    "Aquí se ha mostrado un ejemplo en el que se reduce el valor del learnig rate cada 5 steps, para que sea ilustrativo. Pero en la realidad, lo que se suele hacer es que si despues de varias épocas, el error, o la métrica que se esté usando, no mejora, se reduce el valor del learning rate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8e4d58f53b4b3ced286559ef92073773937aa87eedd0536c036fd264999b02c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
