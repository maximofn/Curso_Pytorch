{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se recordamos, a la hora de entrenar redes neuronales podemos estar en el caso del subentrenamiento, que esté bien entrneada, o del sobreentrenamiento\n",
    "\n",
    "![subentrenamiento, entrenamiento y sobreentrenamiento](../01%20Introduccion%20a%20las%20redes%20neuronales/Imagenes/sobreentrenamiento.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pues bien, a la hora de resolver un problema con redes neuronales, para evitar estar en el primer caso, en el de subentrenamiento, lo que se suele hacer es usar redes grandes para resolver el problema. Probablemente redes más grandes de lo que en realidad necesitamos.\n",
    "\n",
    "Esto hace que podamos caer en el último caso, en el del sobreentrenamiento. Por lo que paraevitar sobreentrenar se suelen usar métodos de regularización que evitan esto.\n",
    "\n",
    "Vamos a ver algunos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularización L2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consiste en sumar un termino en la función ded coste\n",
    "\n",
    "$$loss_{L2} = loss + \\frac{\\lambda}{2N}\\sum_{i=1}^{N}{\\omega_i^2}$$\n",
    "\n",
    "$\\lambda$ es un hiperparámetro que definimos nosotros y que indica la importancia o la magnitod de la regularización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Por qué funciona la regularización L2? Como hemos visto, durante el entrenamiento, los pesos de la red se actualizan restándoles el gradiente de la función de coste, multiplicada por el learning rate $\\alpha$. Así que vamos ha calcular el gradiente\n",
    "\n",
    "$$\\frac{\\partial loss_{L2}}{\\partial \\omega_i} = \\frac{\\partial loss}{\\partial \\omega_i} + \\frac{\\partial}{\\partial \\omega_i}\\left[\\frac{\\lambda}{2N}\\sum_{i=1}^{N}{\\omega_i^2}\\right] = $$\n",
    "$$ = \\frac{\\partial loss}{\\partial \\omega_i} + \\frac{\\lambda}{N}\\omega_i$$\n",
    "\n",
    "Por tanto el peso $\\omega_i$ se actualiza de la siguiente manera\n",
    "\n",
    "$$\\omega_i = \\omega_i - \\alpha\\frac{\\partial loss_{L2}}{\\partial \\omega_i} = \\omega_i - \\frac{\\partial loss}{\\partial \\omega_i} - \\frac{\\lambda}{N}\\omega_i$$\n",
    "\n",
    "Es decir, en redes en las que un peso $\\omega_i$ sea muy grande lo estamos reduciendo gracias al término $-\\frac{\\lambda}{N}\\omega_i$. Por tanto, estamos reduciendo la complegidad de la red, ya que estamos reduciendo algunos pesos.\n",
    "\n",
    "Hay que recordar, que los pesos simbolizan la union entre dos neuronas, por lo que reduciendo el valor de un peso, estamos reduciendo el enlace entre esas dos neuronas, hasta tal punto que si se reduce mucho podría equivaler a eliminar la unión entre esas neuronas.\n",
    "\n",
    "Por lo tras varias épocas de entrenamiento, pasamos de una red grande, con muchas conexiones, a una red más simple, en la que algunas conexiones se han roto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cómo se hace esto en Pytorch? Hasta ahora solo hemos visto el optimizador del [SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD), así que vamos a ver cómo hacerlo para dicho optimizador, ya que para el resto es similar\n",
    "\n",
    "Si recordamos, cada vez que hemos usado este optimizador lo hemos hecho así\n",
    "\n",
    "```python\n",
    "torch.optim.SGD(model.parameters(), lr=LR)\n",
    "```\n",
    "\n",
    "Es decir, le estamos pasando los parámetros del modelo y el learning rate, y cuando llamamos a su método `step()`\n",
    "\n",
    "```python\n",
    "optimizer.step()\n",
    "```\n",
    "\n",
    "Realiza la actualización de los parámetros de la manera que habíamos visto hasta ahora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero cuando se crea el optimizador pasándole el parámetro `weight_decay` realiza la regularización L2. En realidad siempre la está haciendo, lo que pasa es que por defecto, si no indicamos nada, `weight_decay = 0`, lo que supone $\\lambda = 0$. De modo que a la hora de definir el optimizador tenemos que pasarle un valor a `weight_decay`, que es lo mismo que definir el valor de $\\lambda$\n",
    "\n",
    "```python\n",
    "torch.optim.SGD(model.parameters(), lr=LR, weight_decay=X)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early stopping"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
