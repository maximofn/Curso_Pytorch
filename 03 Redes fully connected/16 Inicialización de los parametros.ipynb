{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicialización de los parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch nos da la posibilidad de [inicializar](https://pytorch.org/docs/stable/nn.init.html) los parámetros de una red. Aunque es algo que no se suele modificar, y se suele dejar la manera en la que Pytorch lo hace poir defecto, vamos a ver un ejemplo de inicialización por el método [Xavier](https://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descargamos un dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "cancer = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  type  \n",
       "0          0.4601                  0.11890     0  \n",
       "1          0.2750                  0.08902     0  \n",
       "2          0.3613                  0.08758     0  \n",
       "3          0.6638                  0.17300     0  \n",
       "4          0.2364                  0.07678     0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cancer_df = pd.DataFrame(cancer['data'], columns=cancer['feature_names'])\n",
    "cancer_df['type'] = cancer['target']\n",
    "cancer_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class CancerDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        cols = [col for col in dataframe.columns if col != 'target']\n",
    "        self.parameters = torch.from_numpy(dataframe[cols].values).type(torch.float32)\n",
    "        self.targets = torch.from_numpy(dataframe['type'].values).type(torch.float32)\n",
    "        self.targets = self.targets.reshape((len(self.targets), 1))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.parameters)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        parameters = self.parameters[idx]\n",
    "        target = self.targets[idx]\n",
    "        return parameters, target\n",
    "\n",
    "ds = CancerDataset(cancer_df)\n",
    "train_ds, valid_ds = torch.utils.data.random_split(ds, [int(0.8*len(ds)), len(ds) - int(0.8*len(ds))], generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora el dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BS_train = 64\n",
    "BS_val = 128 # Solo hay 114 datos de validación, por lo que no se puede dividir en batches\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=BS_train, shuffle=True)\n",
    "val_dl = DataLoader(valid_ds, batch_size=BS_val, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos la red neuronal que inicialzia los pesos mediante el método [Xavier](https://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class CancerNeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs, hidden_layers=[100, 50, 20]):\n",
    "        super().__init__()\n",
    "        self.network = torch.nn.Sequential(\n",
    "            torch.nn.Linear(num_inputs, hidden_layers[0]),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_layers[0], hidden_layers[1]),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_layers[1], hidden_layers[2]),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_layers[2], num_outputs),\n",
    "        )\n",
    "        self.activation = torch.nn.Sigmoid()\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "    \n",
    "    # Weights initialization using Xavier's method\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "            nn.init.zeros_(module.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.network(x)\n",
    "        probs = self.activation(logits)\n",
    "        return logits, probs\n",
    "\n",
    "num_inputs = 31\n",
    "num_outputs = 1\n",
    "model = CancerNeuralNetwork(num_inputs, num_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llevamos la red a la GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CancerNeuralNetwork(\n",
       "  (network): Sequential(\n",
       "    (0): Linear(in_features=31, out_features=100, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=50, out_features=20, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=20, out_features=1, bias=True)\n",
       "  )\n",
       "  (activation): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos la función de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-3\n",
    "\n",
    "loss_fn2 = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_prints = 4\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # X and y to device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction and loss\n",
    "        logits, probs = model(X)\n",
    "        loss = loss_fn2(logits, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % int(len(dataloader)/num_prints) == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def val_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            # X and y to device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            logits, probs = model(X)\n",
    "            test_loss += loss_fn2(logits, y).item()\n",
    "            correct += (probs.round() == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.863001  [    0/  455]\n",
      "loss: 10.362530  [  128/  455]\n",
      "loss: 4.719738  [  256/  455]\n",
      "loss: 0.781383  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 3.963881 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 3.213980  [    0/  455]\n",
      "loss: 1.604453  [  128/  455]\n",
      "loss: 0.415575  [  256/  455]\n",
      "loss: 0.586057  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 40.4%, Avg loss: 1.085941 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.143599  [    0/  455]\n",
      "loss: 0.597836  [  128/  455]\n",
      "loss: 0.762338  [  256/  455]\n",
      "loss: 1.031210  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 55.3%, Avg loss: 0.590678 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.596846  [    0/  455]\n",
      "loss: 0.721222  [  128/  455]\n",
      "loss: 0.755344  [  256/  455]\n",
      "loss: 0.945605  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 52.6%, Avg loss: 0.600504 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.613941  [    0/  455]\n",
      "loss: 0.403116  [  128/  455]\n",
      "loss: 0.497373  [  256/  455]\n",
      "loss: 0.491463  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 58.8%, Avg loss: 0.593611 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.641655  [    0/  455]\n",
      "loss: 0.592233  [  128/  455]\n",
      "loss: 0.459304  [  256/  455]\n",
      "loss: 0.409672  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 65.8%, Avg loss: 0.816985 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.548542  [    0/  455]\n",
      "loss: 0.389573  [  128/  455]\n",
      "loss: 0.521483  [  256/  455]\n",
      "loss: 0.405541  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.423999 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.445894  [    0/  455]\n",
      "loss: 0.417736  [  128/  455]\n",
      "loss: 0.299599  [  256/  455]\n",
      "loss: 0.437341  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.447204 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.577272  [    0/  455]\n",
      "loss: 0.503531  [  128/  455]\n",
      "loss: 0.372776  [  256/  455]\n",
      "loss: 0.405071  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.378193 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.385943  [    0/  455]\n",
      "loss: 0.415827  [  128/  455]\n",
      "loss: 0.401309  [  256/  455]\n",
      "loss: 0.555673  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 69.3%, Avg loss: 0.544879 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.556585  [    0/  455]\n",
      "loss: 0.492370  [  128/  455]\n",
      "loss: 0.398606  [  256/  455]\n",
      "loss: 0.283918  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.492454 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.461370  [    0/  455]\n",
      "loss: 0.360008  [  128/  455]\n",
      "loss: 0.351744  [  256/  455]\n",
      "loss: 0.510014  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.389408 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.423869  [    0/  455]\n",
      "loss: 0.279330  [  128/  455]\n",
      "loss: 0.454896  [  256/  455]\n",
      "loss: 0.398849  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.354745 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.387005  [    0/  455]\n",
      "loss: 0.452605  [  128/  455]\n",
      "loss: 0.560351  [  256/  455]\n",
      "loss: 0.473743  [  384/  455]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.477308 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 14\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dl, model, loss_fn2, optimizer)\n",
    "    val_loop(val_dl, model, loss_fn2)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('HuBMAP_HPA')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5908be7129383694b4ff55a3fd43a54e78208ed305dac25c0e93bbd971e0eb3e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
