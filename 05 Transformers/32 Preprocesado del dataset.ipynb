{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesado del dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de los datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero de todo cargamos los datos a los que le hicimos la limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "path = \"data/opus100_croped_10\"\n",
    "opus100 = load_from_disk(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos los start, end, padding token y la longitud máxima de secuencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoder = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "start_token = chr(1)\n",
    "start_token = encoder.encode(start_token)\n",
    "\n",
    "end_token = chr(2)\n",
    "end_token = encoder.encode(end_token)\n",
    "\n",
    "padding_token = chr(3)\n",
    "padding_token = encoder.encode(padding_token)\n",
    "\n",
    "max_secuence_length = 10 + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una función que preprocesa el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "\n",
    "def preprocess_dataset(dataset, split, start_token, end_token, padding_token, encoder, max_secuence_length):\n",
    "    inputs = []\n",
    "    labels = []\n",
    "\n",
    "    progress_bar = tqdm.tqdm(total=len(dataset[split]))\n",
    "\n",
    "    for example in dataset[split]:\n",
    "        input = example['translation']['en']\n",
    "        input = start_token + encoder.encode(input) + end_token\n",
    "        if len(input) > max_secuence_length:  # Truncate if too long\n",
    "            input = input[:max_secuence_length]\n",
    "        else:  # Pad if too short\n",
    "            input = input + padding_token * (max_secuence_length - len(input))\n",
    "        input = torch.tensor(input)\n",
    "        inputs.append(input)\n",
    "\n",
    "        label = example['translation']['es']\n",
    "        label = start_token + encoder.encode(label) + end_token\n",
    "        if len(label) > max_secuence_length:  # Truncate if too long\n",
    "            label = label[:max_secuence_length]\n",
    "        else:  # Pad if too short\n",
    "            label = label + padding_token * (max_secuence_length - len(label))\n",
    "        label = torch.tensor(label)\n",
    "        labels.append(label)\n",
    "\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    inputs = torch.stack(inputs)\n",
    "    labels = torch.stack(labels)\n",
    "\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos la función lo que coger cada muestra del dataset codificarla, convertirla en un tensor y guardarla en un stack. Esto lo hacemos para que durante el entrenamiento no se pierda tiempo en codificar las secuencias, podamos entrenar más rápido y por tanto más épocas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después guardamos esos stacks en un fichero para poder cargarlos más tarde y no tener que volver a preprocesar el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 463854/463854 [00:27<00:00, 16818.00it/s]\n"
     ]
    }
   ],
   "source": [
    "split = 'train'\n",
    "inputs, labels = preprocess_dataset(opus100, split, start_token, end_token, padding_token, encoder, max_secuence_length)\n",
    "torch.save(inputs, f\"data/opus100_croped_10/{split}_inputs.pt\")\n",
    "torch.save(labels, f\"data/opus100_croped_10/{split}_labels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 691/691 [00:00<00:00, 16724.07it/s]\n"
     ]
    }
   ],
   "source": [
    "split = 'test'\n",
    "inputs, labels = preprocess_dataset(opus100, 'test', start_token, end_token, padding_token, encoder, max_secuence_length)\n",
    "torch.save(inputs, f\"data/opus100_croped_10/{split}_inputs.pt\")\n",
    "torch.save(labels, f\"data/opus100_croped_10/{split}_labels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 691/691 [00:00<00:00, 18527.90it/s]\n"
     ]
    }
   ],
   "source": [
    "split = 'validation'\n",
    "inputs, labels = preprocess_dataset(opus100, 'test', start_token, end_token, padding_token, encoder, max_secuence_length)\n",
    "torch.save(inputs, f\"data/opus100_croped_10/{split}_inputs.pt\")\n",
    "torch.save(labels, f\"data/opus100_croped_10/{split}_labels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/opus100_croped_20\"\n",
    "opus100 = load_from_disk(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 741145/741145 [00:47<00:00, 15599.54it/s]\n"
     ]
    }
   ],
   "source": [
    "split = 'train'\n",
    "inputs, labels = preprocess_dataset(opus100, split, start_token, end_token, padding_token, encoder, max_secuence_length)\n",
    "torch.save(inputs, f\"data/opus100_croped_10/{split}_inputs.pt\")\n",
    "torch.save(labels, f\"data/opus100_croped_10/{split}_labels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1311/1311 [00:00<00:00, 15443.28it/s]\n"
     ]
    }
   ],
   "source": [
    "split = 'test'\n",
    "inputs, labels = preprocess_dataset(opus100, 'test', start_token, end_token, padding_token, encoder, max_secuence_length)\n",
    "torch.save(inputs, f\"data/opus100_croped_10/{split}_inputs.pt\")\n",
    "torch.save(labels, f\"data/opus100_croped_10/{split}_labels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1311/1311 [00:00<00:00, 14806.26it/s]\n"
     ]
    }
   ],
   "source": [
    "split = 'validation'\n",
    "inputs, labels = preprocess_dataset(opus100, 'test', start_token, end_token, padding_token, encoder, max_secuence_length)\n",
    "torch.save(inputs, f\"data/opus100_croped_10/{split}_inputs.pt\")\n",
    "torch.save(labels, f\"data/opus100_croped_10/{split}_labels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/opus100_croped\"\n",
    "opus100 = load_from_disk(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 983138/983138 [01:13<00:00, 13412.87it/s]\n"
     ]
    }
   ],
   "source": [
    "split = 'train'\n",
    "inputs, labels = preprocess_dataset(opus100, split, start_token, end_token, padding_token, encoder, max_secuence_length)\n",
    "torch.save(inputs, f\"data/opus100_croped_10/{split}_inputs.pt\")\n",
    "torch.save(labels, f\"data/opus100_croped_10/{split}_labels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1955/1955 [00:00<00:00, 12452.92it/s]\n"
     ]
    }
   ],
   "source": [
    "split = 'test'\n",
    "inputs, labels = preprocess_dataset(opus100, 'test', start_token, end_token, padding_token, encoder, max_secuence_length)\n",
    "torch.save(inputs, f\"data/opus100_croped_10/{split}_inputs.pt\")\n",
    "torch.save(labels, f\"data/opus100_croped_10/{split}_labels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1955/1955 [00:00<00:00, 12194.48it/s]\n"
     ]
    }
   ],
   "source": [
    "split = 'validation'\n",
    "inputs, labels = preprocess_dataset(opus100, 'test', start_token, end_token, padding_token, encoder, max_secuence_length)\n",
    "torch.save(inputs, f\"data/opus100_croped_10/{split}_inputs.pt\")\n",
    "torch.save(labels, f\"data/opus100_croped_10/{split}_labels.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cursopytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
