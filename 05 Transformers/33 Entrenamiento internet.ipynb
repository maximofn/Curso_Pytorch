{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BS: 60\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Dataset\n",
    "SOURCE_LANGUAGE = \"en\"\n",
    "TARGET_LANGUAGE = \"it\"\n",
    "SUBSET = False\n",
    "PERCENT_SUBSET = 0.1\n",
    "\n",
    "# Train\n",
    "EPOCH0 = 0\n",
    "STEP0 = 0\n",
    "LR = 1e-5\n",
    "EPOCHS = 100000\n",
    "GPUS = 1\n",
    "GPU_NUMBER = 0\n",
    "if GPUS > 1:\n",
    "    BS = 120\n",
    "else:\n",
    "    if SUBSET:\n",
    "        BS = 128\n",
    "    else:\n",
    "        BS = 60\n",
    "print(f\"BS: {BS}\")\n",
    "LR_SCHEDULER = False\n",
    "\n",
    "# Model\n",
    "MODEL_PATH = f\"model\"\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    files = os.listdir(MODEL_PATH)\n",
    "    for file in files:\n",
    "        if \"transformer\" in file:\n",
    "            name = file.split(\".\")[0]\n",
    "            STEP0 = int(name.split(\"_\")[-1])\n",
    "            EPOCH0 = int(name.split(\"_\")[-2])\n",
    "DIM_EMBEDDING = 512\n",
    "NUM_HEADS = 8\n",
    "NUM_LAYERS = 6\n",
    "DROPOUT = 0.1\n",
    "LABEL_SMOOTHING = 0.1\n",
    "\n",
    "# Tokenizers\n",
    "TOKENIZERS_PATH = f\"tokenizers\"\n",
    "if not os.path.exists(TOKENIZERS_PATH):\n",
    "    os.makedirs(TOKENIZERS_PATH)\n",
    "UNKNOWN_TOKEN = \"[UNK]\"\n",
    "PADDING_TOKEN = \"[PAD]\"\n",
    "START_OF_SEQUENCE = \"[SOS]\"\n",
    "END_OF_SEQUENCE = \"[EOS]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOs\n",
    "# TODO: Cambiar el dataset\n",
    "# TODO: Podar el transformer\n",
    "# TODO: Usar mi función de crear máscara\n",
    "# TODO: Usar mi función de validación\n",
    "# TODO: Usar mi función de entrenamiento\n",
    "# TODO: Sacar la máscara del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device ✔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.device_count() > 1 and GPUS > 1:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "else:\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(f\"cuda:{GPU_NUMBER}\")\n",
    "        print(f\"Using GPU {GPU_NUMBER}\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de los datos ✔"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset opus_books (/home/wallabot/.cache/huggingface/datasets/opus_books/en-it/1.0.0/e8f950a4f32dc39b7f9088908216cd2d7e21ac35f893d04d39eb594746af2daf)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32332"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "if SUBSET:\n",
    "    dataset_raw = load_dataset('opus_books', f'{SOURCE_LANGUAGE}-{TARGET_LANGUAGE}', split='train')\n",
    "    len_dataset = len(dataset_raw)\n",
    "    len_subset = int(len_dataset * PERCENT_SUBSET)\n",
    "    dataset_raw = load_dataset('opus_books', f'{SOURCE_LANGUAGE}-{TARGET_LANGUAGE}', split=f'train[:{len_subset}]')\n",
    "else:\n",
    "    dataset_raw = load_dataset('opus_books', f'{SOURCE_LANGUAGE}-{TARGET_LANGUAGE}', split='train')\n",
    "\n",
    "len(dataset_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver cómo es el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'translation'],\n",
       "    num_rows: 32332\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que es una tupla de con dos características cada elemento, la primera la id y la segunda el texto.\n",
    "\n",
    "Vamos a ver el primer elemento de la tupla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0',\n",
       " 'translation': {'en': 'Source: Project Gutenberg',\n",
       "  'it': 'Source: www.liberliber.it/Audiobook available here'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_raw[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos ahora el segundo elemento de la tupla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '1', 'translation': {'en': 'Jane Eyre', 'it': 'Jane Eyre'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_raw[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el `id` no nos aporta mucha información, por lo que no lo usaremos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ahora a ver el elemento `translation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'Charlotte Bronte', 'it': 'Charlotte Brontë'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_raw[2]['translation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada elemento `translation` es un diccionario con el texto en el idioma original y el texto traducido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de los tokenizers ✔"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a entrenar un tokenizer para cada idioma. Podríamos utilizar uno ya preentrenado, pero a veces entrenar uno propio puede dar mejores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_sentences(dataset):\n",
    "    all_sentences = []\n",
    "    for i in range(len(dataset)):\n",
    "        all_sentences.append(dataset[i]['translation'][SOURCE_LANGUAGE])\n",
    "        all_sentences.append(dataset[i]['translation'][TARGET_LANGUAGE])\n",
    "    return all_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el tokenizer para el idioma original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training source tokenizer\n"
     ]
    }
   ],
   "source": [
    "tokenizer_source_path = f\"{TOKENIZERS_PATH}/tokenizer_{SOURCE_LANGUAGE}.json\"\n",
    "\n",
    "if not os.path.exists(tokenizer_source_path) or STEP0 == 0 or EPOCH0 == 0:\n",
    "    print(f\"Training source tokenizer\")\n",
    "    tokenizer_source = Tokenizer(WordLevel(unk_token=UNKNOWN_TOKEN))\n",
    "    tokenizer_source.pre_tokenizer = Whitespace()\n",
    "    trainer = WordLevelTrainer(special_tokens=[UNKNOWN_TOKEN, PADDING_TOKEN, START_OF_SEQUENCE, END_OF_SEQUENCE])\n",
    "    all_sentences = get_all_sentences(dataset_raw)\n",
    "    tokenizer_source.train_from_iterator(all_sentences, trainer)\n",
    "    tokenizer_source.save(tokenizer_source_path)\n",
    "else:\n",
    "    tokenizer_source = Tokenizer.from_file(tokenizer_source_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver cómo es el tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"version\": \"1.0\",\n",
      "  \"truncation\": null,\n",
      "  \"padding\": null,\n",
      "  \"added_tokens\": [\n",
      "    {\n",
      "      \"id\": 0,\n",
      "      \"content\": \"[UNK]\",\n",
      "      \"single_word\": false,\n",
      "      \"lstrip\": false,\n",
      "      \"rstrip\": false,\n",
      "      \"normalized\": false,\n",
      "      \"special\": true\n",
      "    },\n",
      "    {\n",
      "      \"id\": 1,\n",
      "      \"content\": \"[PAD]\",\n",
      "      \"single_word\": false,\n",
      "      \"lstrip\": false,\n",
      "      \"rstrip\": false,\n",
      "      \"normalized\": false,\n",
      "      \"special\": true\n",
      "    },\n",
      "    {\n",
      "      \"id\": 2,\n",
      "      \"content\": \"[SOS]\",\n",
      "      \"single_word\": false,\n",
      "      \"lstrip\": false,\n",
      "      \"rstrip\": false,\n",
      "      \"normalized\": false,\n",
      "      \"special\": true\n",
      "    },\n",
      "    {\n",
      "      \"id\": 3,\n",
      "      \"content\": \"[EOS]\",\n",
      "      \"single_word\": false,\n",
      "      \"lstrip\": false,\n",
      "      \"rstrip\": false,\n",
      "      \"normalized\": false,\n",
      "      \"special\": true\n",
      "    }\n",
      "  ],\n",
      "  \"normalizer\": null,\n",
      "  \"pre_tokenizer\": {\n",
      "    \"type\": \"Whitespace\"\n",
      "  },\n",
      "  \"post_processor\": null,\n",
      "  \"decoder\": null,\n",
      "  \"model\": {\n",
      "    \"type\": \"WordLevel\",\n",
      "    \"vocab\": {\n",
      "      \"[UNK]\": 0,\n",
      "      \"[PAD]\": 1,\n",
      "      \"[SOS]\": 2,\n",
      "      \"[EOS]\": 3,\n",
      "      \",\": 4,\n",
      "      \".\": 5,\n",
      "      \"the\": 6,\n",
      "      \"and\": 7,\n",
      "      \"a\": 8,\n",
      "      \"e\": 9,\n",
      "      \"to\": 10,\n",
      "      \"di\": 11,\n",
      "      \"in\": 12,\n",
      "      \"I\": 13,\n",
      "      \"'\": 14,\n",
      "      \"che\": 15,\n",
      "      \"of\": 16,\n",
      "      \"—\": 17,\n",
      "      \"’\": 18,\n",
      "      \";\": 19,\n",
      "      \"la\": 20,\n",
      "      \"non\": 21,\n",
      "      \"il\": 22,\n",
      "      \"was\": 23,\n",
      "      \"that\": 24,\n",
      "      \"he\": 25,\n",
      "      \"it\": 26,\n",
      "      \"un\": 27,\n",
      "      \"had\": 28,\n",
      "      \"per\": 29,\n",
      "      \"his\": 30,\n",
      "      \"not\": 31,\n",
      "      \"with\": 32,\n",
      "      \"her\": 33,\n",
      "      \"si\": 34,\n",
      "      \":\": 35,\n",
      "      \"me\": 36,\n",
      "      \"you\": 37,\n",
      "      \"as\": 38,\n",
      "      \"con\": 39,\n",
      "      \"una\": 40,\n",
      "      \"for\": 41,\n",
      "      \"le\": 42,\n",
      "      \"era\": 43,\n",
      "      \"?\": 44,\n",
      "      \"-\": 45,\n",
      "      \"she\": 46,\n",
      "      \"\\\"\": 47,\n",
      "      \"my\": 48,\n"
     ]
    }
   ],
   "source": [
    "with open(tokenizer_source_path, 'r') as file:\n",
    "    for i in range(100):\n",
    "        line = file.readline()\n",
    "        if line == \"\\n\":\n",
    "            continue\n",
    "        print(line, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el tokenizer para el idioma traducido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training target tokenizer\n"
     ]
    }
   ],
   "source": [
    "tokenizer_target_path = f\"{TOKENIZERS_PATH}/tokenizer_{TARGET_LANGUAGE}.json\"\n",
    "\n",
    "if not os.path.exists(tokenizer_target_path) or STEP0 == 0 or EPOCH0 == 0:\n",
    "    print(f\"Training target tokenizer\")\n",
    "    tokenizer_target = Tokenizer(WordLevel(unk_token=UNKNOWN_TOKEN))\n",
    "    tokenizer_target.pre_tokenizer = Whitespace()\n",
    "    trainer = WordLevelTrainer(special_tokens=[UNKNOWN_TOKEN, PADDING_TOKEN, START_OF_SEQUENCE, END_OF_SEQUENCE])\n",
    "    all_sentences = get_all_sentences(dataset_raw)\n",
    "    tokenizer_target.train_from_iterator(all_sentences, trainer)\n",
    "    tokenizer_target.save(tokenizer_target_path)\n",
    "else:\n",
    "    tokenizer_target = Tokenizer.from_file(tokenizer_target_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver cómo es el tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"version\": \"1.0\",\n",
      "  \"truncation\": null,\n",
      "  \"padding\": null,\n",
      "  \"added_tokens\": [\n",
      "    {\n",
      "      \"id\": 0,\n",
      "      \"content\": \"[UNK]\",\n",
      "      \"single_word\": false,\n",
      "      \"lstrip\": false,\n",
      "      \"rstrip\": false,\n",
      "      \"normalized\": false,\n",
      "      \"special\": true\n",
      "    },\n",
      "    {\n",
      "      \"id\": 1,\n",
      "      \"content\": \"[PAD]\",\n",
      "      \"single_word\": false,\n",
      "      \"lstrip\": false,\n",
      "      \"rstrip\": false,\n",
      "      \"normalized\": false,\n",
      "      \"special\": true\n",
      "    },\n",
      "    {\n",
      "      \"id\": 2,\n",
      "      \"content\": \"[SOS]\",\n",
      "      \"single_word\": false,\n",
      "      \"lstrip\": false,\n",
      "      \"rstrip\": false,\n",
      "      \"normalized\": false,\n",
      "      \"special\": true\n",
      "    },\n",
      "    {\n",
      "      \"id\": 3,\n",
      "      \"content\": \"[EOS]\",\n",
      "      \"single_word\": false,\n",
      "      \"lstrip\": false,\n",
      "      \"rstrip\": false,\n",
      "      \"normalized\": false,\n",
      "      \"special\": true\n",
      "    }\n",
      "  ],\n",
      "  \"normalizer\": null,\n",
      "  \"pre_tokenizer\": {\n",
      "    \"type\": \"Whitespace\"\n",
      "  },\n",
      "  \"post_processor\": null,\n",
      "  \"decoder\": null,\n",
      "  \"model\": {\n",
      "    \"type\": \"WordLevel\",\n",
      "    \"vocab\": {\n",
      "      \"[UNK]\": 0,\n",
      "      \"[PAD]\": 1,\n",
      "      \"[SOS]\": 2,\n",
      "      \"[EOS]\": 3,\n",
      "      \",\": 4,\n",
      "      \".\": 5,\n",
      "      \"the\": 6,\n",
      "      \"and\": 7,\n",
      "      \"a\": 8,\n",
      "      \"e\": 9,\n",
      "      \"to\": 10,\n",
      "      \"di\": 11,\n",
      "      \"in\": 12,\n",
      "      \"I\": 13,\n",
      "      \"'\": 14,\n",
      "      \"che\": 15,\n",
      "      \"of\": 16,\n",
      "      \"—\": 17,\n",
      "      \"’\": 18,\n",
      "      \";\": 19,\n",
      "      \"la\": 20,\n",
      "      \"non\": 21,\n",
      "      \"il\": 22,\n",
      "      \"was\": 23,\n",
      "      \"that\": 24,\n",
      "      \"he\": 25,\n",
      "      \"it\": 26,\n",
      "      \"un\": 27,\n",
      "      \"had\": 28,\n",
      "      \"per\": 29,\n",
      "      \"his\": 30,\n",
      "      \"not\": 31,\n",
      "      \"with\": 32,\n",
      "      \"her\": 33,\n",
      "      \"si\": 34,\n",
      "      \":\": 35,\n",
      "      \"me\": 36,\n",
      "      \"you\": 37,\n",
      "      \"as\": 38,\n",
      "      \"con\": 39,\n",
      "      \"una\": 40,\n",
      "      \"for\": 41,\n",
      "      \"le\": 42,\n",
      "      \"era\": 43,\n",
      "      \"?\": 44,\n",
      "      \"-\": 45,\n",
      "      \"she\": 46,\n",
      "      \"\\\"\": 47,\n",
      "      \"my\": 48,\n"
     ]
    }
   ],
   "source": [
    "with open(tokenizer_target_path, 'r') as file:\n",
    "    for i in range(100):\n",
    "        line = file.readline()\n",
    "        if line == \"\\n\":\n",
    "            continue\n",
    "        print(line, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtención de la lóngitud máxima de las secuencias ✔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max source sequence length: 309\n",
      "Max target sequence length: 274\n",
      "Max sequence length: 311\n"
     ]
    }
   ],
   "source": [
    "max_source_sequence_length = 0\n",
    "max_target_sequence_length = 0\n",
    "\n",
    "for i in range(len(dataset_raw)):\n",
    "    source_sequence_length = len(tokenizer_source.encode(dataset_raw[i]['translation'][SOURCE_LANGUAGE]).ids)\n",
    "    target_sequence_length = len(tokenizer_target.encode(dataset_raw[i]['translation'][TARGET_LANGUAGE]).ids)\n",
    "    if source_sequence_length > max_source_sequence_length:\n",
    "        max_source_sequence_length = source_sequence_length\n",
    "    if target_sequence_length > max_target_sequence_length:\n",
    "        max_target_sequence_length = target_sequence_length\n",
    "\n",
    "max_sequence_len = max(max_source_sequence_length, max_target_sequence_length)\n",
    "max_sequence_len += 2   # Add 2 for the start and end of sequence tokens\n",
    "\n",
    "print(f\"Max source sequence length: {max_source_sequence_length}\")\n",
    "print(f\"Max target sequence length: {max_target_sequence_length}\")\n",
    "print(f\"Max sequence length: {max_sequence_len}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets ✔"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask ✔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(size):\n",
    "    mask = torch.triu(torch.ones(1, size, size), diagonal = 1).type(torch.int)\n",
    "    return mask == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset class ✔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class BilingualDataset(Dataset):\n",
    "    def __init__(self, dataset, tokenizer_src, tokenizer_tgt, src_lang, tgt_lang, max_seq_len) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer_src = tokenizer_src\n",
    "        self.tokenizer_tgt = tokenizer_tgt\n",
    "        self.src_lang = src_lang\n",
    "        self.tgt_lang = tgt_lang\n",
    "        \n",
    "        # Defining special tokens by using the target language tokenizer\n",
    "        self.sos_token = torch.tensor([tokenizer_tgt.token_to_id(START_OF_SEQUENCE)], dtype=torch.int64)\n",
    "        self.eos_token = torch.tensor([tokenizer_tgt.token_to_id(END_OF_SEQUENCE)], dtype=torch.int64)\n",
    "        self.pad_token = torch.tensor([tokenizer_tgt.token_to_id(PADDING_TOKEN)], dtype=torch.int64)\n",
    "        self.unk_token = torch.tensor([tokenizer_tgt.token_to_id(UNKNOWN_TOKEN)], dtype=torch.int64)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Getting the source and target texts from the dataset\n",
    "        src_target_pair = self.dataset[index]['translation']\n",
    "        src_text = src_target_pair[self.src_lang]\n",
    "        tgt_text = src_target_pair[self.tgt_lang]\n",
    "        \n",
    "        # Tokenizing source and target texts \n",
    "        encoder_input_tokens = self.tokenizer_src.encode(src_text).ids\n",
    "        decoder_input_tokens = self.tokenizer_tgt.encode(tgt_text).ids\n",
    "        \n",
    "        # Computing how many padding tokens need to be added to the tokenized texts \n",
    "        encoder_num_padding_tokens = self.max_seq_len - len(encoder_input_tokens) - 2 # Subtracting the two '[EOS]' and '[SOS]' special tokens\n",
    "        decoder_num_padding_tokens = self.max_seq_len - len(decoder_input_tokens) - 1 # Subtracting the '[SOS]' special token\n",
    "        \n",
    "        # If the texts exceed the 'seq_len' allowed, it will raise an error. This means that one of the sentences in the pair is too long to be processed\n",
    "        # given the current sequence length limit (this will be defined in the config dictionary below)\n",
    "        if encoder_num_padding_tokens < 0 or decoder_num_padding_tokens < 0:\n",
    "            raise ValueError('Sentence is too long')\n",
    "         \n",
    "        # Building the encoder input tensor by combining several elements\n",
    "        encoder_input = torch.cat(\n",
    "            [\n",
    "                self.sos_token, # inserting the '[SOS]' token\n",
    "                torch.tensor(encoder_input_tokens, dtype = torch.int64), # Inserting the tokenized source text\n",
    "                self.eos_token, # Inserting the '[EOS]' token\n",
    "                torch.tensor([self.pad_token] * encoder_num_padding_tokens, dtype = torch.int64) # Addind padding tokens\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Building the decoder input tensor by combining several elements\n",
    "        decoder_input = torch.cat(\n",
    "            [\n",
    "                self.sos_token, # inserting the '[SOS]' token \n",
    "                torch.tensor(decoder_input_tokens, dtype = torch.int64), # Inserting the tokenized target text\n",
    "                torch.tensor([self.pad_token] * decoder_num_padding_tokens, dtype = torch.int64) # Addind padding tokens\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Creating a label tensor, the expected output for training the model\n",
    "        label = torch.cat(\n",
    "            [\n",
    "                torch.tensor(decoder_input_tokens, dtype = torch.int64), # Inserting the tokenized target text\n",
    "                self.eos_token, # Inserting the '[EOS]' token \n",
    "                torch.tensor([self.pad_token] * decoder_num_padding_tokens, dtype = torch.int64) # Adding padding tokens\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Ensuring that the length of each tensor above is equal to the defined 'seq_len'\n",
    "        assert encoder_input.size(0) == self.max_seq_len\n",
    "        assert decoder_input.size(0) == self.max_seq_len\n",
    "        assert label.size(0) == self.max_seq_len\n",
    "\n",
    "        return {\n",
    "            'encoder_input': encoder_input,\n",
    "            'decoder_input': decoder_input, \n",
    "            'decoder_mask': (decoder_input != self.pad_token).unsqueeze(0).unsqueeze(0).int() & create_mask(decoder_input.size(0)),\n",
    "            'label': label,\n",
    "            'src_text': src_text,\n",
    "            'tgt_text': tgt_text\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos una muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder input shape: torch.Size([311])\n",
      "Decoder input shape: torch.Size([311])\n",
      "Label shape: torch.Size([311])\n",
      "Source text: I think she is very kind, mais excessivement terre-à-terre. [Excessively matter-of-fact.]\n",
      "Target text: È molto buona, mi pare, mais excessivement terre-à-terre.\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "sample_dataset = BilingualDataset(dataset_raw, tokenizer_source, tokenizer_target, SOURCE_LANGUAGE, TARGET_LANGUAGE, max_sequence_len)\n",
    "idx = randint(0, len(sample_dataset))\n",
    "sample_dataset = sample_dataset[idx]\n",
    "\n",
    "print(f\"Encoder input shape: {sample_dataset['encoder_input'].shape}\")\n",
    "print(f\"Decoder input shape: {sample_dataset['decoder_input'].shape}\")\n",
    "print(f\"Label shape: {sample_dataset['label'].shape}\")\n",
    "print(f\"Source text: {sample_dataset['src_text']}\")\n",
    "print(f\"Target text: {sample_dataset['tgt_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset ✔"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que vemos que está bien, creamos los datasets de entrenamiento y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len train: 32008, len validation: 324\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "percent_train = 0.99\n",
    "len_train = int(len(dataset_raw) * percent_train)\n",
    "len_val = len(dataset_raw) - len_train\n",
    "train_dataset_raw, validation_dataset_raw = random_split(dataset_raw, [len_train, len_val])\n",
    "\n",
    "print(f\"Len train: {len(train_dataset_raw)}, len validation: {len(validation_dataset_raw)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BilingualDataset(train_dataset_raw, tokenizer_source, tokenizer_target, SOURCE_LANGUAGE, TARGET_LANGUAGE, max_sequence_len)\n",
    "validation_dataset = BilingualDataset(validation_dataset_raw, tokenizer_source, tokenizer_target, SOURCE_LANGUAGE, TARGET_LANGUAGE, max_sequence_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaders ✔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BS, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=BS, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver una muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "type(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos la muestra es un diccionario, vamos a ver sus claves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['encoder_input', 'decoder_input', 'decoder_mask', 'label', 'src_text', 'tgt_text'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las claves son las salidas que habíamos definido en el dataset. Vamos a ver ahora cómo es cada una de las claves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60, 311]), torch.Size([60, 311]), torch.Size([60, 311]), 60, 60)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['encoder_input'].shape, batch['decoder_input'].shape, batch['label'].shape, len(batch['src_text']), len(batch['tgt_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada una de las claves tiene tantas muestras como hemos definido en el batch size (`BS`). Vamos ahora a ver una de las muestras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder input shape: torch.Size([311])\n",
      "Decoder input shape: torch.Size([311])\n",
      "Label shape: torch.Size([311])\n",
      "Source text: 'Who was it came in?' he asked the door-keeper.\n",
      "Target text: — Chi è entrato? — chiese all’usciere.\n"
     ]
    }
   ],
   "source": [
    "idx = randint(0, BS)\n",
    "\n",
    "print(f\"Encoder input shape: {batch['encoder_input'][idx].shape}\")\n",
    "print(f\"Decoder input shape: {batch['decoder_input'][idx].shape}\")\n",
    "print(f\"Label shape: {batch['label'][idx].shape}\")\n",
    "print(f\"Source text: {batch['src_text'][idx]}\")\n",
    "print(f\"Target text: {batch['tgt_text'][idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo ✔"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvemos a escribir todo el código del transformer y creamos un objeto de este"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clases de bajo nivel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "class CustomLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(CustomLinear, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "        init.kaiming_uniform_(self.linear.weight, nonlinearity='relu')\n",
    "        if self.linear.bias is not None:\n",
    "            init.zeros_(self.linear.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "class CustomEmbedding(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        super(CustomEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_dim)\n",
    "        init.xavier_uniform_(self.embedding.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.embedding(x)\n",
    "\n",
    "class Embedding(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        self.embedding = CustomEmbedding(vocab_size, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embedding(x)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, max_sequence_len, embedding_model_dim):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_model_dim\n",
    "        positional_encoding = torch.zeros(max_sequence_len, self.embedding_dim)\n",
    "        for pos in range(max_sequence_len):\n",
    "            for i in range(0, self.embedding_dim, 2):\n",
    "                positional_encoding[pos, i]     = torch.sin(torch.tensor(pos / (10000 ** ((2 * i) / self.embedding_dim))))\n",
    "                positional_encoding[pos, i + 1] = torch.cos(torch.tensor(pos / (10000 ** ((2 * (i+1)) / self.embedding_dim))))\n",
    "        positional_encoding = positional_encoding.unsqueeze(0)\n",
    "        self.register_buffer('positional_encoding', positional_encoding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x * torch.sqrt(torch.tensor(self.embedding_dim))\n",
    "        sequence_len = x.size(1)\n",
    "        x = x + self.positional_encoding[:,:sequence_len]\n",
    "        return x\n",
    "\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, dim_embedding):\n",
    "        super().__init__()\n",
    "        self.dim_embedding = dim_embedding\n",
    "    \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        key_trasposed = key.transpose(-1,-2)\n",
    "        product = torch.matmul(query, key_trasposed)\n",
    "        scale = product / torch.sqrt(torch.tensor(self.dim_embedding))\n",
    "        if mask is not None:\n",
    "            scale = scale.masked_fill(mask == 0, float('-inf'))\n",
    "        attention_matrix = torch.softmax(scale, dim=-1)\n",
    "        output = torch.matmul(attention_matrix, value)\n",
    "        return output\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, heads, dim_embedding):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dim_embedding = dim_embedding\n",
    "        self.dim_proyection = dim_embedding // heads\n",
    "        self.heads = heads\n",
    "        self.proyection_Q = CustomLinear(dim_embedding, dim_embedding)\n",
    "        self.proyection_K = CustomLinear(dim_embedding, dim_embedding)\n",
    "        self.proyection_V = CustomLinear(dim_embedding, dim_embedding)\n",
    "        self.attention = CustomLinear(dim_embedding, dim_embedding)\n",
    "        self.scaled_dot_product_attention = ScaledDotProductAttention(self.dim_proyection)\n",
    "    \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        batch_size = Q.size(0)\n",
    "        proyection_Q = self.proyection_Q(Q).view(batch_size, -1, self.heads, self.dim_proyection)\n",
    "        proyection_K = self.proyection_K(K).view(batch_size, -1, self.heads, self.dim_proyection)\n",
    "        proyection_V = self.proyection_V(V).view(batch_size, -1, self.heads, self.dim_proyection)\n",
    "        proyection_Q = proyection_Q.transpose(1,2)\n",
    "        proyection_K = proyection_K.transpose(1,2)\n",
    "        proyection_V = proyection_V.transpose(1,2)\n",
    "        scaled_dot_product_attention = self.scaled_dot_product_attention(proyection_Q, proyection_K, proyection_V, mask=mask)\n",
    "        concat = scaled_dot_product_attention.transpose(1,2).contiguous().view(batch_size, -1, self.dim_embedding)\n",
    "        output = self.attention(concat)\n",
    "        return output\n",
    "\n",
    "class AddAndNorm(nn.Module):\n",
    "    def __init__(self, dim_embedding):\n",
    "        super().__init__()\n",
    "        self.normalization = nn.LayerNorm(dim_embedding)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        return self.normalization(torch.add(x, sublayer))\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim_embedding, increment=4):\n",
    "        super().__init__()\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            CustomLinear(dim_embedding, dim_embedding*increment),\n",
    "            nn.ReLU(),\n",
    "            CustomLinear(dim_embedding*increment, dim_embedding)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.feed_forward(x)\n",
    "        return x\n",
    "\n",
    "class Linear(nn.Module):\n",
    "    def __init__(self, dim_embedding, vocab_size):\n",
    "        super().__init__()\n",
    "        self.linear = CustomLinear(dim_embedding, vocab_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "class Softmax(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "class Dropout(torch.nn.Module):\n",
    "    def __init__(self, p=0.1):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            return torch.nn.functional.dropout(x, p=self.p)\n",
    "        else:\n",
    "            return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clases de medio nivel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, heads, dim_embedding, prob_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.multi_head_attention = MultiHeadAttention(heads, dim_embedding)\n",
    "        self.dropout_1 = Dropout(prob_dropout)\n",
    "        self.add_and_norm_1 = AddAndNorm(dim_embedding)\n",
    "        self.feed_forward = FeedForward(dim_embedding)\n",
    "        self.dropout_2 = Dropout(prob_dropout)\n",
    "        self.add_and_norm_2 = AddAndNorm(dim_embedding)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        multi_head_attention = self.multi_head_attention(x, x, x)\n",
    "        dropout1 = self.dropout_1(multi_head_attention)\n",
    "        add_and_norm_1 = self.add_and_norm_1(x, dropout1)\n",
    "        feed_forward = self.feed_forward(add_and_norm_1)\n",
    "        dropout2 = self.dropout_2(feed_forward)\n",
    "        add_and_norm_2 = self.add_and_norm_2(add_and_norm_1, dropout2)\n",
    "        return add_and_norm_2\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, heads, dim_embedding, Nx, prob_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(heads, dim_embedding, prob_dropout) for _ in range(Nx)])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for encoder_layer in self.encoder_layers:\n",
    "            x = encoder_layer(x)\n",
    "        return x\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, dim_embedding, max_sequence_len, heads, Nx, prob_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.input_embedding = Embedding(vocab_size, dim_embedding)\n",
    "        self.positional_encoding = PositionalEncoding(max_sequence_len, dim_embedding)\n",
    "        self.encoder = Encoder(heads, dim_embedding, Nx, prob_dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        input_embedding = self.input_embedding(x)\n",
    "        positional_encoding = self.positional_encoding(input_embedding)\n",
    "        encoder = self.encoder(positional_encoding)\n",
    "        return encoder\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, heads, dim_embedding, prob_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.masked_multi_head_attention = MultiHeadAttention(heads, dim_embedding)\n",
    "        self.dropout_1 = Dropout(prob_dropout)\n",
    "        self.add_and_norm_1 = AddAndNorm(dim_embedding)\n",
    "        self.encoder_decoder_multi_head_attention = MultiHeadAttention(heads, dim_embedding)\n",
    "        self.dropout_2 = Dropout(prob_dropout)\n",
    "        self.add_and_norm_2 = AddAndNorm(dim_embedding)\n",
    "        self.feed_forward = FeedForward(dim_embedding)\n",
    "        self.dropout_3 = Dropout(prob_dropout)\n",
    "        self.add_and_norm_3 = AddAndNorm(dim_embedding)\n",
    "    \n",
    "    def forward(self, x, encoder_output, mask=None):\n",
    "        Q = x\n",
    "        K = x\n",
    "        V = x\n",
    "        masked_multi_head_attention = self.masked_multi_head_attention(Q, K, V, mask=mask)\n",
    "        dropout1 = self.dropout_1(masked_multi_head_attention)\n",
    "        add_and_norm_1 = self.add_and_norm_1(dropout1, x)\n",
    "\n",
    "        Q = add_and_norm_1\n",
    "        K = encoder_output\n",
    "        V = encoder_output\n",
    "        encoder_decoder_multi_head_attention = self.encoder_decoder_multi_head_attention(Q, K, V)\n",
    "        dropout2 = self.dropout_2(encoder_decoder_multi_head_attention)\n",
    "        add_and_norm_2 = self.add_and_norm_2(dropout2, add_and_norm_1)\n",
    "\n",
    "        feed_forward = self.feed_forward(add_and_norm_2)\n",
    "        dropout3 = self.dropout_3(feed_forward)\n",
    "        add_and_norm_3 = self.add_and_norm_3(dropout3, add_and_norm_2)\n",
    "\n",
    "        return add_and_norm_3\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, heads, dim_embedding, Nx, prob_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([DecoderLayer(heads, dim_embedding, prob_dropout) for _ in range(Nx)])\n",
    "    \n",
    "    def forward(self, x, encoder_output, mask=None):\n",
    "        for decoder_layer in self.layers:\n",
    "            x = decoder_layer(x, encoder_output, mask)\n",
    "        return x\n",
    "\n",
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, heads, dim_embedding, Nx, vocab_size, max_sequence_len, prob_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embedding = Embedding(vocab_size, dim_embedding)\n",
    "        self.positional_encoding = PositionalEncoding(max_sequence_len, dim_embedding)\n",
    "        self.decoder = Decoder(heads, dim_embedding, Nx, prob_dropout)\n",
    "        self.linear = Linear(dim_embedding, vocab_size)\n",
    "        # self.softmax = Softmax()\n",
    "    \n",
    "    def forward(self, x, encoder_output, mask=None):\n",
    "        x = self.embedding(x)\n",
    "        x = self.positional_encoding(x)\n",
    "        x = self.decoder(x, encoder_output, mask)\n",
    "        x = self.linear(x)\n",
    "        # x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "class Linear_and_softmax(nn.Module):\n",
    "    def __init__(self, dim_embedding, vocab_size):\n",
    "        super().__init__()\n",
    "        self.linear = CustomLinear(dim_embedding, vocab_size)\n",
    "        # self.softmax = Softmax()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        # x = self.softmax(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clase de alto nivel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, src_max_seq_len, tgt_max_seq_len, dim_embedding, Nx, heads, prob_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.transformerEncoder = TransformerEncoder(src_vocab_size, dim_embedding, src_max_seq_len, heads, Nx, prob_dropout)\n",
    "        self.transformerDecoder = TransformerDecoder(heads, dim_embedding, Nx, tgt_vocab_size, tgt_max_seq_len, prob_dropout)\n",
    "        self.encoder = Encoder(heads, dim_embedding, Nx, prob_dropout)\n",
    "        self.decoder = Decoder(heads, dim_embedding, Nx, prob_dropout)\n",
    "        self.sourceEmbedding = Embedding(src_vocab_size, dim_embedding)\n",
    "        self.targetEmbedding = Embedding(tgt_vocab_size, dim_embedding)\n",
    "        self.sourcePositional_encoding = PositionalEncoding(src_max_seq_len, dim_embedding)\n",
    "        self.targetPositional_encoding = PositionalEncoding(tgt_max_seq_len, dim_embedding)\n",
    "        self.linear = Linear_and_softmax(dim_embedding, tgt_vocab_size)\n",
    "    \n",
    "    def encode(self, source):\n",
    "        embedding = self.sourceEmbedding(source)\n",
    "        positional_encoding = self.sourcePositional_encoding(embedding)\n",
    "        encoder_output = self.encoder(positional_encoding)\n",
    "        return encoder_output\n",
    "    \n",
    "    def decode(self, encoder_output, target, target_mask):\n",
    "        embedding = self.targetEmbedding(target)\n",
    "        positional_encoding = self.targetPositional_encoding(embedding)\n",
    "        decoder_output = self.decoder(positional_encoding, encoder_output, target_mask)\n",
    "        return decoder_output\n",
    "    \n",
    "    def projection(self, decoder_output):\n",
    "        linear_output = self.linear(decoder_output)\n",
    "        # softmax_output = self.softmax(linear_output)\n",
    "        return linear_output\n",
    "    \n",
    "    def forward(self, source, target, mask=None):\n",
    "        encoder_output = self.transformerEncoder(source)\n",
    "        decoder_output = self.transformerDecoder(target, encoder_output, mask)\n",
    "        return decoder_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source vocab size: 30000, target vocab size: 30000, source max sequence len: 311, target max sequence len: 311, dim_embedding: 512, heads: 8, Nx: 6, prob_dropout: 0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "source_vocab_size = tokenizer_source.get_vocab_size()\n",
    "target_vocab_size = tokenizer_target.get_vocab_size()\n",
    "src_max_seq_len = max_sequence_len\n",
    "tgt_max_seq_len = max_sequence_len\n",
    "dim_embedding = DIM_EMBEDDING\n",
    "Nx = NUM_LAYERS\n",
    "heads = NUM_HEADS\n",
    "prob_dropout = DROPOUT\n",
    "print(f\"source vocab size: {source_vocab_size}, target vocab size: {target_vocab_size}, source max sequence len: {src_max_seq_len}, target max sequence len: {tgt_max_seq_len}, dim_embedding: {dim_embedding}, heads: {heads}, Nx: {Nx}, prob_dropout: {prob_dropout}\")\n",
    "\n",
    "model = Transformer(\n",
    "    src_vocab_size = source_vocab_size,\n",
    "    tgt_vocab_size = target_vocab_size,\n",
    "    src_max_seq_len = src_max_seq_len,\n",
    "    tgt_max_seq_len = tgt_max_seq_len,\n",
    "    dim_embedding = dim_embedding,\n",
    "    Nx = Nx,\n",
    "    heads = heads,\n",
    "    prob_dropout = prob_dropout,\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data parallel\n",
    "# if torch.cuda.device_count() > 1 and GPUS > 1:\n",
    "#     number_gpus = torch.cuda.device_count()\n",
    "#     print(f\"Let's use {number_gpus} GPUs!\")\n",
    "#     transformer = nn.DataParallel(transformer)\n",
    "\n",
    "#     # def create_mask(sequence_len):\n",
    "#     #     mask = torch.tril(torch.ones((2*sequence_len, sequence_len)))\n",
    "#     #     return mask\n",
    "#     def create_mask(sequence_len):\n",
    "#         mask = torch.triu(torch.ones(1, 2*sequence_len, sequence_len), diagonal = 1).type(torch.int)\n",
    "#         return mask == 0\n",
    "# else:\n",
    "#     number_gpus = 1\n",
    "#     print(f\"Let's use {number_gpus} GPUs! GPU NUMBER: {GPU_NUMBER}\")\n",
    "    \n",
    "#     # def create_mask(sequence_len):\n",
    "#     #     mask = torch.tril(torch.ones((sequence_len, sequence_len)))\n",
    "#     #     return mask\n",
    "#     def create_mask(sequence_len):\n",
    "#         mask = torch.triu(torch.ones(1, sequence_len, sequence_len), diagonal = 1).type(torch.int)\n",
    "#         return mask == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 311, 311])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = create_mask(max_sequence_len)\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizador ✔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función de pérdida ✔"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos la función de pérdida con label smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(\n",
    "    ignore_index = tokenizer_source.token_to_id(PADDING_TOKEN), \n",
    "    label_smoothing = LABEL_SMOOTHING).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR ✔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Step():\n",
    "    def __init__(self):\n",
    "        self.step = 0\n",
    "    \n",
    "    def set_step(self, st):\n",
    "        self.step = st\n",
    "    \n",
    "    def get_step(self):\n",
    "        return int(self.step)\n",
    "\n",
    "class LearningRate():\n",
    "    def __init__(self):\n",
    "        self.lr = 0\n",
    "    \n",
    "    def set_lr(self, l_r_):\n",
    "        self.lr = l_r_\n",
    "    \n",
    "    def get_lr(self):\n",
    "        return self.lr\n",
    "\n",
    "actual_step = Step()\n",
    "actual_lr = LearningRate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_lr(step_num, dim_embeding_model=512, warmup_steps=4000):\n",
    "    step_num += 1e-7 # Avoid division by zero\n",
    "    step_num += STEP0\n",
    "    actual_step.set_step(step_num)\n",
    "    step_num_exp = -0.4\n",
    "    warmup_steps_exp = -2.6\n",
    "    dim_embeding_model_exp = -0.1\n",
    "    lr = np.power(dim_embeding_model, dim_embeding_model_exp) * np.minimum(np.power(step_num, step_num_exp), step_num * np.power(warmup_steps, warmup_steps_exp))\n",
    "    actual_lr.set_lr(lr)\n",
    "    return lr\n",
    "\n",
    "lr_lambda = lambda step: calculate_lr(step, dim_embeding_model=dim_embedding)\n",
    "if LR_SCHEDULER:\n",
    "    lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation loop ✔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(model, source, tokenizer_tgt, max_len, device, bs):\n",
    "    # Retrieving the indices from the start and end of sequences of the target tokens\n",
    "    sos_idx = tokenizer_tgt.token_to_id('[SOS]')    # Start of Sentence token index (2)\n",
    "    # eos_idx = tokenizer_tgt.token_to_id('[EOS]')    # End of Sentence token index (3)\n",
    "\n",
    "    # Computing the output of the encoder for the source sequence\n",
    "    encoder_output = model.encode(source)\n",
    "    \n",
    "    # Initializing the decoder input with the Start of Sentence token\n",
    "    decoder_input = torch.empty(bs,1).fill_(sos_idx).type_as(source).to(device)\n",
    "    \n",
    "    # Looping until the 'max_len', maximum length, is reached\n",
    "    while True:\n",
    "        if decoder_input.size(1) == max_len:\n",
    "            break\n",
    "            \n",
    "        # Building a mask for the decoder input\n",
    "        decoder_mask = create_mask(decoder_input.size(1)).to(device)\n",
    "        \n",
    "        # Calculating the output of the decoder\n",
    "        out = model.decode(encoder_output, decoder_input, decoder_mask)\n",
    "        \n",
    "        # Applying the projection layer to get the probabilities for the next token\n",
    "        prob = model.projection(out[:, -1])\n",
    "\n",
    "        # Selecting token with the highest probability\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        # decoder_input = torch.cat([decoder_input, torch.empty(1,1). type_as(source).fill_(next_word.item()).to(device)], dim=1)\n",
    "        decoder_input = torch.cat([decoder_input, next_word.unsqueeze(1)], dim=1)\n",
    "    \n",
    "    if len(decoder_input.shape) == 1:\n",
    "        decoder_input = decoder_input.unsqueeze(0)\n",
    "    elif len(decoder_input.shape) == 3:\n",
    "        decoder_input = decoder_input.squeeze(0)\n",
    "\n",
    "    return decoder_input # Sequence of tokens generated by the decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "\n",
    "def validation_loop(model, validation_ds, tokenizer_tgt, max_len, device):\n",
    "    model.eval() # Setting model to evaluation mode\n",
    "\n",
    "    # Calculating the number of batches in the validation dataset\n",
    "    dataset_size = len(validation_ds.dataset)  # Tamaño total del conjunto de datos\n",
    "    batch_size = validation_ds.batch_size      # Tamaño del batch\n",
    "    drop_last = validation_ds.drop_last        # Configuración de drop_last\n",
    "    num_batches = len(validation_ds)           # Número total de batches\n",
    "\n",
    "    # Calculating the total number of samples in the validation dataset\n",
    "    total_samples = batch_size * (num_batches - 1) + min(batch_size, dataset_size % batch_size)\n",
    "\n",
    "    # If drop_last is False and the dataset size is not divisible by the batch size, we need to add one more batch\n",
    "    if drop_last and dataset_size % batch_size != 0:\n",
    "        total_samples -= dataset_size % batch_size\n",
    "\n",
    "    # Initializing progress bar\n",
    "    progress_bar = tqdm(range(total_samples), desc = 'Processing validation examples') # Initializing progress bar\n",
    "\n",
    "    # Initializing lists to store scores\n",
    "    bleu_scores = []\n",
    "    meteor_scores = []\n",
    "    \n",
    "    # Creating evaluation loop\n",
    "    with torch.no_grad(): # Ensuring that no gradients are computed during this process\n",
    "        for batch in validation_ds:\n",
    "            # Loading input data and masks onto the GPU\n",
    "            encoder_input = batch['encoder_input'].to(device)\n",
    "            \n",
    "            # Applying the 'greedy_decode' function to get the model's output for the source text of the input batch\n",
    "            num_samples = len(batch['src_text'])\n",
    "            model_out_bs = greedy_decode(model, encoder_input, tokenizer_tgt, max_len, device, num_samples)\n",
    "\n",
    "            # Get metrics for every example in the batch\n",
    "            for i in range(num_samples):\n",
    "                source_text = batch['src_text'][i]\n",
    "                target_text = batch['tgt_text'][i]\n",
    "                model_out_i = model_out_bs[i]\n",
    "                model_out_text = tokenizer_tgt.decode(model_out_i.detach().cpu().numpy())\n",
    "\n",
    "                # Calculating metrics\n",
    "                references = [target_text.split()]\n",
    "                hypothesis = model_out_text.split()\n",
    "                bleu_score = sentence_bleu(references, hypothesis)\n",
    "                meteor_score_value = meteor_score(references, hypothesis)\n",
    "            \n",
    "                # Appending scores to lists\n",
    "                bleu_scores.append(bleu_score)\n",
    "                meteor_scores.append(meteor_score_value)\n",
    "\n",
    "                # Calculating mean scores            \n",
    "                mean_bleu_score = sum(bleu_scores)/len(bleu_scores) # Calculating mean BLEU score\n",
    "                mean_meteor_score = sum(meteor_scores)/len(meteor_scores) # Calculating mean METEOR score\n",
    "\n",
    "                # Updating progress bar and printing bleu and meteor scores\n",
    "                progress_bar.update(1)\n",
    "                progress_bar.set_postfix({'BLEU': f'{mean_bleu_score:.9f}', 'METEOR': f'{mean_meteor_score:.9f}'})\n",
    "\n",
    "    # Printing results\n",
    "    console_width = 80 # Fixed witdh for printed messages\n",
    "    print('-'*console_width)\n",
    "    print(f'SOURCE: {source_text}')\n",
    "    print(f'TARGET: {target_text}')\n",
    "    print(f'PREDICTED: {model_out_text}')\n",
    "    print('-'*console_width)\n",
    "\n",
    "    return mean_bleu_score, mean_meteor_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train loop ✔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, train_dataloader, device, tokenizer_target, epoch, loss_fn, optimizer, lr_scheduler=None):\n",
    "    # Initializing an iterator over the training dataloader\n",
    "    # We also use tqdm to display a progress bar\n",
    "    print()\n",
    "    batch_iterator = tqdm(train_dataloader, desc = f'Processing epoch {epoch:02d}')\n",
    "    \n",
    "    # For each batch...\n",
    "    for batch in batch_iterator:\n",
    "        model.train() # Train the model\n",
    "            \n",
    "        # Loading input data and masks onto the GPU\n",
    "        encoder_input = batch['encoder_input'].to(device)\n",
    "        decoder_input = batch['decoder_input'].to(device)\n",
    "        decoder_mask = batch['decoder_mask'].to(device)\n",
    "        \n",
    "        # Running tensors through the Transformer\n",
    "        encoder_output = model.encode(encoder_input)\n",
    "        decoder_output = model.decode(encoder_output, decoder_input, decoder_mask)\n",
    "        proj_output = model.projection(decoder_output)\n",
    "        \n",
    "        # Loading the target labels onto the GPU\n",
    "        label = batch['label'].to(device)\n",
    "        \n",
    "        # Computing loss between model's output and true labels\n",
    "        loss = loss_fn(proj_output.view(-1, tokenizer_target.get_vocab_size()), label.view(-1))\n",
    "        \n",
    "        # Updating progress bar, print loss and lr\n",
    "        batch_iterator.set_postfix({'loss': f'{loss.item():.6f}', 'lr': f'{actual_lr.get_lr():.9f}'})\n",
    "        \n",
    "        # Performing backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Updating parameters based on the gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Clearing the gradients to prepare for the next batch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Update step and LR\n",
    "        if LR_SCHEDULER:\n",
    "            lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 00:   0%|          | 0/534 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 00: 100%|██████████| 534/534 [05:20<00:00,  1.67it/s, loss=7.454990, lr=0.000000000]\n",
      "Processing validation examples:   0%|          | 0/324 [00:00<?, ?it/s]/home/wallabot/miniconda3/envs/cursopytorch/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/wallabot/miniconda3/envs/cursopytorch/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/wallabot/miniconda3/envs/cursopytorch/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:27<00:00,  3.72it/s, BLEU=0.000000000, METEOR=0.005262346]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: The host was a respectable-looking, middle-aged man.\n",
      "TARGET: L'oste era un uomo attempato, di aspetto rispettabile.\n",
      "PREDICTED: ,\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 01: 100%|██████████| 534/534 [05:20<00:00,  1.66it/s, loss=7.126633, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.76it/s, BLEU=0.000000000, METEOR=0.018568804] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: His father and the educationalist were both displeased with Serezha, and he really learnt badly.\n",
      "TARGET: Il padre e l’istitutore erano scontenti di Serëza, e realmente egli studiava molto male.\n",
      "PREDICTED: , , , , , , , , , , , , , , ,\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 02: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=7.055809, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.75it/s, BLEU=0.000000000, METEOR=0.022454631] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: \"Yes,\" said he, \"there is my glory and joy.\n",
      "TARGET: — Sì, — riprese, — è la mia gloria e la mia gioia.\n",
      "PREDICTED: — — , , , , , , , , , , — — —\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 03: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=6.883481, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.000000000, METEOR=0.022654181] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: I'm off to the \"infernal regions,\" added he, and walked away.\n",
      "TARGET: Vado nell’infernale — disse il colonnello e si allontanò dalla tavola.\n",
      "PREDICTED: — — , , , , , , — — — — — — — — — — — . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 04: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=6.763955, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.000000000, METEOR=0.025692245] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: 'And you are not afraid?'\n",
      "TARGET: — E non hai paura?\n",
      "PREDICTED: — E ? — ? ?\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 05: 100%|██████████| 534/534 [05:20<00:00,  1.66it/s, loss=6.808292, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.000000000, METEOR=0.022510726] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Answer: 'A chemist makes solutions which do not make anyone happy, but I have made a dissolution and made three people happy!'\n",
      "TARGET: Il monarca fa il cambio della guardia e di questo nessuno si avvantaggia ed io, invece, ho portato a termine un divorzio e tre persone ne trarranno vantaggio”.\n",
      "PREDICTED: Non , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , . , , , , , , , , , , , , , , , , , , , . , . , . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 06: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=6.765081, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000000000, METEOR=0.022986806] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: When?\n",
      "TARGET: Quando?\n",
      "PREDICTED: — E ? ? ? ? ? ? ?\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 07: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=6.569856, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:27<00:00,  3.72it/s, BLEU=0.000000000, METEOR=0.021850962] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Those who so bind themselves, and are not rapacious, ought to be honoured and loved; those who do not bind themselves may be dealt with in two ways; they may fail to do this through pusillanimity and a natural want of courage, in which case you ought to make use of them, especially of those who are of good counsel; and thus, whilst in prosperity you honour them, in adversity you do not have to fear them.\n",
      "TARGET: Quelli che si obbligano, e non sieno rapaci, si debbono onorare et amare; quelli che non si obbligano, si hanno ad esaminare in dua modi: o fanno questo per pusillanimità e defetto naturale d’animo: allora tu ti debbi servire di quelli massime che sono di buono consiglio, perché nelle prosperità te ne onori, e nelle avversità non hai da temerne.\n",
      "PREDICTED: Ma , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ,\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 08: 100%|██████████| 534/534 [05:20<00:00,  1.67it/s, loss=6.663502, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:27<00:00,  3.72it/s, BLEU=0.000000000, METEOR=0.018920476] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Kitty felt that Anna looked at her with animosity.\n",
      "TARGET: Kitty sentiva che Anna la guardava con ostilità.\n",
      "PREDICTED: Vronskij ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ a a . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 09: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=6.473949, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000000000, METEOR=0.029764121] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Those who so bind themselves, and are not rapacious, ought to be honoured and loved; those who do not bind themselves may be dealt with in two ways; they may fail to do this through pusillanimity and a natural want of courage, in which case you ought to make use of them, especially of those who are of good counsel; and thus, whilst in prosperity you honour them, in adversity you do not have to fear them.\n",
      "TARGET: Quelli che si obbligano, e non sieno rapaci, si debbono onorare et amare; quelli che non si obbligano, si hanno ad esaminare in dua modi: o fanno questo per pusillanimità e defetto naturale d’animo: allora tu ti debbi servire di quelli massime che sono di buono consiglio, perché nelle prosperità te ne onori, e nelle avversità non hai da temerne.\n",
      "PREDICTED: E , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ,\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 10: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=6.284330, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:27<00:00,  3.72it/s, BLEU=0.000000000, METEOR=0.026547362] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: It was the first time that the possibility of his wife's falling in love with anybody had occurred to him, and he was horrified.\n",
      "TARGET: Per la prima volta gli si affacciava alla mente l’ipotesi che sua moglie potesse amare un altro, ed egli inorridiva di fronte a questo.\n",
      "PREDICTED: La ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ era , era , ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ era , ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ era , era , era , era , ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ era , ’ ’ ’ ’ ’ ’ ’ era , ’ ’ ’ era , ’ ’ ’ era , era\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 11: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=6.706194, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:27<00:00,  3.72it/s, BLEU=0.000000000, METEOR=0.030342662] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: 'I didn't know it was your table,' said Alice; 'it's laid for a great many more than three.'\n",
      "TARGET: — Non sapevo che la tavola ti appartenesse, — rispose Alice; — è apparecchiata per più di tre.\n",
      "PREDICTED: — Non — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 12: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=6.580496, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000000000, METEOR=0.027670190] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: 'This is my true, almost my best friend,' he said to Vronsky. 'You too are even more near and dear to me; and I want you to be friends, and I know that you will be friendly and intimate because you are both good fellows.'\n",
      "TARGET: — È il mio sincero, forse il mio migliore amico — disse a Vronskij. — Tu per me sei ancora più prossimo e caro. E io voglio e so che voi dovete essere amici, molto amici, perché siete tutti e due brave persone.\n",
      "PREDICTED: — Non — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho non ho non ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho ho non ho non ho non ho non non non , , , , , non non , , , , , , ,\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 13: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=6.286330, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:27<00:00,  3.72it/s, BLEU=0.000000000, METEOR=0.032090710] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: 'Forgive me if my words displease you,' he said humbly.\n",
      "TARGET: — Perdonatemi se vi spiace quello che ho detto — disse umilmente.\n",
      "PREDICTED: — Non ho — disse — disse . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 14: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=6.163836, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000000000, METEOR=0.031373755] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: It's not philanthropy, it's kind-heartedness.\n",
      "TARGET: Non di filantropico, ma di cuore.\n",
      "PREDICTED: Non è è , non ’ ’ ’ ’ ’ è . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 15: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=6.288527, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000000000, METEOR=0.039227920] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: \"You are welcome to all my confidence that is worth having, Jane; but for God's sake, don't desire a useless burden!\n",
      "TARGET: — Siete la benvenuta, Jane, se volete essere a parte di quelle confidenze che sono degne di voi; ma per l'amor di Dio, non cercate di caricarvi di un fardello inutile!\n",
      "PREDICTED: — Sì , non , non , non , non , non , non , non . non . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 16: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=6.386666, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000000000, METEOR=0.041087591] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Miss Ingram, as before, was the only lady equestrian; and, as before, Mr. Rochester galloped at her side; the two rode a little apart from the rest.\n",
      "TARGET: La signorina Ingram era la sola donna a cavallo e, come il giorno prima, il signor Rochester le galoppava a fianco. Essi erano separati dagli altri.\n",
      "PREDICTED: Il signor Rochester il signor Rochester il signor Rochester , il signor Rochester , il signor Rochester , il signor Rochester , il signor Rochester , il signor il signor il signor il signor Rochester . il signor Rochester . il signor Rochester . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 17: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=6.204048, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000000000, METEOR=0.041433568] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Source: Project Gutenberg\n",
      "TARGET: Source: www.liberliber.it/Audiobook available here\n",
      "PREDICTED: \n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 18: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=5.951588, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000000000, METEOR=0.044826017] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Is it too late?\n",
      "TARGET: È troppo tardi?\n",
      "PREDICTED: È è ? ? ? ? ? ? ?\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 19: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=6.240094, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000000000, METEOR=0.046994527] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: And welcome little fishes in\n",
      "TARGET: — L'ho intesa, l'ho intesa! —\n",
      "PREDICTED: E , .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 20: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=5.922143, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000000000, METEOR=0.051898644] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Why could I never please?\n",
      "TARGET: Perché non piacevo a nessuno?\n",
      "PREDICTED: Perché mai mai mai mai ? ? ? ? ? ? ? ? ? ? ? ? ? ?\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 21: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=6.125468, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000000000, METEOR=0.054212779] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: I haven't thought about it.'\n",
      "TARGET: Non ci pensavo.\n",
      "PREDICTED: Io non non posso posso . non posso . non posso non non non non . . non non non non non . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 22: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=6.085185, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000000000, METEOR=0.058885932] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: They filled up the foreground entirely.\n",
      "TARGET: Essi occupavano completamente il primo piano.\n",
      "PREDICTED: Il il . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 23: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=5.921594, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000000000, METEOR=0.060103631] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: His father and the educationalist were both displeased with Serezha, and he really learnt badly.\n",
      "TARGET: Il padre e l’istitutore erano scontenti di Serëza, e realmente egli studiava molto male.\n",
      "PREDICTED: La marito e non non era non erano l ’ marito e che non non non non l ’ marito . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 24: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=5.754034, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000000000, METEOR=0.063966650] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Karenin was, however, so much upset that he did not at once understand the reasonableness of adultery by mutual consent and his perplexity was expressed in his looks; but the lawyer immediately helped him.\n",
      "TARGET: Aleksej Aleksandrovic era così sconvolto che non capì subito la ragionevolezza dell’adulterio ammesso per reciproco accordo e si leggeva la perplessità nel suo sguardo; ma l’avvocato gli venne subito in aiuto.\n",
      "PREDICTED: — Aleksej Aleksandrovic , Aleksej Aleksandrovic , Aleksej Aleksandrovic , ma Aleksej Aleksandrovic , ma era era era era era era era era la suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo , ma non era . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Aleksej Aleksandrovic . . Aleksej Aleksandrovic . . . . . . . . Aleksej Aleksandrovic . . Aleksej Aleksandrovic . Aleksej Aleksandrovic . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 25: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=5.951059, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000000000, METEOR=0.059367902] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: They were doing no one any harm, and everybody was pleased.\n",
      "TARGET: Non davano noia a nessuno e tutti si trovavano bene.\n",
      "PREDICTED: La , e ci ci ci ci ci ci ci ci ci erano . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 26: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=6.038142, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000000000, METEOR=0.061023352] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: 'Yes, but now it's decided,' said Anna, looking straight into Vronsky's eyes with an expression that told him he must not think of the possibility of a reconciliation.\n",
      "TARGET: — Ma ormai decisamente — disse Anna, guardando diritto negli occhi Vronskij con uno sguardo tale che gli diceva di non pensare neppure alla possibilità di una riconciliazione.\n",
      "PREDICTED: — Sì , non non non lo un occhi — disse Anna , Anna , Anna , Anna , Anna , Anna , Anna , Anna , Anna , Anna , Anna , Anna , Anna di lui di lui . gli lei . gli lei . , non non non non non non non un viso , non un viso , non un viso , gli lei , non un viso , non un viso , gli lei . , non non gli lei . , gli un viso . , non gli lei . , non gli lei . , non gli lei . , che gli , che gli , che , che gli un viso . , che gli gli un viso , gli un viso , gli un viso , non gli un suo gli gli gli gli un occhi . , che gli un suo occhi . , gli un viso . . , gli un suo . , che , che gli un viso . , che , che , , , , che , che , che , , , , , che gli un suo un suo , gli un viso , gli un suo occhi , gli un occhi , gli un occhi . , gli gli gli un occhi , non gli un occhi , gli gli un occhi . , gli un occhi . , gli gli un occhi , gli un , , , , , gli gli gli gli gli gli gli un occhi . , gli gli gli gli gli gli gli un occhi . , gli gli gli gli gli gli gli gli gli gli gli gli gli\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 27: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=5.746275, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000000000, METEOR=0.069040250] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: A splendid Midsummer shone over England: skies so pure, suns so radiant as were then seen in long succession, seldom favour even singly, our wave- girt land. It was as if a band of Italian days had come from the South, like a flock of glorious passenger birds, and lighted to rest them on the cliffs of Albion.\n",
      "TARGET: I campi intorno a Thornfield erano verdi e falciati, bianchi i sentieri per la polvere, gli alberi erano in tutto il loro splendore, le siepi e i boschi folti di fogliame e scuri, contrastavano con l'erba fresca e chiara dei prati.\n",
      "PREDICTED: La , , , , , , , , , , , , , , , , , , , , , , , , , , , , , di . di . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 28: 100%|██████████| 534/534 [05:20<00:00,  1.66it/s, loss=6.038870, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000000000, METEOR=0.068049155] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: I went to my window, opened it, and looked out. There were the two wings of the building; there was the garden; there were the skirts of Lowood; there was the hilly horizon.\n",
      "TARGET: Andai alla finestra e l'aprii guardando dinanzi a me; qui erano le due ale dell'edificio, là il giardino, poi i muri di Lowood e finalmente l'orizzonte delle montagne.\n",
      "PREDICTED: La mattina era la notte , e la notte , e la la notte , e la notte , la notte , e la la notte , la notte , e la notte , la notte , e la . la la . la . la . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . la ' . la ' . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 29: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=5.940345, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000000000, METEOR=0.066515005] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Long—long—long—many minutes, many hours, many days, have I heard it—yet I dared not—oh, pity me, miserable wretch that I am!—I dared not—I dared not speak!\n",
      "TARGET: Io, sì, che sento, ed ho sentito da molto tempo... molto, molto tempo, molti minuti, molte ore, molti giorni, ho sentito, ma non osavo... oh! pietà per me, miserabile disgraziato che sono!\n",
      "PREDICTED: Non mi , non mi , non mi , non mi , non , non , non , non , non , non , non , non . , non ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 30: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=5.484339, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000000000, METEOR=0.070652448] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: And it must be decided...'\n",
      "TARGET: E bisogna dunque decidere...\n",
      "PREDICTED: E è ... ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 31: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=5.817605, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.000000000, METEOR=0.076746501] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: \"I do not speak to the feeble, or think of them: I address only such as are worthy of the work, and competent to accomplish it.\"\n",
      "TARGET: — Non parlo dei deboli, non ci penso neppure; parlo di quelli che sono degni del compito e capaci di compierlo.\n",
      "PREDICTED: — Non posso una di , — e non non non non non non non non non non di . di . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 32: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=5.737625, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000000000, METEOR=0.077303728] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: 'C'est devenu tellement commun, les écoles,' [Schools have become so common.] answered Vronsky. 'Of course that's not the reason, but I...\n",
      "TARGET: — C’est devenu tellement commun, les écoles — disse Vronskij. — Voi capite, non è certo per questo, ma così, mi ci sono appassionato.\n",
      "PREDICTED: — Il — disse il . — Ma non , non . non non sono . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 33: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=5.543979, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000000000, METEOR=0.073924862] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: But do cats eat bats, I wonder?' And here Alice began to get rather sleepy, and went on saying to herself, in a dreamy sort of way, 'Do cats eat bats?\n",
      "TARGET: Ma i gatti, poi, mangiano i pipistrelli? — E Alice cominciò a sonnecchiare, e fra sonno e veglia continuò a dire fra i denti: — I gatti, poi, mangiano i pipistrelli?\n",
      "PREDICTED: Ma a a , — disse Alice , Alice Alice , e Alice Alice a a a a a a . ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 34: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=5.534770, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000759241, METEOR=0.074746639] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: \"Down, Pilot!\" I again said.\n",
      "TARGET: — Giù, Pilato! — ripetei.\n",
      "PREDICTED: — , — disse il signorina . , — . ! ! ! . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 35: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=5.400885, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000000000, METEOR=0.075651547] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Some men understand only the one, some only the other.\n",
      "TARGET: Alcuni comprendono l’uno, altri l’altro.\n",
      "PREDICTED: Per l ’ , l ’ l ’ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 36: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=5.612082, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000548715, METEOR=0.074436906] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: VRONSKY AND KITTY WALTZED several times round the room and then Kitty went to her mother, but hardly had she exchanged a few words with the Countess Nordston before Vronsky returned to fetch her for the first quadrille.\n",
      "TARGET: Vronskij fece qualche giro di valzer con Kitty. Dopo il valzer Kitty si avvicinò alla madre ed ebbe appena il tempo di scambiare qualche parola con la Nordston, che Vronskij era già venuta a riprenderla per la prima quadriglia.\n",
      "PREDICTED: Vronskij Vronskij , Vronskij , Vronskij , Vronskij , Vronskij , Vronskij , Vronskij , Vronskij , Vronskij , Vronskij , Vronskij , Vronskij , Vronskij , Vronskij , Vronskij , Vronskij , Vronskij , Vronskij , Vronskij , Vronskij , Vronskij , Vronskij , Vronskij , Vronskij a Vronskij a Vronskij . Vronskij da Vronskij . Vronskij . Vronskij . da Vronskij . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 37: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=5.517783, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000472538, METEOR=0.073652363] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Oh, how delightful it was to be safe in the boat, after our trials and fears!\n",
      "TARGET: Che delizia ci sembrò trovarci al sicuro nella barca, dopo tutte le nostre fatiche e i nostri timori!\n",
      "PREDICTED: Oh , la mia vita , la mia vita , la mia vita , la vita , la vita , e la vita , la vita , la vita . , se era la vita , se la vita , se la vita , la vita , la vita , la vita ! , se la vita ! , se la vita ! , se la vita ! , se la vita ! , se la vita ! , se la vita ! , la vita ! , la vita ! , la vita ! , la vita ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 38: 100%|██████████| 534/534 [05:20<00:00,  1.66it/s, loss=5.579816, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000391164, METEOR=0.079746483] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: You had better change your frock now; I will go with you and fasten it.\n",
      "TARGET: Fareste bene a vestirvi ora. Vi aiuterò io.\n",
      "PREDICTED: Ho da voi e io io io io io io io io io io io io da . io io io io io io io io voi . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 39: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=5.707530, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000654340, METEOR=0.080604120] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Both were men respected for their characters and abilities.\n",
      "TARGET: Erano persone stimabili per carattere e per ingegno.\n",
      "PREDICTED: Le erano e erano . i loro . . . . . . . . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 40: 100%|██████████| 534/534 [05:20<00:00,  1.66it/s, loss=5.609801, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000628045, METEOR=0.082064763] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Anna now acknowledged to herself that he was weary of her and would regret giving up his freedom to return to her; yet in spite of this she was glad that he would come.\n",
      "TARGET: Adesso Anna riconosceva già ch’egli sentiva il peso di lei, che lasciava con rammarico la propria libertà per tornare da lei, e, malgrado questo, era contenta che egli sarebbe tornato.\n",
      "PREDICTED: Anna Anna , Anna , Anna , Anna , Anna , Anna , Anna , Anna , per più più più più più più più più più più . più . . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 41: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=5.453038, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000240156, METEOR=0.078863257] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Some men understand only the one, some only the other.\n",
      "TARGET: Alcuni comprendono l’uno, altri l’altro.\n",
      "PREDICTED: Per l ’ altro , l ’ uno un ’ , ma non si . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 42: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=5.309184, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000821535, METEOR=0.085583597] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: \"He says she'll not be here long.\"\n",
      "TARGET: — Che Elena non rimarrà qui per molto tempo.\n",
      "PREDICTED: — Non posso . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 43: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=5.384903, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000715000, METEOR=0.080843484] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Alas! it was too late to wish that!\n",
      "TARGET: Oimè! troppo tardi!\n",
      "PREDICTED: Oh ! ! ! ! è così così così ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 44: 100%|██████████| 534/534 [05:20<00:00,  1.66it/s, loss=5.430720, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000989620, METEOR=0.084993299] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: They had to submit, for although all the doctors studied in the same schools and from the same books and knew the same sciences, and though some said that this celebrated man was a bad doctor, at the Princess Shcherbatskaya's and in her set it was for some reason assumed that he alone had a quite special knowledge and he alone could save Kitty.\n",
      "TARGET: Era necessario piegarvisi, perché, sebbene anche gli altri medici avessero frequentato la stessa scuola e studiato sugli stessi libri e tutti fossero in possesso di una stessa scienza, e pur avendo costui presso alcuni fama di medico inetto, tuttavia nella casa della principessa e nella sua cerchia, chi sa perché, si riteneva che solo questo medico famoso sapesse qualcosa di speciale e solo lui potesse salvare Kitty.\n",
      "PREDICTED: il tempo , e il tempo , il tempo , e , il tempo , il tempo , gli erano il tempo , e il tempo il tempo , gli erano la cosa gli stesso cosa il tempo , gli stesso cosa gli stesso cosa gli stesso cosa , gli stesso , e , gli stesso stesso stesso stesso , gli stesso il tempo , gli stesso il tempo che gli stesso il tempo , gli stesso la cosa la cosa il tempo , e gli stesso , gli stesso , gli stesso il tempo il tempo il tempo , gli stesso . che gli stesso , non era la cosa il tempo , gli poteva stesso stesso stesso , gli stesso cosa la cosa la cosa la cosa la cosa la cosa la cosa la cosa la cosa la cosa la cosa . . . . , non poteva stesso . , non era nulla . , non gli stesso cosa , non poteva stesso cosa . il cosa gli stesso stesso . , non era gli stesso . . . . , non gli stesso . , non era nulla , non era stesso stesso , non era stesso cosa stesso cosa stesso stesso . gli stesso . gli stesso . , non era nulla , non era gli poteva non era gli stesso stesso stesso stesso stesso , non era gli stesso . , non era mai stesso . , non era . , non era . , non poteva stesso stesso . , non era . , non era . . , non era . , non era . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 45: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=5.307698, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.000804093, METEOR=0.082072234] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: His father from his point of view considered that the boy did not try to learn what he was being taught.\n",
      "TARGET: Secondo il padre, egli non voleva apprendere quello che gli insegnavano.\n",
      "PREDICTED: Il padre che era il suo suo suo suo suo suo suo suo suo suo suo suo suo padre , ma non aveva stato stato stato stato . che era stato il suo suo suo suo suo ’ anima . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 46: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=5.059835, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000976414, METEOR=0.084584478] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: However, I put myself into the same position for an attack that I had formerly provided, and was just ready for action, if anything had presented.\n",
      "TARGET: Pur finalmente mi collocai in tutta quell’attitudine d’assalto cui m’era già disposto, e mi trovava già presto alla battaglia se alcun che fosse avvenuto.\n",
      "PREDICTED: che io io , io , io , io , io , io , io , io , , , io la tempo , io , , io , , io , io , , , io , io , , io , , io , , io , , io la tempo la tempo la tempo la tempo la la la la la la la la . la vita la vita la vita la vita , io la vita , io la vita , io la vita , io la vita , io la vita , io la vita , io la vita , io la vita , io la vita , la vita , la vita , io la vita , , la vita , la vita la vita , , , , , , , , , , , , , . , io , io , io , per , io la vita , io la vita , io , per la vita , per , per , per la vita , per , per , per , per , io la vita , per , io , io , io , io , io , io , io , , , , , , , , , , per , per , per , per , per . , per , per la vita , per la vita , per la , per , per , per , per\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 47: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=5.422140, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.001030025, METEOR=0.081631866] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: As she said this, she looked up, and there was the Cat again, sitting on a branch of a tree.\n",
      "TARGET: Mentre diceva così guardò in su, e vide di nuovo il Gatto, seduto sul ramo d'un albero.\n",
      "PREDICTED: Se il momento si di un po ' di un po ' di un po ' di piedi , — disse il corridoio , con il corridoio , di nuovo di nuovo . di nuovo di nuovo . di nuovo di nuovo . . . . di nuovo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . : . . . . : . . . : : : : : : : : : : : : : : : : : : : : : : :\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 48: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=5.200831, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000989620, METEOR=0.085547880] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: \"I wish,\" continued the good lady, \"you would ask her a question or two about her parents: I wonder if she remembers them?\"\n",
      "TARGET: — Vorrei, — continuò la buona signora, — che le faceste qualche domanda sui suoi genitori, per vedere se se ne rammenta.\n",
      "PREDICTED: — È la signorina di me — disse la signorina la signorina la signorina , — — che non avete detto la signorina la signorina la signorina . che avete ? ? ? ? ? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 49: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=5.101494, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.001085917, METEOR=0.087165970] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: \"A fig for Rizzio!\" cried she, tossing her head with all its curls, as she moved to the piano.\n",
      "TARGET: — Non m'importa nulla di Rizzio! — esclamò scrollando gli abbondanti ricci bruni e accostandosi al pianoforte.\n",
      "PREDICTED: — Oh ! — disse , , con un sorriso , , con i suoi occhi , . ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 50: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=5.358016, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.001096318, METEOR=0.088126936] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: And in the beginning of their expansion on land, through not having much territory, and because of their great reputation, they had not much to fear from their captains; but when they expanded, as under Carmignuola, they had a taste of this mistake; for, having found him a most valiant man (they beat the Duke of Milan under his leadership), and, on the other hand, knowing how lukewarm he was in the war, they feared they would no longer conquer under him, and for this reason they were not willing, nor were they able, to let him go; and so, not to lose again that which they had acquired, they were compelled, in order to secure themselves, to murder him.\n",
      "TARGET: E nel principio dello augumento loro in terra, per non vi avere molto stato e per essere in grande reputazione, non aveano da temere molto de' loro capitani; ma, come ellino ampliorono, che fu sotto el Carmignola, ebbono uno saggio di questo errore. Perché, vedutolo virtuosissimo, battuto che ebbono sotto il suo governo el duca di Milano, e conoscendo da altra parte come elli era raffreddo nella guerra, iudicorono con lui non potere più vincere, perché non voleva, né potere licenziarlo, per non riperdere ciò che aveano acquistato; onde che furono necessitati, per assicurarsene, ammazzarlo.\n",
      "PREDICTED: E che di , che , a , che , a , che a , a , che a a , , a , che a a a a a a , , , , , che non a , a a a a a a . che non a , non , non a a a . a , non , non . a . a , non . . a . , non . che non , non . a . a . a . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . il . che non . . che non si . , non si , non si , non si , non si , non si , non si , non si , non si , non si , non si , non si , non si , non si\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 51: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=5.131818, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.001206761, METEOR=0.086570422] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: It brings him also no profit, but pure loss.'\n",
      "TARGET: Anche senza tornaconto. Proprio in perdita.\n",
      "PREDICTED: Per bene , ma è bene , ma più più più , ma più più più . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 52: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=4.973727, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.001107537, METEOR=0.088572539] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Anna smiled – and the smile passed on to him; she became thoughtful – and he became serious.\n",
      "TARGET: Anna rideva e il riso si trasmetteva a lui. Anna diveniva pensosa, ed egli si faceva serio.\n",
      "PREDICTED: Vronskij si alzò , e si alzò a un sorriso , e si alzò , si alzò a un sorriso . a un sorriso . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 53: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=5.054494, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000322074, METEOR=0.092170673] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: He went to Millcote this morning, and will be back here to-night or to-morrow: does that circumstance exclude him from the list of your acquaintance--blot him, as it were, out of existence?\"\n",
      "TARGET: È andato a Millcote stamani e tornerà stasera o domani; è questa circostanza forse che v'impedisce di conoscerlo?\n",
      "PREDICTED: La volta di di quella volta , che la notte , e la notte di di , che vi la vita di , e la vita di ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 54: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=5.152965, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.001085917, METEOR=0.090279597] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: You had better change your frock now; I will go with you and fasten it.\n",
      "TARGET: Fareste bene a vestirvi ora. Vi aiuterò io.\n",
      "PREDICTED: Ecco , io io io io io , e io io io ha a casa . io .... .... .... .... . . . . . . . , io .... , io , io .... , io , io .... , io .... , io , io , io , io .... , io .... .... .... .... .... .... .... .... .... .... .... .... .... .... .... .... .... .... .... ....\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 55: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=5.043926, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.001132848, METEOR=0.091090085] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: When?\n",
      "TARGET: Quando?\n",
      "PREDICTED: Quando ?\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 56: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=4.925776, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.001505825, METEOR=0.094466027] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: You know, I thought of coming to the meadow to have a look at you, but it was so unbearably hot that I got only as far as the forest!\n",
      "TARGET: Avrei voluto venire alla fienagione per vederti, ma il caldo era così insopportabile che non sono andato più in là del bosco.\n",
      "PREDICTED: Vi ho stato così che ci che ci di quel giorno , ma che ci che ci che ci che ci . che ci da . . . . per . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 57: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=5.266925, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.001505825, METEOR=0.091826037] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: The other horses, also alarmed, splashed through the water with their hobbled feet, making a sound of slapping as they drew their hoofs out of the thick clayey mud, and began floundering their way out of the marsh.\n",
      "TARGET: Gli altri cavalli si spaventarono anch’essi e, sguazzando per l’acquitrino con le zampe impastoiate e producendo con gli zoccoli tirati su dall’argilla spessa un suono simile a uno schiocco, si misero a saltar fuori della palude.\n",
      "PREDICTED: l ’ erba , a , l ’ erba , l ’ erba , l ’ erba , l ’ erba , di , l ’ erba , l ’ erba , l ’ erba , l ’ erba di l ’ erba . l ’ erba , l ’ erba . a . l ’ erba . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 58: 100%|██████████| 534/534 [05:20<00:00,  1.66it/s, loss=5.117222, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.001388456, METEOR=0.090037723] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: By-and-by a small boat came in sight, towed through the water at a tremendous pace by a powerful barge horse, on which sat a very small boy.\n",
      "TARGET: Venne a poco a poco in vista una barchetta, rimorchiata a un terribile passo, da un enorme cavallo montato da un ragazzotto.\n",
      "PREDICTED: a un ’ altra barca , in un ’ altra , di un ’ altra , , di un ’ altra , , di un ’ altra , di un ’ altra . di un ’ altra . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 59: 100%|██████████| 534/534 [05:20<00:00,  1.66it/s, loss=5.079746, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.001184984, METEOR=0.091529148] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Our books—the books which, for years, had formed no small portion of the mental existence of the invalid—were, as might be supposed, in strict keeping with this character of phantasm.\n",
      "TARGET: I nostri libri, – i libri che da anni costituivano una gran parte dell'esistenza spirituale dei malato, erano, si capisce, in accordo perfetto con quel carattere da visionario.\n",
      "PREDICTED: La mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia . Non ’ mia .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 60: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=5.104509, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.001696179, METEOR=0.096130099] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: They filled up the foreground entirely.\n",
      "TARGET: Essi occupavano completamente il primo piano.\n",
      "PREDICTED: Il suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo ’ suo suo suo suo suo ’ suo suo suo ’ suo ’ suo ’ suo suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 61: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=4.762044, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.001257641, METEOR=0.095785659] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Completely to regain her composure, she went to the nursery and spent the evening with her son. She put him to bed herself, made the sign of the cross over him, and tucked him up.\n",
      "TARGET: Per rasserenarsi completamente era andata nella camera del bambino e aveva passato tutta la serata col figlio; lo aveva messo lei stessa a letto, gli aveva fatto il segno della croce e gli aveva rimboccato le coperte.\n",
      "PREDICTED: Ella il suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo ’ suo suo suo suo suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ suo ’ suo ’ ’ ’ ’ ’ ’ ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ ’ suo ’ suo ’ suo ’ suo ’ suo ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ suo ’ suo ’ ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ ’ ’ ’ ’ ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’ suo ’\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 62: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=5.173316, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.000322074, METEOR=0.092616587] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Titus whetted his own and Levin's, and they began mowing again.\n",
      "TARGET: Tit finì di affilare la falce sua e quella di Levin, e insieme proseguirono.\n",
      "PREDICTED: E Levin Levin cominciò a Levin , e gli altri di Levin . gli mise a Levin . a Levin . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 63: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=5.043116, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.000369338, METEOR=0.091653416] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: You know, I thought of coming to the meadow to have a look at you, but it was so unbearably hot that I got only as far as the forest!\n",
      "TARGET: Avrei voluto venire alla fienagione per vederti, ma il caldo era così insopportabile che non sono andato più in là del bosco.\n",
      "PREDICTED: Vi ho detto che ci che ci che ci di quel padrone , ma ci che ci in quel padrone di quel padrone di quel padrone , e ci . che ci da . un po ' ora . da da quel giorno . . . da quel giorno . . . . . . . che che che che che così che ci che ci da . che ci . . . da . . da quel giorno . . . . . . . . . che che che che che che che che che che che che che che che che che che che che che che che che ci per per per che che che che che che che che che che che che che che che ci per per per per per che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 64: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=5.385884, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.001243292, METEOR=0.098406837] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: They sent for one of Oblonsky's, but it was much too wide and too short.\n",
      "TARGET: Avevano mandato da Stepan Arkad’ic e avevano portato una camicia; ma era stretta e corta in modo impossibile.\n",
      "PREDICTED: Il suo vecchio era stato , ma Stepan Arkad ’ ic era stato stato da Stepan Arkad ’ ic e non era stato . solo come non solo . . . . . . . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 65: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=4.770373, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.000349641, METEOR=0.099807625] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Alice guessed in a moment that it was looking for the fan and the pair of white kid gloves, and she very good-naturedly began hunting about for them, but they were nowhere to be seen--everything seemed to have changed since her swim in the pool, and the great hall, with the glass table and the little door, had vanished completely.\n",
      "TARGET: Ma invano. Tutto sembrava trasformato dal momento che era caduta nello stagno; e la gran sala col tavolino di cristallo, e la porticina erano interamente svanite.\n",
      "PREDICTED: Alice era una porta di silenzio e il silenzio , ma non era una porta di una porta di ; ma non era una porta di una porta di una porta e poi non era una porta di una porta ; ma non era una porta di una porta di a una porta e non era una porta , ma non era a a . a a a : a nuovo : a nuovo . a nuovo Alice . la porta . la porta . la porta . : di . : : la porta . : . : la porta . : : : la porta . la porta . di . . . . . . . . . di silenzio . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 66: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=5.232784, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.001058874, METEOR=0.092655137] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: The cry died, and was not renewed.\n",
      "TARGET: Ma il grido non si fece più udire.\n",
      "PREDICTED: La porta non era di nuovo di nuovo . non la porta . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 67: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=4.876164, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.000489028, METEOR=0.096312224] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Just as you get your side beautifully fixed, he gives it a hoist from his end, and spoils it all.\n",
      "TARGET: Nel momento che l’avete bravamente fissata dal lato vostro, egli la solleva per il lembo che ha in mano lui, e guasta tutto.\n",
      "PREDICTED: E , , , , , , , , , , la volta la il un uomo di di Levin . il , il la , il , la la , la , la , la , la , la di di . , la , la , la , la , la , di . , la , la , la , la . , la , la , la , la , la . , la , la . , la . , la , la . , la , , la , , . . . , , , . . , , , , , . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 68: 100%|██████████| 534/534 [05:20<00:00,  1.66it/s, loss=4.916807, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.001432986, METEOR=0.096081391] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Not like some of us!'\n",
      "TARGET: Non così noi!\n",
      "PREDICTED: — Ma è un ’ . ! ! .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 69: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=4.982673, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.000440191, METEOR=0.096053498] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: 'Forgive me if my words displease you,' he said humbly.\n",
      "TARGET: — Perdonatemi se vi spiace quello che ho detto — disse umilmente.\n",
      "PREDICTED: — come , — disse il , — voi . ! ! . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 70: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=5.012870, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.000403597, METEOR=0.099915188] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: As in former years, at the beginning of the spring he went abroad to recuperate his health, which was upset each year by the winter's work.\n",
      "TARGET: All’inizio della primavera andò all’estero per fare una cura di acque termali che ristabilisse la salute sua debilitata ogni anno dallo sforzo invernale.\n",
      "PREDICTED: La prima prima prima , in campagna , in campagna , in campagna , in campagna , l ’ anno era l ’ anno l ’ anno di campagna . l ’ anno l ’ anno in campagna . l ’ anno . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 71: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=4.744622, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.000296762, METEOR=0.095241855] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: 'Yes, but in what direction?' asked Karenin. 'Toward getting things done, or toward changing what has been done already?\n",
      "TARGET: — Sì, ma a che è diretta la sua attività? — disse Aleksej Aleksandrovic. — Ad agire o a ricalcare quello che è stato fatto?\n",
      "PREDICTED: — Sì , ma che c ’ è il tempo ? — disse Aleksej Aleksandrovic . — Sì , che si era ancora ancora il tempo che si era ? ? ? ? ? ? ? ?\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 72: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=4.738067, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.000296762, METEOR=0.098950531] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Seeing his hat on the hat-rail, she shuddered with aversion.\n",
      "TARGET: Visto il cappello di lui all’attaccapanni, rabbrividì di repulsione.\n",
      "PREDICTED: Egli sollevò un sguardo sulla fronte , con un sguardo , con lui . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 73: 100%|██████████| 534/534 [05:20<00:00,  1.66it/s, loss=4.609487, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.000349641, METEOR=0.100320465] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: \"So much?\" was the doubtful answer; and he prolonged his scrutiny for some minutes. Presently he addressed me--\"Your name, little girl?\"\n",
      "TARGET: — Non pare che ne abbia tanti, — osservò in tono di dubbio, e prolungò per alcuni minuti il mio esame; poi, dirigendosi a me, disse: — Come vi chiamate, piccina?\n",
      "PREDICTED: — Mi dissi : — John , — mi è un ' altra voce , che mi è forse per me , ma mi è un ' altra ? ? ? ? ?\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 74: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=4.554029, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.000459248, METEOR=0.092759694] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Hardly knowing what she did, she picked up a little bit of stick, and held it out to the puppy; whereupon the puppy jumped into the air off all its feet at once, with a yelp of delight, and rushed at the stick, and made believe to worry it; then Alice dodged behind a great thistle, to keep herself from being run over; and the moment she appeared on the other side, the puppy made another rush at the stick, and tumbled head over heels in its hurry to get hold of it; then Alice, thinking it was very like having a game of play with a cart-horse, and expecting every moment to be trampled under its feet, ran round the thistle again; then the puppy began a series of short charges at the stick, running a very little way forwards each time and a long way back, and barking hoarsely all the while, till at last it sat down a good way off, panting, with its tongue hanging out of its mouth, and its great eyes half shut.\n",
      "TARGET: Per far la disinvolta, prese un ramoscello e lo presentò al cagnolino; il quale diede un balzo in aria come una palla con un latrato di gioia, e s'avventò al ramoscello come per sbranarlo. Allora Alice si mise cautamente dietro un cardo altissimo per non esser travolta; quando si affacciò dall'altro lato, il cagnolino s'era avventato nuovamente al ramoscello, ed aveva fatto un capitombolo nella furia di afferrarlo.\n",
      "PREDICTED: Non fosse un po ' di un po ' , e un po ' di un po ' di di , un , un di , e , di un , , di un , e di un , di un , e a un , a un tratto di un tratto di un tratto il cavallo , il cavallo il cavallo . il cavallo , il cavallo , il cane , il cane di un tratto di un tratto , il il cane . , di un tratto di , il . , il , il : il . il il . il il il il . il . di un . . , , , , di un . il il il il . il il il cane . il cane . il cane il cane il cane il cane il cane di un il cane di un il cane di un . il cane di un . . di un di un . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 75: 100%|██████████| 534/534 [05:20<00:00,  1.66it/s, loss=4.569966, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.000349641, METEOR=0.099907307] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: She felt that it was impossible for her to leave; but still deceiving herself, she went an sorting the things and pretending that she really would go.\n",
      "TARGET: Sentiva che non era possibile andar via; ma, ingannando se stessa, preparava la roba e si fingeva di partire.\n",
      "PREDICTED: Per quanto si poteva , ma si poteva a lei , ma si poteva lei si poteva a lei e di lei si poteva lei . . . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 76: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=4.805644, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.000349641, METEOR=0.099480811] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: 'Well, and what did you think about me?\n",
      "TARGET: — Ma cosa pensavi mai di me?\n",
      "PREDICTED: — Be ’, che hai fatto e questo ? ? ? ? ?\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 77: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=4.703836, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.000321036, METEOR=0.104446888] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: It was about two hours before night when, our guide being something before us, and not just in sight, out rushed three monstrous wolves, and after them a bear, from a hollow way adjoining to a thick wood; two of the wolves made at the guide, and had he been far before us, he would have been devoured before we could have helped him; one of them fastened upon his horse, and the other attacked the man with such violence, that he had not time, or presence of mind enough, to draw his pistol, but hallooed and cried out to us most lustily.\n",
      "TARGET: Due ore quasi prima di sera il conduttore nel precederci s’era alquanto scostato da noi, onde lo avevamo perduto di vista, allorchè sbucarono dal folto di una contigua selva tre enormi lupi, e dietro ad essi un orso. Due di questi lupi investirono la guida e buon per lei che non ci era andata avanti di tanto, poichè certo sarebbe stata divorata prima che avessimo potuto correre in suo aiuto.\n",
      "PREDICTED: Era vero che il nostro nostro nostro nostro nostro nostro nostro di da da , ma a da da , a da un po ’ da vero , e a a a a . E i due ore da vero da vero da vero da vero da vero da vero a vero a , ma tre giorni , , ma tre giorni a , a a . il nostro ’ ora tre due due due , ma a noi il nostro . il nostro . il nostro . , ma poi , ma non si a . , ma non si . , ma non si a a . a . , ma non si . a . a . a . a . a . a . a . a . . . . . . . . . . . . . . . . . . . . . . . il nostro . , , , a . a . . . . . a . a . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 78: 100%|██████████| 534/534 [05:20<00:00,  1.66it/s, loss=4.684855, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.000275903, METEOR=0.102954480] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: But I, and all her relatives, who all love her, beg and implore you!\n",
      "TARGET: Ma io, noi tutti parenti, tutti quelli che le vogliono bene, ti preghiamo, ti supplichiamo.\n",
      "PREDICTED: Ma come le donne sono così e le donne della propria donna , le donne , le donne sono così così così così così ! ! ! . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 79: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=4.580578, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.000308422, METEOR=0.097587143] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: 'If, as in former elections, all the districts nominated the Provincial Marshal, he would be elected, receiving white balls from every one.\n",
      "TARGET: Se tutti i distretti, come nelle elezioni passate, avessero pregato il maresciallo del governatorato, l’avrebbero eletto con tutte palle bianche.\n",
      "PREDICTED: “ Da quel tempo , del nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro anno hanno le giovani del governatorato , e le città del governatorato del governatorato , del governatorato del governatorato . del governatorato , è a città , del governatorato , del governatorato , del governatorato , del governatorato , del nostro tempo , del nostro tempo , del tempo , del nostro anno , del nostro anno , del nostro ’ hanno , del nostro ’ hanno , del nostro ’ hanno , del nostro ’ hanno , del nostro ’ hanno , del nostro ’ anno , del anno , del nostro ’ anno , del anno del ’ anno del ’ anno del ’ anno del ’ anno del ’ anno del ’ anno del ’ del ’ del ’ anno del ’ . del ’ del ’ . del ’ del ’ del ’ del ’ del ’ . del ’ del ’ del ’ . del ’ del ’ del ’ del ’ del ’ del ’ del ’ del ’ del ’ del ’ del ’ del ’ del ’ ’ ’ ’ ’ ’ ’ ’ ’ del ’ del ’ ’ ’ ’ ’ del ’ del ’ del ’ del ’ del ’ del ’ del ’ del ’ del ’ del ’ ’ ’ ’ del ’ del ’ ’ ’ del ’ del ’ del ’ del ’ ’ ’ del ’ ’ ’ ’ del ’ del ’ del ’ del ’ del ’ del ’\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 80: 100%|██████████| 534/534 [05:20<00:00,  1.66it/s, loss=4.866529, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.000349641, METEOR=0.099469817] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: 'I didn't know it was your table,' said Alice; 'it's laid for a great many more than three.'\n",
      "TARGET: — Non sapevo che la tavola ti appartenesse, — rispose Alice; — è apparecchiata per più di tre.\n",
      "PREDICTED: — Non sono molto molto più , — rispose Alice , — ma la città di un po ' di tre anni di tre volte di tre volte . come non sono più di più . in mare . in meglio in meglio . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 81: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=4.530243, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.000296762, METEOR=0.103318696] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: \"I am disposed to be gregarious and communicative to-night,\" he repeated, \"and that is why I sent for you: the fire and the chandelier were not sufficient company for me; nor would Pilot have been, for none of these can talk.\n",
      "TARGET: Il fuoco o il lume non erano compagni adatti e Pilato neppure, perché non parla. In quanto a Adele non poteva soddisfarmi e lo stesso debbo dire della signora Fairfax.\n",
      "PREDICTED: — E non sono più più di me , — disse . E un po ' di camera , — e in una donna di per me ; ma non sono più in una donna di e i suoi bambini . E non sono più più . di . di lei . , non sono più in un momento . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 82: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=4.733610, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.000349641, METEOR=0.104839323] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: If you had not promised before, she would have grown reconciled to her position and have gone on living in the country.\n",
      "TARGET: Se tu non avessi promesso prima, lei si sarebbe adattata alla sua situazione, avrebbe vissuto in campagna.\n",
      "PREDICTED: Se non posso pensare a non pensare — ella disse a lei , e Levin non aveva la vita a lei di lei , le aveva lasciato la vita . di lei . a lei . . a lei . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 83: 100%|██████████| 534/534 [05:20<00:00,  1.66it/s, loss=4.855294, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.000308422, METEOR=0.102128042] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Miss Ingram, as before, was the only lady equestrian; and, as before, Mr. Rochester galloped at her side; the two rode a little apart from the rest.\n",
      "TARGET: La signorina Ingram era la sola donna a cavallo e, come il giorno prima, il signor Rochester le galoppava a fianco. Essi erano separati dagli altri.\n",
      "PREDICTED: Saint - John Ingram non aveva una signorina Ingram di una signorina Ingram con un poco Ingram e due due due due due due due due due due due Ingram . Ingram . Ingram . . il signor Rochester . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 84: 100%|██████████| 534/534 [05:20<00:00,  1.66it/s, loss=4.846244, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.000334728, METEOR=0.102582850] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: George stirred it all up, and then he said that there seemed to be a lot of room to spare, so we overhauled both the hampers, and picked out all the odds and ends and the remnants, and added them to the stew.\n",
      "TARGET: Giorgio rimescolò il tutto, e poi, avendo osservato che vi rimaneva tant’altro spazio, frugammo nelle due ceste, e ne cavammo quante ne potemmo cavare, per aggiungerle allo stufato.\n",
      "PREDICTED: Giorgio disse a noi ci era più , e noi noi ci , e noi noi ci era in noi . Giorgio ci ci ci ci ci ci era in noi , e noi Giorgio ci era un po ’ di noi . di noi ci disse . . a noi . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 85: 100%|██████████| 534/534 [05:21<00:00,  1.66it/s, loss=4.705526, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.000334728, METEOR=0.102161198] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Completely to regain her composure, she went to the nursery and spent the evening with her son. She put him to bed herself, made the sign of the cross over him, and tucked him up.\n",
      "TARGET: Per rasserenarsi completamente era andata nella camera del bambino e aveva passato tutta la serata col figlio; lo aveva messo lei stessa a letto, gli aveva fatto il segno della croce e gli aveva rimboccato le coperte.\n",
      "PREDICTED: In il letto , il suo letto , l ’ aveva la testa , e il suo suo letto , non aveva ancora , l ’ orologio , e non l ’ aveva , l ’ altra , non poteva il suo suo suo suo suo suo suo suo suo suo suo suo pensiero . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 86:  97%|█████████▋| 520/534 [05:13<00:08,  1.66it/s, loss=4.605704, lr=0.000000000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m     train_loop(model, train_dataloader, device, tokenizer_target, epoch, loss_fn, optimizer, lr_scheduler)    \n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# # Initializing an iterator over the training dataloader\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# # We also use tqdm to display a progress bar\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# print()\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# We run the 'run_validation' function at the end of each epoch\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# to evaluate model performance\u001b[39;00m\n\u001b[1;32m     53\u001b[0m validation_loop(model, validation_dataloader, tokenizer_target, max_sequence_len, device)\n",
      "Cell \u001b[0;32mIn[38], line 22\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(model, train_dataloader, device, tokenizer_target, epoch, loss_fn, optimizer, lr_scheduler)\u001b[0m\n\u001b[1;32m     19\u001b[0m proj_output \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mprojection(decoder_output)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Loading the target labels onto the GPU\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Computing loss between model's output and true labels\u001b[39;00m\n\u001b[1;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(proj_output\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, tokenizer_target\u001b[38;5;241m.\u001b[39mget_vocab_size()), label\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in range(0, EPOCHS):\n",
    "    if LR_SCHEDULER:\n",
    "        train_loop(model, train_dataloader, device, tokenizer_target, epoch, loss_fn, optimizer, lr_scheduler)    \n",
    "    else:\n",
    "        train_loop(model, train_dataloader, device, tokenizer_target, epoch, loss_fn, optimizer)\n",
    "    # # Initializing an iterator over the training dataloader\n",
    "    # # We also use tqdm to display a progress bar\n",
    "    # print()\n",
    "    # batch_iterator = tqdm(train_dataloader, desc = f'Processing epoch {epoch:02d}')\n",
    "    \n",
    "    # # For each batch...\n",
    "    # for batch in batch_iterator:\n",
    "    #     model.train() # Train the model\n",
    "        \n",
    "    #     # Loading input data and masks onto the GPU\n",
    "    #     encoder_input = batch['encoder_input'].to(device)\n",
    "    #     decoder_input = batch['decoder_input'].to(device)\n",
    "    #     decoder_mask = batch['decoder_mask'].to(device)\n",
    "        \n",
    "    #     # Running tensors through the Transformer\n",
    "    #     encoder_output = model.encode(encoder_input)\n",
    "    #     decoder_output = model.decode(encoder_output, decoder_input, decoder_mask)\n",
    "    #     proj_output = model.projection(decoder_output)\n",
    "        \n",
    "    #     # Loading the target labels onto the GPU\n",
    "    #     label = batch['label'].to(device)\n",
    "        \n",
    "    #     # Computing loss between model's output and true labels\n",
    "    #     loss = loss_fn(proj_output.view(-1, tokenizer_target.get_vocab_size()), label.view(-1))\n",
    "        \n",
    "    #     # Updating progress bar, print loss and lr\n",
    "    #     batch_iterator.set_postfix({'loss': f'{loss.item():.6f}', 'lr': f'{actual_lr.get_lr():.9f}'})\n",
    "        \n",
    "    #     # Update LR\n",
    "        \n",
    "    #     # Performing backpropagation\n",
    "    #     loss.backward()\n",
    "        \n",
    "    #     # Updating parameters based on the gradients\n",
    "    #     optimizer.step()\n",
    "        \n",
    "    #     # Clearing the gradients to prepare for the next batch\n",
    "    #     optimizer.zero_grad()\n",
    "\n",
    "    #     # Update step and LR\n",
    "    #     if LR_SCHEDULER:\n",
    "    #         lr_scheduler.step()\n",
    "        \n",
    "    # We run the 'run_validation' function at the end of each epoch\n",
    "    # to evaluate model performance\n",
    "    validation_loop(model, validation_dataloader, tokenizer_target, max_sequence_len, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cursopytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
