{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BS: 60\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Dataset\n",
    "SOURCE_LANGUAGE = \"en\"\n",
    "TARGET_LANGUAGE = \"it\"\n",
    "SUBSET = False\n",
    "PERCENT_SUBSET = 0.1\n",
    "\n",
    "# Train\n",
    "EPOCH0 = 0\n",
    "STEP0 = 0\n",
    "LR = 1e-5\n",
    "EPOCHS = 100000\n",
    "GPUS = 1\n",
    "GPU_NUMBER = 0\n",
    "if GPUS > 1:\n",
    "    BS = 120\n",
    "else:\n",
    "    if SUBSET:\n",
    "        BS = 128\n",
    "    else:\n",
    "        BS = 60\n",
    "print(f\"BS: {BS}\")\n",
    "LR_SCHEDULER = False\n",
    "\n",
    "# Model\n",
    "MODEL_PATH = f\"model\"\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    files = os.listdir(MODEL_PATH)\n",
    "    for file in files:\n",
    "        if \"transformer\" in file:\n",
    "            name = file.split(\".\")[0]\n",
    "            STEP0 = int(name.split(\"_\")[-1])\n",
    "            EPOCH0 = int(name.split(\"_\")[-2])\n",
    "DIM_EMBEDDING = 512\n",
    "NUM_HEADS = 8\n",
    "NUM_LAYERS = 6\n",
    "DROPOUT = 0.1\n",
    "LABEL_SMOOTHING = 0.1\n",
    "\n",
    "# Tokenizers\n",
    "TOKENIZERS_PATH = f\"tokenizers\"\n",
    "if not os.path.exists(TOKENIZERS_PATH):\n",
    "    os.makedirs(TOKENIZERS_PATH)\n",
    "UNKNOWN_TOKEN = \"[UNK]\"\n",
    "PADDING_TOKEN = \"[PAD]\"\n",
    "START_OF_SEQUENCE = \"[SOS]\"\n",
    "END_OF_SEQUENCE = \"[EOS]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device ✔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.device_count() > 1 and GPUS > 1:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "else:\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(f\"cuda:{GPU_NUMBER}\")\n",
    "        print(f\"Using GPU {GPU_NUMBER}\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de los datos ✔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset opus_books (/home/wallabot/.cache/huggingface/datasets/opus_books/en-it/1.0.0/e8f950a4f32dc39b7f9088908216cd2d7e21ac35f893d04d39eb594746af2daf)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32332"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "if SUBSET:\n",
    "    dataset_raw = load_dataset('opus_books', f'{SOURCE_LANGUAGE}-{TARGET_LANGUAGE}', split='train')\n",
    "    len_dataset = len(dataset_raw)\n",
    "    len_subset = int(len_dataset * PERCENT_SUBSET)\n",
    "    dataset_raw = load_dataset('opus_books', f'{SOURCE_LANGUAGE}-{TARGET_LANGUAGE}', split=f'train[:{len_subset}]')\n",
    "else:\n",
    "    dataset_raw = load_dataset('opus_books', f'{SOURCE_LANGUAGE}-{TARGET_LANGUAGE}', split='train')\n",
    "\n",
    "len(dataset_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de los tokenizers ✔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_sentences(dataset):\n",
    "    all_sentences = []\n",
    "    for i in range(len(dataset)):\n",
    "        all_sentences.append(dataset[i]['translation'][SOURCE_LANGUAGE])\n",
    "        all_sentences.append(dataset[i]['translation'][TARGET_LANGUAGE])\n",
    "    return all_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training source tokenizer\n"
     ]
    }
   ],
   "source": [
    "tokenizer_source_path = f\"{TOKENIZERS_PATH}/tokenizer_{SOURCE_LANGUAGE}.json\"\n",
    "\n",
    "if not os.path.exists(tokenizer_source_path) or STEP0 == 0 or EPOCH0 == 0:\n",
    "    print(f\"Training source tokenizer\")\n",
    "    tokenizer_source = Tokenizer(WordLevel(unk_token=UNKNOWN_TOKEN))\n",
    "    tokenizer_source.pre_tokenizer = Whitespace()\n",
    "    trainer = WordLevelTrainer(special_tokens=[UNKNOWN_TOKEN, PADDING_TOKEN, START_OF_SEQUENCE, END_OF_SEQUENCE])\n",
    "    all_sentences = get_all_sentences(dataset_raw)\n",
    "    tokenizer_source.train_from_iterator(all_sentences, trainer)\n",
    "    tokenizer_source.save(tokenizer_source_path)\n",
    "else:\n",
    "    tokenizer_source = Tokenizer.from_file(tokenizer_source_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training target tokenizer\n"
     ]
    }
   ],
   "source": [
    "tokenizer_target_path = f\"{TOKENIZERS_PATH}/tokenizer_{TARGET_LANGUAGE}.json\"\n",
    "\n",
    "if not os.path.exists(tokenizer_target_path) or STEP0 == 0 or EPOCH0 == 0:\n",
    "    print(f\"Training target tokenizer\")\n",
    "    tokenizer_target = Tokenizer(WordLevel(unk_token=UNKNOWN_TOKEN))\n",
    "    tokenizer_target.pre_tokenizer = Whitespace()\n",
    "    trainer = WordLevelTrainer(special_tokens=[UNKNOWN_TOKEN, PADDING_TOKEN, START_OF_SEQUENCE, END_OF_SEQUENCE])\n",
    "    all_sentences = get_all_sentences(dataset_raw)\n",
    "    tokenizer_target.train_from_iterator(all_sentences, trainer)\n",
    "    tokenizer_target.save(tokenizer_target_path)\n",
    "else:\n",
    "    tokenizer_target = Tokenizer.from_file(tokenizer_target_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtención de la lóngitud máxima de las secuencias ✔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max source sequence length: 309\n",
      "Max target sequence length: 274\n",
      "Max sequence length: 311\n"
     ]
    }
   ],
   "source": [
    "max_source_sequence_length = 0\n",
    "max_target_sequence_length = 0\n",
    "\n",
    "for i in range(len(dataset_raw)):\n",
    "    source_sequence_length = len(tokenizer_source.encode(dataset_raw[i]['translation'][SOURCE_LANGUAGE]).ids)\n",
    "    target_sequence_length = len(tokenizer_target.encode(dataset_raw[i]['translation'][TARGET_LANGUAGE]).ids)\n",
    "    if source_sequence_length > max_source_sequence_length:\n",
    "        max_source_sequence_length = source_sequence_length\n",
    "    if target_sequence_length > max_target_sequence_length:\n",
    "        max_target_sequence_length = target_sequence_length\n",
    "\n",
    "max_sequence_len = max(max_source_sequence_length, max_target_sequence_length)\n",
    "max_sequence_len += 2   # Add 2 for the start and end of sequence tokens\n",
    "\n",
    "print(f\"Max source sequence length: {max_source_sequence_length}\")\n",
    "print(f\"Max target sequence length: {max_target_sequence_length}\")\n",
    "print(f\"Max sequence length: {max_sequence_len}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets ✔"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask ✔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(size):\n",
    "    mask = torch.triu(torch.ones(1, size, size), diagonal = 1).type(torch.int)\n",
    "    return mask == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset class ✔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class BilingualDataset(Dataset):\n",
    "    def __init__(self, dataset, tokenizer_src, tokenizer_tgt, src_lang, tgt_lang, max_seq_len) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer_src = tokenizer_src\n",
    "        self.tokenizer_tgt = tokenizer_tgt\n",
    "        self.src_lang = src_lang\n",
    "        self.tgt_lang = tgt_lang\n",
    "        \n",
    "        # Defining special tokens by using the target language tokenizer\n",
    "        self.sos_token = torch.tensor([tokenizer_tgt.token_to_id(START_OF_SEQUENCE)], dtype=torch.int64)\n",
    "        self.eos_token = torch.tensor([tokenizer_tgt.token_to_id(END_OF_SEQUENCE)], dtype=torch.int64)\n",
    "        self.pad_token = torch.tensor([tokenizer_tgt.token_to_id(PADDING_TOKEN)], dtype=torch.int64)\n",
    "        self.unk_token = torch.tensor([tokenizer_tgt.token_to_id(UNKNOWN_TOKEN)], dtype=torch.int64)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Getting the source and target texts from the dataset\n",
    "        src_target_pair = self.dataset[index]['translation']\n",
    "        src_text = src_target_pair[self.src_lang]\n",
    "        tgt_text = src_target_pair[self.tgt_lang]\n",
    "        \n",
    "        # Tokenizing source and target texts \n",
    "        encoder_input_tokens = self.tokenizer_src.encode(src_text).ids\n",
    "        decoder_input_tokens = self.tokenizer_tgt.encode(tgt_text).ids\n",
    "        \n",
    "        # Computing how many padding tokens need to be added to the tokenized texts \n",
    "        encoder_num_padding_tokens = self.max_seq_len - len(encoder_input_tokens) - 2 # Subtracting the two '[EOS]' and '[SOS]' special tokens\n",
    "        decoder_num_padding_tokens = self.max_seq_len - len(decoder_input_tokens) - 1 # Subtracting the '[SOS]' special token\n",
    "        \n",
    "        # If the texts exceed the 'seq_len' allowed, it will raise an error. This means that one of the sentences in the pair is too long to be processed\n",
    "        # given the current sequence length limit (this will be defined in the config dictionary below)\n",
    "        if encoder_num_padding_tokens < 0 or decoder_num_padding_tokens < 0:\n",
    "            raise ValueError('Sentence is too long')\n",
    "         \n",
    "        # Building the encoder input tensor by combining several elements\n",
    "        encoder_input = torch.cat(\n",
    "            [\n",
    "                self.sos_token, # inserting the '[SOS]' token\n",
    "                torch.tensor(encoder_input_tokens, dtype = torch.int64), # Inserting the tokenized source text\n",
    "                self.eos_token, # Inserting the '[EOS]' token\n",
    "                torch.tensor([self.pad_token] * encoder_num_padding_tokens, dtype = torch.int64) # Addind padding tokens\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Building the decoder input tensor by combining several elements\n",
    "        decoder_input = torch.cat(\n",
    "            [\n",
    "                self.sos_token, # inserting the '[SOS]' token \n",
    "                torch.tensor(decoder_input_tokens, dtype = torch.int64), # Inserting the tokenized target text\n",
    "                torch.tensor([self.pad_token] * decoder_num_padding_tokens, dtype = torch.int64) # Addind padding tokens\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Creating a label tensor, the expected output for training the model\n",
    "        label = torch.cat(\n",
    "            [\n",
    "                torch.tensor(decoder_input_tokens, dtype = torch.int64), # Inserting the tokenized target text\n",
    "                self.eos_token, # Inserting the '[EOS]' token \n",
    "                torch.tensor([self.pad_token] * decoder_num_padding_tokens, dtype = torch.int64) # Adding padding tokens\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Ensuring that the length of each tensor above is equal to the defined 'seq_len'\n",
    "        assert encoder_input.size(0) == self.max_seq_len\n",
    "        assert decoder_input.size(0) == self.max_seq_len\n",
    "        assert label.size(0) == self.max_seq_len\n",
    "\n",
    "        return {\n",
    "            'encoder_input': encoder_input,\n",
    "            'decoder_input': decoder_input, \n",
    "            'decoder_mask': (decoder_input != self.pad_token).unsqueeze(0).unsqueeze(0).int() & create_mask(decoder_input.size(0)),\n",
    "            'label': label,\n",
    "            'src_text': src_text,\n",
    "            'tgt_text': tgt_text\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset ✔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len train: 32008, len validation: 324\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "percent_train = 0.99\n",
    "len_train = int(len(dataset_raw) * percent_train)\n",
    "len_val = len(dataset_raw) - len_train\n",
    "train_dataset_raw, validation_dataset_raw = random_split(dataset_raw, [len_train, len_val])\n",
    "\n",
    "print(f\"Len train: {len(train_dataset_raw)}, len validation: {len(validation_dataset_raw)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BilingualDataset(train_dataset_raw, tokenizer_source, tokenizer_target, SOURCE_LANGUAGE, TARGET_LANGUAGE, max_sequence_len)\n",
    "validation_dataset = BilingualDataset(validation_dataset_raw, tokenizer_source, tokenizer_target, SOURCE_LANGUAGE, TARGET_LANGUAGE, max_sequence_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaders ✔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BS, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=BS, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo ✔"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clases de bajo nivel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "class CustomLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(CustomLinear, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "        init.kaiming_uniform_(self.linear.weight, nonlinearity='relu')\n",
    "        if self.linear.bias is not None:\n",
    "            init.zeros_(self.linear.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "class CustomEmbedding(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        super(CustomEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_dim)\n",
    "        init.xavier_uniform_(self.embedding.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.embedding(x)\n",
    "\n",
    "class Embedding(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        self.embedding = CustomEmbedding(vocab_size, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embedding(x)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, max_sequence_len, embedding_model_dim):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_model_dim\n",
    "        positional_encoding = torch.zeros(max_sequence_len, self.embedding_dim)\n",
    "        for pos in range(max_sequence_len):\n",
    "            for i in range(0, self.embedding_dim, 2):\n",
    "                positional_encoding[pos, i]     = torch.sin(torch.tensor(pos / (10000 ** ((2 * i) / self.embedding_dim))))\n",
    "                positional_encoding[pos, i + 1] = torch.cos(torch.tensor(pos / (10000 ** ((2 * (i+1)) / self.embedding_dim))))\n",
    "        positional_encoding = positional_encoding.unsqueeze(0)\n",
    "        self.register_buffer('positional_encoding', positional_encoding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x * torch.sqrt(torch.tensor(self.embedding_dim))\n",
    "        sequence_len = x.size(1)\n",
    "        x = x + self.positional_encoding[:,:sequence_len]\n",
    "        return x\n",
    "\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, dim_embedding):\n",
    "        super().__init__()\n",
    "        self.dim_embedding = dim_embedding\n",
    "    \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        key_trasposed = key.transpose(-1,-2)\n",
    "        product = torch.matmul(query, key_trasposed)\n",
    "        scale = product / torch.sqrt(torch.tensor(self.dim_embedding))\n",
    "        if mask is not None:\n",
    "            scale = scale.masked_fill(mask == 0, float('-inf'))\n",
    "        attention_matrix = torch.softmax(scale, dim=-1)\n",
    "        output = torch.matmul(attention_matrix, value)\n",
    "        return output\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, heads, dim_embedding):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dim_embedding = dim_embedding\n",
    "        self.dim_proyection = dim_embedding // heads\n",
    "        self.heads = heads\n",
    "        self.proyection_Q = CustomLinear(dim_embedding, dim_embedding)\n",
    "        self.proyection_K = CustomLinear(dim_embedding, dim_embedding)\n",
    "        self.proyection_V = CustomLinear(dim_embedding, dim_embedding)\n",
    "        self.attention = CustomLinear(dim_embedding, dim_embedding)\n",
    "        self.scaled_dot_product_attention = ScaledDotProductAttention(self.dim_proyection)\n",
    "    \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        batch_size = Q.size(0)\n",
    "        proyection_Q = self.proyection_Q(Q).view(batch_size, -1, self.heads, self.dim_proyection)\n",
    "        proyection_K = self.proyection_K(K).view(batch_size, -1, self.heads, self.dim_proyection)\n",
    "        proyection_V = self.proyection_V(V).view(batch_size, -1, self.heads, self.dim_proyection)\n",
    "        proyection_Q = proyection_Q.transpose(1,2)\n",
    "        proyection_K = proyection_K.transpose(1,2)\n",
    "        proyection_V = proyection_V.transpose(1,2)\n",
    "        scaled_dot_product_attention = self.scaled_dot_product_attention(proyection_Q, proyection_K, proyection_V, mask=mask)\n",
    "        concat = scaled_dot_product_attention.transpose(1,2).contiguous().view(batch_size, -1, self.dim_embedding)\n",
    "        output = self.attention(concat)\n",
    "        return output\n",
    "\n",
    "class AddAndNorm(nn.Module):\n",
    "    def __init__(self, dim_embedding):\n",
    "        super().__init__()\n",
    "        self.normalization = nn.LayerNorm(dim_embedding)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        return self.normalization(torch.add(x, sublayer))\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim_embedding, increment=4):\n",
    "        super().__init__()\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            CustomLinear(dim_embedding, dim_embedding*increment),\n",
    "            nn.ReLU(),\n",
    "            CustomLinear(dim_embedding*increment, dim_embedding)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.feed_forward(x)\n",
    "        return x\n",
    "\n",
    "class Linear(nn.Module):\n",
    "    def __init__(self, dim_embedding, vocab_size):\n",
    "        super().__init__()\n",
    "        self.linear = CustomLinear(dim_embedding, vocab_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "class Softmax(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "class Dropout(torch.nn.Module):\n",
    "    def __init__(self, p=0.1):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            return torch.nn.functional.dropout(x, p=self.p)\n",
    "        else:\n",
    "            return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clases de medio nivel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, heads, dim_embedding, prob_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.multi_head_attention = MultiHeadAttention(heads, dim_embedding)\n",
    "        self.dropout_1 = Dropout(prob_dropout)\n",
    "        self.add_and_norm_1 = AddAndNorm(dim_embedding)\n",
    "        self.feed_forward = FeedForward(dim_embedding)\n",
    "        self.dropout_2 = Dropout(prob_dropout)\n",
    "        self.add_and_norm_2 = AddAndNorm(dim_embedding)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        multi_head_attention = self.multi_head_attention(x, x, x)\n",
    "        dropout1 = self.dropout_1(multi_head_attention)\n",
    "        add_and_norm_1 = self.add_and_norm_1(x, dropout1)\n",
    "        feed_forward = self.feed_forward(add_and_norm_1)\n",
    "        dropout2 = self.dropout_2(feed_forward)\n",
    "        add_and_norm_2 = self.add_and_norm_2(add_and_norm_1, dropout2)\n",
    "        return add_and_norm_2\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, heads, dim_embedding, Nx, prob_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(heads, dim_embedding, prob_dropout) for _ in range(Nx)])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for encoder_layer in self.encoder_layers:\n",
    "            x = encoder_layer(x)\n",
    "        return x\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, dim_embedding, max_sequence_len, heads, Nx, prob_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.input_embedding = Embedding(vocab_size, dim_embedding)\n",
    "        self.positional_encoding = PositionalEncoding(max_sequence_len, dim_embedding)\n",
    "        self.encoder = Encoder(heads, dim_embedding, Nx, prob_dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        input_embedding = self.input_embedding(x)\n",
    "        positional_encoding = self.positional_encoding(input_embedding)\n",
    "        encoder = self.encoder(positional_encoding)\n",
    "        return encoder\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, heads, dim_embedding, prob_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.masked_multi_head_attention = MultiHeadAttention(heads, dim_embedding)\n",
    "        self.dropout_1 = Dropout(prob_dropout)\n",
    "        self.add_and_norm_1 = AddAndNorm(dim_embedding)\n",
    "        self.encoder_decoder_multi_head_attention = MultiHeadAttention(heads, dim_embedding)\n",
    "        self.dropout_2 = Dropout(prob_dropout)\n",
    "        self.add_and_norm_2 = AddAndNorm(dim_embedding)\n",
    "        self.feed_forward = FeedForward(dim_embedding)\n",
    "        self.dropout_3 = Dropout(prob_dropout)\n",
    "        self.add_and_norm_3 = AddAndNorm(dim_embedding)\n",
    "    \n",
    "    def forward(self, x, encoder_output, mask=None):\n",
    "        Q = x\n",
    "        K = x\n",
    "        V = x\n",
    "        masked_multi_head_attention = self.masked_multi_head_attention(Q, K, V, mask=mask)\n",
    "        dropout1 = self.dropout_1(masked_multi_head_attention)\n",
    "        add_and_norm_1 = self.add_and_norm_1(dropout1, x)\n",
    "\n",
    "        Q = add_and_norm_1\n",
    "        K = encoder_output\n",
    "        V = encoder_output\n",
    "        encoder_decoder_multi_head_attention = self.encoder_decoder_multi_head_attention(Q, K, V)\n",
    "        dropout2 = self.dropout_2(encoder_decoder_multi_head_attention)\n",
    "        add_and_norm_2 = self.add_and_norm_2(dropout2, add_and_norm_1)\n",
    "\n",
    "        feed_forward = self.feed_forward(add_and_norm_2)\n",
    "        dropout3 = self.dropout_3(feed_forward)\n",
    "        add_and_norm_3 = self.add_and_norm_3(dropout3, add_and_norm_2)\n",
    "\n",
    "        return add_and_norm_3\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, heads, dim_embedding, Nx, prob_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([DecoderLayer(heads, dim_embedding, prob_dropout) for _ in range(Nx)])\n",
    "    \n",
    "    def forward(self, x, encoder_output, mask=None):\n",
    "        for decoder_layer in self.layers:\n",
    "            x = decoder_layer(x, encoder_output, mask)\n",
    "        return x\n",
    "\n",
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, heads, dim_embedding, Nx, vocab_size, max_sequence_len, prob_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embedding = Embedding(vocab_size, dim_embedding)\n",
    "        self.positional_encoding = PositionalEncoding(max_sequence_len, dim_embedding)\n",
    "        self.decoder = Decoder(heads, dim_embedding, Nx, prob_dropout)\n",
    "        self.linear = Linear(dim_embedding, vocab_size)\n",
    "        # self.softmax = Softmax()\n",
    "    \n",
    "    def forward(self, x, encoder_output, mask=None):\n",
    "        x = self.embedding(x)\n",
    "        x = self.positional_encoding(x)\n",
    "        x = self.decoder(x, encoder_output, mask)\n",
    "        x = self.linear(x)\n",
    "        # x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "class Linear_and_softmax(nn.Module):\n",
    "    def __init__(self, dim_embedding, vocab_size):\n",
    "        super().__init__()\n",
    "        self.linear = CustomLinear(dim_embedding, vocab_size)\n",
    "        # self.softmax = Softmax()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        # x = self.softmax(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clase de alto nivel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, src_max_seq_len, tgt_max_seq_len, dim_embedding, Nx, heads, prob_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.transformerEncoder = TransformerEncoder(src_vocab_size, dim_embedding, src_max_seq_len, heads, Nx, prob_dropout)\n",
    "        self.transformerDecoder = TransformerDecoder(heads, dim_embedding, Nx, tgt_vocab_size, tgt_max_seq_len, prob_dropout)\n",
    "        self.encoder = Encoder(heads, dim_embedding, Nx, prob_dropout)\n",
    "        self.decoder = Decoder(heads, dim_embedding, Nx, prob_dropout)\n",
    "        self.sourceEmbedding = Embedding(src_vocab_size, dim_embedding)\n",
    "        self.targetEmbedding = Embedding(tgt_vocab_size, dim_embedding)\n",
    "        self.sourcePositional_encoding = PositionalEncoding(src_max_seq_len, dim_embedding)\n",
    "        self.targetPositional_encoding = PositionalEncoding(tgt_max_seq_len, dim_embedding)\n",
    "        self.linear = Linear_and_softmax(dim_embedding, tgt_vocab_size)\n",
    "    \n",
    "    def encode(self, source):\n",
    "        embedding = self.sourceEmbedding(source)\n",
    "        positional_encoding = self.sourcePositional_encoding(embedding)\n",
    "        encoder_output = self.encoder(positional_encoding)\n",
    "        return encoder_output\n",
    "    \n",
    "    def decode(self, encoder_output, target, target_mask):\n",
    "        embedding = self.targetEmbedding(target)\n",
    "        positional_encoding = self.targetPositional_encoding(embedding)\n",
    "        decoder_output = self.decoder(positional_encoding, encoder_output, target_mask)\n",
    "        return decoder_output\n",
    "    \n",
    "    def projection(self, decoder_output):\n",
    "        linear_output = self.linear(decoder_output)\n",
    "        # softmax_output = self.softmax(linear_output)\n",
    "        return linear_output\n",
    "    \n",
    "    def forward(self, source, target, mask=None):\n",
    "        encoder_output = self.transformerEncoder(source)\n",
    "        decoder_output = self.transformerDecoder(target, encoder_output, mask)\n",
    "        return decoder_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source vocab size: 30000, target vocab size: 30000, source max sequence len: 311, target max sequence len: 311, dim_embedding: 512, heads: 8, Nx: 6, prob_dropout: 0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "source_vocab_size = tokenizer_source.get_vocab_size()\n",
    "target_vocab_size = tokenizer_target.get_vocab_size()\n",
    "src_max_seq_len = max_sequence_len\n",
    "tgt_max_seq_len = max_sequence_len\n",
    "dim_embedding = DIM_EMBEDDING\n",
    "Nx = NUM_LAYERS\n",
    "heads = NUM_HEADS\n",
    "prob_dropout = DROPOUT\n",
    "print(f\"source vocab size: {source_vocab_size}, target vocab size: {target_vocab_size}, source max sequence len: {src_max_seq_len}, target max sequence len: {tgt_max_seq_len}, dim_embedding: {dim_embedding}, heads: {heads}, Nx: {Nx}, prob_dropout: {prob_dropout}\")\n",
    "\n",
    "model = Transformer(\n",
    "    src_vocab_size = source_vocab_size,\n",
    "    tgt_vocab_size = target_vocab_size,\n",
    "    src_max_seq_len = src_max_seq_len,\n",
    "    tgt_max_seq_len = tgt_max_seq_len,\n",
    "    dim_embedding = dim_embedding,\n",
    "    Nx = Nx,\n",
    "    heads = heads,\n",
    "    prob_dropout = prob_dropout,\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizador ✔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función de pérdida ✔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(\n",
    "    ignore_index = tokenizer_source.token_to_id(PADDING_TOKEN), \n",
    "    label_smoothing = LABEL_SMOOTHING).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR ✔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Step():\n",
    "    def __init__(self):\n",
    "        self.step = 0\n",
    "    \n",
    "    def set_step(self, st):\n",
    "        self.step = st\n",
    "    \n",
    "    def get_step(self):\n",
    "        return int(self.step)\n",
    "\n",
    "class LearningRate():\n",
    "    def __init__(self):\n",
    "        self.lr = 0\n",
    "    \n",
    "    def set_lr(self, l_r_):\n",
    "        self.lr = l_r_\n",
    "    \n",
    "    def get_lr(self):\n",
    "        return self.lr\n",
    "\n",
    "actual_step = Step()\n",
    "actual_lr = LearningRate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_lr(step_num, dim_embeding_model=512, warmup_steps=4000):\n",
    "    step_num += 1e-7 # Avoid division by zero\n",
    "    step_num += STEP0\n",
    "    actual_step.set_step(step_num)\n",
    "    step_num_exp = -0.4\n",
    "    warmup_steps_exp = -2.6\n",
    "    dim_embeding_model_exp = -0.1\n",
    "    lr = np.power(dim_embeding_model, dim_embeding_model_exp) * np.minimum(np.power(step_num, step_num_exp), step_num * np.power(warmup_steps, warmup_steps_exp))\n",
    "    actual_lr.set_lr(lr)\n",
    "    return lr\n",
    "\n",
    "lr_lambda = lambda step: calculate_lr(step, dim_embeding_model=dim_embedding)\n",
    "if LR_SCHEDULER:\n",
    "    lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation loop ✔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(model, source, tokenizer_tgt, max_len, device, bs=1):\n",
    "    # Retrieving the indices from the start and end of sequences of the target tokens\n",
    "    sos_idx = tokenizer_tgt.token_to_id('[SOS]')    # Start of Sentence token index (2)\n",
    "    # eos_idx = tokenizer_tgt.token_to_id('[EOS]')    # End of Sentence token index (3)\n",
    "\n",
    "    # Computing the output of the encoder for the source sequence\n",
    "    encoder_output = model.encode(source)\n",
    "    \n",
    "    # Initializing the decoder input with the Start of Sentence token\n",
    "    decoder_input = torch.empty(bs,1).fill_(sos_idx).type_as(source).to(device)\n",
    "    \n",
    "    # Looping until the 'max_len', maximum length, is reached\n",
    "    while True:\n",
    "        if decoder_input.size(1) == max_len:\n",
    "            break\n",
    "            \n",
    "        # Building a mask for the decoder input\n",
    "        decoder_mask = create_mask(decoder_input.size(1)).to(device)\n",
    "        \n",
    "        # Calculating the output of the decoder\n",
    "        out = model.decode(encoder_output, decoder_input, decoder_mask)\n",
    "        \n",
    "        # Applying the projection layer to get the probabilities for the next token\n",
    "        prob = model.projection(out[:, -1])\n",
    "\n",
    "        # Selecting token with the highest probability\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        # decoder_input = torch.cat([decoder_input, torch.empty(1,1). type_as(source).fill_(next_word.item()).to(device)], dim=1)\n",
    "        decoder_input = torch.cat([decoder_input, next_word.unsqueeze(1)], dim=1)\n",
    "    \n",
    "    if len(decoder_input.shape) == 1:\n",
    "        decoder_input = decoder_input.unsqueeze(0)\n",
    "    elif len(decoder_input.shape) == 3:\n",
    "        decoder_input = decoder_input.squeeze(0)\n",
    "\n",
    "    return decoder_input # Sequence of tokens generated by the decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "\n",
    "def validation_loop(model, validation_ds, tokenizer_src, tokenizer_tgt, max_len, device, print_msg, num_examples=2):\n",
    "    model.eval() # Setting model to evaluation mode\n",
    "\n",
    "    # Calculating the number of batches in the validation dataset\n",
    "    dataset_size = len(validation_ds.dataset)  # Tamaño total del conjunto de datos\n",
    "    batch_size = validation_ds.batch_size      # Tamaño del batch\n",
    "    drop_last = validation_ds.drop_last        # Configuración de drop_last\n",
    "    num_batches = len(validation_ds)           # Número total de batches\n",
    "\n",
    "    # Calculating the total number of samples in the validation dataset\n",
    "    total_samples = batch_size * (num_batches - 1) + min(batch_size, dataset_size % batch_size)\n",
    "\n",
    "    # If drop_last is False and the dataset size is not divisible by the batch size, we need to add one more batch\n",
    "    if drop_last and dataset_size % batch_size != 0:\n",
    "        total_samples -= dataset_size % batch_size\n",
    "\n",
    "    # Initializing progress bar\n",
    "    progress_bar = tqdm(range(total_samples), desc = 'Processing validation examples') # Initializing progress bar\n",
    "\n",
    "    # Initializing lists to store scores\n",
    "    bleu_scores = []\n",
    "    meteor_scores = []\n",
    "    \n",
    "    # Creating evaluation loop\n",
    "    with torch.no_grad(): # Ensuring that no gradients are computed during this process\n",
    "        for batch in validation_ds:\n",
    "            # Loading input data and masks onto the GPU\n",
    "            encoder_input = batch['encoder_input'].to(device)\n",
    "            \n",
    "            # Applying the 'greedy_decode' function to get the model's output for the source text of the input batch\n",
    "            num_samples = len(batch['src_text'])\n",
    "            model_out_bs = greedy_decode(model, encoder_input, tokenizer_tgt, max_len, device, bs=num_samples)\n",
    "\n",
    "            # Get metrics for every example in the batch\n",
    "            for i in range(num_samples):\n",
    "                source_text = batch['src_text'][i]\n",
    "                target_text = batch['tgt_text'][i]\n",
    "                model_out_i = model_out_bs[i]\n",
    "                model_out_text = tokenizer_tgt.decode(model_out_i.detach().cpu().numpy())\n",
    "\n",
    "                # Calculating metrics\n",
    "                references = [target_text.split()]\n",
    "                hypothesis = model_out_text.split()\n",
    "                bleu_score = sentence_bleu(references, hypothesis)\n",
    "                meteor_score_value = meteor_score(references, hypothesis)\n",
    "            \n",
    "                # Appending scores to lists\n",
    "                bleu_scores.append(bleu_score)\n",
    "                meteor_scores.append(meteor_score_value)\n",
    "\n",
    "                # Calculating mean scores            \n",
    "                mean_bleu_score = sum(bleu_scores)/len(bleu_scores) # Calculating mean BLEU score\n",
    "                mean_meteor_score = sum(meteor_scores)/len(meteor_scores) # Calculating mean METEOR score\n",
    "\n",
    "                # Updating progress bar and printing bleu and meteor scores\n",
    "                progress_bar.update(1)\n",
    "                progress_bar.set_postfix({'BLEU': f'{mean_bleu_score:.9f}', 'METEOR': f'{mean_meteor_score:.9f}'})\n",
    "\n",
    "    # Printing results\n",
    "    console_width = 80 # Fixed witdh for printed messages\n",
    "    print('-'*console_width)\n",
    "    print(f'SOURCE: {source_text}')\n",
    "    print(f'TARGET: {target_text}')\n",
    "    print(f'PREDICTED: {model_out_text}')\n",
    "    print('-'*console_width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 00: 100%|██████████| 534/534 [05:19<00:00,  1.67it/s, loss=7.395373, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:27<00:00,  3.71it/s, BLEU=0.000000000, METEOR=0.000000000] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: 'Really?' said Vronsky, frowning.\n",
      "TARGET: — Davvero? — disse Vronskij, aggrottando le sopracciglia.\n",
      "PREDICTED: \n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 01: 100%|██████████| 534/534 [05:19<00:00,  1.67it/s, loss=7.143915, lr=0.000000000]\n",
      "Processing validation examples:   1%|          | 2/324 [00:15<1:24:36, 15.77s/it, BLEU=0.000000000, METEOR=0.000000000]/home/wallabot/miniconda3/envs/cursopytorch/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/wallabot/miniconda3/envs/cursopytorch/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/wallabot/miniconda3/envs/cursopytorch/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.76it/s, BLEU=0.000000000, METEOR=0.018620699] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: You consider my arms filled and my embraces appropriated?\"\n",
      "TARGET: Voi credete che le mie braccia non sieno più vuote e che i miei baci spettino a un'altra.\n",
      "PREDICTED: — , , , , , , , , , . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 02: 100%|██████████| 534/534 [05:20<00:00,  1.67it/s, loss=6.975619, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.75it/s, BLEU=0.000000000, METEOR=0.021832330] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: I did not altogether like to give in, though I did not relish the plunge.\n",
      "TARGET: Io non volevo rinunziare interamente a un tuffo, benchè non mi sorridesse.\n",
      "PREDICTED: — E , , , , , , , , , , , , , , , , , , , , , , , , , .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 03: 100%|██████████| 534/534 [05:19<00:00,  1.67it/s, loss=6.824063, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.000000000, METEOR=0.024572653] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: You will think me superstitious,--some superstition I have in my blood, and always had: nevertheless, this is true--true at least it is that I heard what I now relate.\n",
      "TARGET: Sentite qualcosa di più strano e mi crederete superstizioso. \"È certo che ho avuto sempre un po' di superstizione nel sangue; ma assicuratevi che quello che sto per dirvi è vero.\n",
      "PREDICTED: — Non , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , . , , , , , , , , , , , , , . , , , , , , , , , , . , , , , , , , . , , , , , . , , , , , . , , , , , . , , , , . , , , . , , , , . , , , . . , , , , . . , , . , , , . . . , , , , , . . . , , . . , , , . . . , , , , . . . . , , , , , , . . . , , , . . . . . , , , , , . . . . . . . . . . , , , , , . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 04: 100%|██████████| 534/534 [05:19<00:00,  1.67it/s, loss=6.802623, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.000000000, METEOR=0.029419585] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: 'I don't see that it is a joke, that...' began Levin, but Koznyshev interrupted him.\n",
      "TARGET: — Io non vedo come questo sia uno scherzo, che... — voleva cominciare Levin, ma Sergej Ivanovic lo interruppe.\n",
      "PREDICTED: — Ma , , , , , , , , , , , , , , , , , , , , , , , , . , , . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 05: 100%|██████████| 534/534 [05:19<00:00,  1.67it/s, loss=6.772199, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.74it/s, BLEU=0.000000000, METEOR=0.027948133] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: The two sisters nursed all the six children successfully through the illness, but Kitty's health did not improve, and in Lent the Shcherbatskys went abroad.\n",
      "TARGET: Tutte e due le sorelle portarono felicemente a guarigione i sei piccoli, ma la salute di Kitty non migliorò, e durante la quaresima gli Šcerbackij partirono per l’estero.\n",
      "PREDICTED: E , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , . , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ,\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 06: 100%|██████████| 534/534 [05:19<00:00,  1.67it/s, loss=6.752402, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000000000, METEOR=0.027620220] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Karenin sat down on a chair and with a look full of suffering and weariness watched the nurse as she paced the room.\n",
      "TARGET: Aleksej Aleksandrovic si era seduto su di una sedia e col viso abbattuto e sofferente, guardava la njanja che andava avanti e indietro.\n",
      "PREDICTED: Aleksej Aleksandrovic e e e e e e e e e e e e e . e . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 07: 100%|██████████| 534/534 [05:19<00:00,  1.67it/s, loss=6.768605, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000000000, METEOR=0.028556046] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: At ten o'clock Vronsky returned.\n",
      "TARGET: Alle dieci venne Vronskij.\n",
      "PREDICTED: La ’ ’ ’ ’ ’ ’ si si si si si si . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 08: 100%|██████████| 534/534 [05:19<00:00,  1.67it/s, loss=6.923685, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:27<00:00,  3.72it/s, BLEU=0.000000000, METEOR=0.028195759] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: I had closed my shutter, laid a mat to the door to prevent the snow from blowing in under it, trimmed my fire, and after sitting nearly an hour on the hearth listening to the muffled fury of the tempest, I lit a candle, took down \"Marmion,\" and beginning--\n",
      "TARGET: Avevo chiuso le imposte e steso una stuoia dalla parte interna della porta, perché la neve non passasse di sotto, e dopo essere stata un'ora accanto al fuoco ascoltando il rumore della tempesta, avevo preso Marmion e m'ero messa a leggere la strofa seguente:\n",
      "PREDICTED: La mi mi , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ,\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 09: 100%|██████████| 534/534 [05:20<00:00,  1.67it/s, loss=6.777938, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:27<00:00,  3.72it/s, BLEU=0.000000000, METEOR=0.025119673] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: “Well, then,” said I, “you may let them escape; and Providence seems to have awakened them on purpose to save themselves. Now,” says I, “if the rest escape you, it is your fault.”\n",
      "TARGET: Eccitato da queste parole prese su un dei moschetti che gli aveva dati, e postasi una pistola nella cintura e armati con gli altri due moschetti i suoi due compagni, s’avviò insieme con essi che lo precedevano d’alcuni passi.\n",
      "PREDICTED: — E , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ,\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 10: 100%|██████████| 534/534 [05:20<00:00,  1.67it/s, loss=6.578362, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:27<00:00,  3.72it/s, BLEU=0.000000000, METEOR=0.028544474] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: You will think me superstitious,--some superstition I have in my blood, and always had: nevertheless, this is true--true at least it is that I heard what I now relate.\n",
      "TARGET: Sentite qualcosa di più strano e mi crederete superstizioso. \"È certo che ho avuto sempre un po' di superstizione nel sangue; ma assicuratevi che quello che sto per dirvi è vero.\n",
      "PREDICTED: \" Ma che che che mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi che mi che che che che che che che che che che che che che che che che che che che che che che che che che che che , che , che , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ,\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 11: 100%|██████████| 534/534 [05:20<00:00,  1.67it/s, loss=6.381001, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:27<00:00,  3.72it/s, BLEU=0.000000000, METEOR=0.034797936] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: 'Between the potatoes. We too rent a little land.\n",
      "TARGET: Anche noi teniamo un pezzetto di terra.\n",
      "PREDICTED: — , , . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 12: 100%|██████████| 534/534 [05:19<00:00,  1.67it/s, loss=6.513088, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:27<00:00,  3.72it/s, BLEU=0.000921218, METEOR=0.037130153] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: So it happens with fortune, who shows her power where valour has not prepared to resist her, and thither she turns her forces where she knows that barriers and defences have not been raised to constrain her.\n",
      "TARGET: Similmente interviene della fortuna: la quale dimonstra la sua potenzia dove non è ordinata virtù a resisterle, e quivi volta li sua impeti, dove la sa che non sono fatti li argini e li ripari a tenerla.\n",
      "PREDICTED: E la , , , , , , , , , , , , , , , , , la , la , la . , , , . , , . , la . , . , . . . , la . . . . . . . . . , la . . . . . . . . . . . . . . . . . . . . . . . . . . , , la . . . . . . . . . . . . . , . , la . . . . . , , . . . , la . , , , , , , . , la la , , . , la la la la la la la la la la la la la la la la la la la , la , la la la la la la la la la . , la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 13: 100%|██████████| 534/534 [05:20<00:00,  1.67it/s, loss=6.364981, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:27<00:00,  3.72it/s, BLEU=0.000000000, METEOR=0.036197087] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Directly Levin approached the bath he was shown an experiment which succeeded perfectly.\n",
      "TARGET: Non appena Levin si fu avvicinato alla vasca da bagno, gli fu offerto subito un esperimento, e l’esperimento riuscì in pieno.\n",
      "PREDICTED: Levin Levin , Levin , Levin , Levin , ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ Levin . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 14: 100%|██████████| 534/534 [05:20<00:00,  1.67it/s, loss=6.459440, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000921218, METEOR=0.040326397] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Levin was surprised that they disputed about it so long, especially as, when he asked Koznyshev whether he thought that money had been misappropriated, he received the reply:\n",
      "TARGET: Levin era sorpreso che si discutesse così a lungo di questo, soprattutto perché quando aveva chiesto a Sergej Ivanovic se egli supponeva che le somme fossero state malversate, Sergej Ivanovic aveva risposto:\n",
      "PREDICTED: E , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , che che che che che che che che che che che che che che che che che che che che che che che che che che che , , , che che che che , , che che che che che , , , , che che che che che , , , , , che che che che che che che che che che che , , , , , , , , , , , , , , , , che cosa , che cosa , che cosa , che cosa che cosa , che che , , , che che che che , , , , , , , , , , , , , , che che che che che che , , , che che cosa , che cosa , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ,\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 15: 100%|██████████| 534/534 [05:20<00:00,  1.67it/s, loss=6.122970, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.001067039, METEOR=0.050732385] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: But really what has he done...\n",
      "TARGET: Ma cosa mai ha fatto?\n",
      "PREDICTED: Ma è , è è ? ? !\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 16: 100%|██████████| 534/534 [05:20<00:00,  1.67it/s, loss=6.341681, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.001268931, METEOR=0.052227726] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: As they were having a chat before dinner, Oblonsky had said to Bartnyansky:\n",
      "TARGET: Prima di pranzo, messisi a parlare, Stepan Arkad’ic aveva detto a Bartnjanskij:\n",
      "PREDICTED: Stepan ’ ic , Stepan ’ ic , Stepan ’ ic , Stepan ’ ic , Stepan ’ ic , un ic . , si ic , si ic , si un ic , si un ic , si un ic . , si un ic , si un ic , si si si si si si si si si si si si un ic , si un ic , un un un un ic . , , , , , , , , , , , , , , , , , , , , , , . , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , . , , , , , , , , , , , , , , , , , , , , , , , . , , , , , , , , , , , , , , , , , , , , , , , . , , , , , , , , , , , , , , , , , , , , , , , , , , . , , , , , , un ic , , , , , , , , , , , , , , , , , , , , , , , , , , , . , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , . ,\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 17: 100%|██████████| 534/534 [05:19<00:00,  1.67it/s, loss=6.165667, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.001268931, METEOR=0.056350456] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: I was near, and listened to both you and her.\n",
      "TARGET: \"Ero vicino e ho sentito la vostra conversazione.\n",
      "PREDICTED: e e e e e e e e e e e . e e e e e . e e e e e e e e e e e e e e e e e e e e . e e e e e e e e e e e e e e e e e e e . e e e e e e e e e e e e e e e e e . e e e e e e e e e e . . e e e e e e e e e e e e e e e e e e e e e e e e . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 18: 100%|██████████| 534/534 [05:19<00:00,  1.67it/s, loss=6.211956, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.001067039, METEOR=0.053918978] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Then these folks would go and be pirates until the marriage was over.\n",
      "TARGET: Meglio sparire, in attesa della celebrazione del matrimonio.\n",
      "PREDICTED: E il ’ era più più , più più più più più più più più . che più più più più . . . . . . più più più più più più più più più più più più più più più più più più più . . . . . . . . più più più più più più più più più più più più più più più più più più più . . . . . . . . . . . . . . . . . . . . . . più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più . . . . . . . . . . . . . . . . . . . . più più più più più più più più più più più più più più più più più più più più più più più più più più più più . . più più più più più più più più più più più più più più più più più più più più . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 19: 100%|██████████| 534/534 [05:20<00:00,  1.67it/s, loss=6.264954, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.001067039, METEOR=0.054122787] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: \"No, but I thought you would never come. I could not bear to wait in the house for you, especially with this rain and wind.\"\n",
      "TARGET: — No, ma mi pareva che non sareste tornato più e non potevo aspettarvi tranquillamente a casa, sopratutto con quest'acqua e con questo vento.\n",
      "PREDICTED: — Non ho ho ho ho ho ho ho ho ho ho me , ma non me , non me , non me , non me , non me . , non me . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 20: 100%|██████████| 534/534 [05:20<00:00,  1.67it/s, loss=5.954166, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000921218, METEOR=0.056208441] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: It's the Judge's song out of PINAFORE - no, I don't mean PINAFORE - I mean - you know what I mean - the other thing, you know.\n",
      "TARGET: È la canzone del Giudice del «Pinafore»... No, non volevo dire il «Pinafore»... volevo dire... già sapete ciò che volevo dire... quell’altro, sapete.\n",
      "PREDICTED: Io non ho ci ci ci ci ci ci ci ci ci ci ci ci ci ci ci ci ci ci ci ci ci ci ci ci ci ci ci ci ci ci ci ci ci . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 21: 100%|██████████| 534/534 [05:19<00:00,  1.67it/s, loss=5.959284, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000921218, METEOR=0.063135577] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: She came and shook hand with me when she heard that I was her governess; and as I led her in to breakfast, I addressed some phrases to her in her own tongue: she replied briefly at first, but after we were seated at the table, and she had examined me some ten minutes with her large hazel eyes, she suddenly commenced chattering fluently.\n",
      "TARGET: Nel condurla a colazione le rivolsi alcune parole nella sua lingua, alle quali rispose brevemente, ma dopo, a tavola, mi fissò con i suoi occhietti castani e incominciò a ciarlare.\n",
      "PREDICTED: Ella mi occhi , mi occhi , e mi occhi a occhi , e mi occhi a occhi , e mi occhi a occhi a occhi , e mi occhi , e mi occhi a occhi a occhi a occhi , e la , e mi occhi a occhi , e mi occhi , e la . a occhi a occhi a occhi . a occhi a occhi a occhi , mi occhi . , mi occhi , mi occhi , mi occhi , mi occhi . , mi . , mi , mi . , mi , mi me . , mi me a . , mi me a . , mi . . , mi me , mi , mi me . . , mi me a a a me mi me mi . . . a . , mi me , mi me mi me a me . . mi , mi me . , mi me mi me mi me . . mi me mi me mi me mi me mi me mi mi mi me mi me mi mi mi me mi me mi me mi me mi me mi me mi mi mi mi mi mi mi mi me mi me mi me mi me mi me mi mi mi me mi me mi me mi me mi me mi me mi me mi me mi me mi me mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 22: 100%|██████████| 534/534 [05:20<00:00,  1.67it/s, loss=5.839463, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.000724147, METEOR=0.065975296] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: And to do this we must lower the level of cultivation and give the peasants an interest in its success.\n",
      "TARGET: Ma per fare ciò, occorre abbassare il livello dell’azienda e interessare i lavoratori alla prosperità di questa.\n",
      "PREDICTED: E che il che il il che il . il ’ . . . . . . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 23: 100%|██████████| 534/534 [05:20<00:00,  1.66it/s, loss=5.937834, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:26<00:00,  3.73it/s, BLEU=0.001067039, METEOR=0.066425782] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: This pale crescent was \"the likeness of a kingly crown;\" what it diademed was \"the shape which shape had none.\"\n",
      "TARGET: Quella pallida aureola era l'emblema di una corona reale e circondava una testa senza corpo.\n",
      "PREDICTED: La giorno era era era era il , ma il ' era era , ma era . che era era era . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 24: 100%|██████████| 534/534 [05:20<00:00,  1.67it/s, loss=6.060523, lr=0.000000000]\n",
      "Processing validation examples: 100%|██████████| 324/324 [01:27<00:00,  3.72it/s, BLEU=0.000654340, METEOR=0.065190568] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Yet I saw abundance of fowls, but knew not their kinds; neither when I killed them could I tell what was fit for food, and what not.\n",
      "TARGET: Notai bensì una grande abbondanza di volatili senza conoscerne le specie, e senza poter nemmeno sapere, quando ne ebbi uccisi alcuni, quali fossero buoni per cibarsene e quali no.\n",
      "PREDICTED: Non non che non non che non che non che non che che che . non che non . che non che non . che non . che non non . che non . che non . che non . che non . che non . . che non . . che non . che non . . . che non . . . che non . . . che non . che non non non non . . . . . . . . . . . . . . che non . . non . . . . . . . . . . . . . . . . non non non non non non non non non non . . . . . . . . . . . . . . . . . . non . . . . non . . . non . . . . . . non . . . non . . . . . . . . . . . . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 25:  56%|█████▌    | 297/534 [02:58<02:22,  1.66it/s, loss=5.846130, lr=0.000000000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m batch_iterator \u001b[38;5;241m=\u001b[39m tqdm(train_dataloader, desc \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcessing epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# For each batch...\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m batch_iterator:\n\u001b[1;32m     12\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain() \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Loading input data and masks onto the GPU\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cursopytorch/lib/python3.10/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cursopytorch/lib/python3.10/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/cursopytorch/lib/python3.10/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/cursopytorch/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/cursopytorch/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[11], line 67\u001b[0m, in \u001b[0;36mBilingualDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     54\u001b[0m decoder_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m     55\u001b[0m     [\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msos_token, \u001b[38;5;66;03m# inserting the '[SOS]' token \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m     ]\n\u001b[1;32m     60\u001b[0m )\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Creating a label tensor, the expected output for training the model\u001b[39;00m\n\u001b[1;32m     63\u001b[0m label \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m     64\u001b[0m     [\n\u001b[1;32m     65\u001b[0m         torch\u001b[38;5;241m.\u001b[39mtensor(decoder_input_tokens, dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mint64), \u001b[38;5;66;03m# Inserting the tokenized target text\u001b[39;00m\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meos_token, \u001b[38;5;66;03m# Inserting the '[EOS]' token \u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdecoder_num_padding_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint64\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Adding padding tokens\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     ]\n\u001b[1;32m     69\u001b[0m )\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Ensuring that the length of each tensor above is equal to the defined 'seq_len'\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m encoder_input\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_seq_len\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in range(0, EPOCHS):\n",
    "        \n",
    "    # Initializing an iterator over the training dataloader\n",
    "    # We also use tqdm to display a progress bar\n",
    "    print()\n",
    "    batch_iterator = tqdm(train_dataloader, desc = f'Processing epoch {epoch:02d}')\n",
    "    \n",
    "    # For each batch...\n",
    "    for batch in batch_iterator:\n",
    "        model.train() # Train the model\n",
    "        \n",
    "        # Loading input data and masks onto the GPU\n",
    "        encoder_input = batch['encoder_input'].to(device)\n",
    "        decoder_input = batch['decoder_input'].to(device)\n",
    "        decoder_mask = batch['decoder_mask'].to(device)\n",
    "        \n",
    "        # Running tensors through the Transformer\n",
    "        encoder_output = model.encode(encoder_input)\n",
    "        decoder_output = model.decode(encoder_output, decoder_input, decoder_mask)\n",
    "        proj_output = model.projection(decoder_output)\n",
    "        \n",
    "        # Loading the target labels onto the GPU\n",
    "        label = batch['label'].to(device)\n",
    "        \n",
    "        # Computing loss between model's output and true labels\n",
    "        loss = loss_fn(proj_output.view(-1, tokenizer_target.get_vocab_size()), label.view(-1))\n",
    "        \n",
    "        # Updating progress bar, print loss and lr\n",
    "        batch_iterator.set_postfix({'loss': f'{loss.item():.6f}', 'lr': f'{actual_lr.get_lr():.9f}'})\n",
    "        \n",
    "        # Update LR\n",
    "        \n",
    "        # Performing backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Updating parameters based on the gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Clearing the gradients to prepare for the next batch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Update step and LR\n",
    "        if LR_SCHEDULER:\n",
    "            lr_scheduler.step()\n",
    "        \n",
    "    # We run the 'run_validation' function at the end of each epoch\n",
    "    # to evaluate model performance\n",
    "    validation_loop(model, validation_dataloader, tokenizer_source, tokenizer_target, max_sequence_len, device, lambda msg: batch_iterator.write(msg))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cursopytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
