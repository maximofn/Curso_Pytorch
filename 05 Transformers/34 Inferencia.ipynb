{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hemos entrenado nuestro transformer podemos probar a ver qué tal lo hace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos primero a implementar un transformer con todo el código que hemos usado antes, primero escribimos las funciones de bajo nivel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Embedding(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embedding(x)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, max_sequence_len, embedding_model_dim):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_model_dim\n",
    "        positional_encoding = torch.zeros(max_sequence_len, self.embedding_dim)\n",
    "        for pos in range(max_sequence_len):\n",
    "            for i in range(0, self.embedding_dim, 2):\n",
    "                positional_encoding[pos, i]     = torch.sin(torch.tensor(pos / (10000 ** ((2 * i) / self.embedding_dim))))\n",
    "                positional_encoding[pos, i + 1] = torch.cos(torch.tensor(pos / (10000 ** ((2 * (i+1)) / self.embedding_dim))))\n",
    "        positional_encoding = positional_encoding.unsqueeze(0)\n",
    "        self.register_buffer('positional_encoding', positional_encoding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x * torch.sqrt(torch.tensor(self.embedding_dim))\n",
    "        sequence_len = x.size(1)\n",
    "        x = x + self.positional_encoding[:,:sequence_len]\n",
    "        return x\n",
    "\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, dim_embedding):\n",
    "        super().__init__()\n",
    "        self.dim_embedding = dim_embedding\n",
    "    \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        key_trasposed = key.transpose(-1,-2)\n",
    "        product = torch.matmul(query, key_trasposed)\n",
    "        scale = product / torch.sqrt(torch.tensor(self.dim_embedding))\n",
    "        if mask is not None:\n",
    "            scale = scale.masked_fill(mask == 0, float('-inf'))\n",
    "        attention_matrix = torch.softmax(scale, dim=-1)\n",
    "        output = torch.matmul(attention_matrix, value)\n",
    "        return output\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, heads, dim_embedding):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dim_embedding = dim_embedding\n",
    "        self.dim_proyection = dim_embedding // heads\n",
    "        self.heads = heads\n",
    "        self.proyection_Q = nn.Linear(dim_embedding, dim_embedding)\n",
    "        self.proyection_K = nn.Linear(dim_embedding, dim_embedding)\n",
    "        self.proyection_V = nn.Linear(dim_embedding, dim_embedding)\n",
    "        self.attention = nn.Linear(dim_embedding, dim_embedding)\n",
    "        self.scaled_dot_product_attention = ScaledDotProductAttention(self.dim_proyection)\n",
    "    \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        batch_size = Q.size(0)\n",
    "        proyection_Q = self.proyection_Q(Q).view(batch_size, -1, self.heads, self.dim_proyection)\n",
    "        proyection_K = self.proyection_K(K).view(batch_size, -1, self.heads, self.dim_proyection)\n",
    "        proyection_V = self.proyection_V(V).view(batch_size, -1, self.heads, self.dim_proyection)\n",
    "        proyection_Q = proyection_Q.transpose(1,2)\n",
    "        proyection_K = proyection_K.transpose(1,2)\n",
    "        proyection_V = proyection_V.transpose(1,2)\n",
    "        scaled_dot_product_attention = self.scaled_dot_product_attention(proyection_Q, proyection_K, proyection_V, mask=mask)\n",
    "        concat = scaled_dot_product_attention.transpose(1,2).contiguous().view(batch_size, -1, self.dim_embedding)\n",
    "        output = self.attention(concat)\n",
    "        return output\n",
    "\n",
    "class AddAndNorm(nn.Module):\n",
    "    def __init__(self, dim_embedding):\n",
    "        super().__init__()\n",
    "        self.normalization = nn.LayerNorm(dim_embedding)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        return self.normalization(torch.add(x, sublayer))\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim_embedding, increment=4):\n",
    "        super().__init__()\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(dim_embedding, dim_embedding*increment),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dim_embedding*increment, dim_embedding)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.feed_forward(x)\n",
    "        return x\n",
    "\n",
    "class Linear(nn.Module):\n",
    "    def __init__(self, dim_embedding, vocab_size):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(dim_embedding, vocab_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "class Softmax(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "class Dropout(torch.nn.Module):\n",
    "    def __init__(self, p=0.1):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            return torch.nn.functional.dropout(x, p=self.p)\n",
    "        else:\n",
    "            return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora las clases de medio nivel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, heads, dim_embedding, prob_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.multi_head_attention = MultiHeadAttention(heads, dim_embedding)\n",
    "        self.dropout_1 = Dropout(prob_dropout)\n",
    "        self.add_and_norm_1 = AddAndNorm(dim_embedding)\n",
    "        self.feed_forward = FeedForward(dim_embedding)\n",
    "        self.dropout_2 = Dropout(prob_dropout)\n",
    "        self.add_and_norm_2 = AddAndNorm(dim_embedding)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        multi_head_attention = self.multi_head_attention(x, x, x)\n",
    "        dropout1 = self.dropout_1(multi_head_attention)\n",
    "        add_and_norm_1 = self.add_and_norm_1(x, dropout1)\n",
    "        feed_forward = self.feed_forward(add_and_norm_1)\n",
    "        dropout2 = self.dropout_2(feed_forward)\n",
    "        add_and_norm_2 = self.add_and_norm_2(add_and_norm_1, dropout2)\n",
    "        return add_and_norm_2\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, heads, dim_embedding, Nx, prob_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(heads, dim_embedding, prob_dropout) for _ in range(Nx)])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for encoder_layer in self.encoder_layers:\n",
    "            x = encoder_layer(x)\n",
    "        return x\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, dim_embedding, max_sequence_len, heads, Nx, prob_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.input_embedding = Embedding(vocab_size, dim_embedding)\n",
    "        self.positional_encoding = PositionalEncoding(max_sequence_len, dim_embedding)\n",
    "        self.encoder = Encoder(heads, dim_embedding, Nx, prob_dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        input_embedding = self.input_embedding(x)\n",
    "        positional_encoding = self.positional_encoding(input_embedding)\n",
    "        encoder = self.encoder(positional_encoding)\n",
    "        return encoder\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, heads, dim_embedding, prob_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.masked_multi_head_attention = MultiHeadAttention(heads, dim_embedding)\n",
    "        self.dropout_1 = Dropout(prob_dropout)\n",
    "        self.add_and_norm_1 = AddAndNorm(dim_embedding)\n",
    "        self.encoder_decoder_multi_head_attention = MultiHeadAttention(heads, dim_embedding)\n",
    "        self.dropout_2 = Dropout(prob_dropout)\n",
    "        self.add_and_norm_2 = AddAndNorm(dim_embedding)\n",
    "        self.feed_forward = FeedForward(dim_embedding)\n",
    "        self.dropout_3 = Dropout(prob_dropout)\n",
    "        self.add_and_norm_3 = AddAndNorm(dim_embedding)\n",
    "    \n",
    "    def forward(self, x, encoder_output, mask=None):\n",
    "        Q = x\n",
    "        K = x\n",
    "        V = x\n",
    "        masked_multi_head_attention = self.masked_multi_head_attention(Q, K, V, mask=mask)\n",
    "        dropout1 = self.dropout_1(masked_multi_head_attention)\n",
    "        add_and_norm_1 = self.add_and_norm_1(dropout1, x)\n",
    "\n",
    "        Q = add_and_norm_1\n",
    "        K = encoder_output\n",
    "        V = encoder_output\n",
    "        encoder_decoder_multi_head_attention = self.encoder_decoder_multi_head_attention(Q, K, V)\n",
    "        dropout2 = self.dropout_2(encoder_decoder_multi_head_attention)\n",
    "        add_and_norm_2 = self.add_and_norm_2(dropout2, add_and_norm_1)\n",
    "\n",
    "        feed_forward = self.feed_forward(add_and_norm_2)\n",
    "        dropout3 = self.dropout_3(feed_forward)\n",
    "        add_and_norm_3 = self.add_and_norm_3(dropout3, add_and_norm_2)\n",
    "\n",
    "        return add_and_norm_3\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, heads, dim_embedding, Nx, prob_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([DecoderLayer(heads, dim_embedding, prob_dropout) for _ in range(Nx)])\n",
    "    \n",
    "    def forward(self, x, encoder_output, mask=None):\n",
    "        for decoder_layer in self.layers:\n",
    "            x = decoder_layer(x, encoder_output, mask)\n",
    "        return x\n",
    "\n",
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, heads, dim_embedding, Nx, vocab_size, max_sequence_len, prob_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embedding = Embedding(vocab_size, dim_embedding)\n",
    "        self.positional_encoding = PositionalEncoding(max_sequence_len, dim_embedding)\n",
    "        self.decoder = Decoder(heads, dim_embedding, Nx, prob_dropout)\n",
    "        self.linear = Linear(dim_embedding, vocab_size)\n",
    "        self.softmax = Softmax()\n",
    "    \n",
    "    def forward(self, x, encoder_output, mask=None):\n",
    "        x = self.embedding(x)\n",
    "        x = self.positional_encoding(x)\n",
    "        x = self.decoder(x, encoder_output, mask)\n",
    "        x = self.linear(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y por último la clase transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_size, dim_embedding, max_sequence_len, heads, Nx, prob_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.encoder = TransformerEncoder(vocab_size, dim_embedding, max_sequence_len, heads, Nx, prob_dropout)\n",
    "        self.decoder = TransformerDecoder(heads, dim_embedding, Nx, vocab_size, max_sequence_len, prob_dropout)\n",
    "    \n",
    "    def forward(self, source, target, mask=None):\n",
    "        encoder_output = self.encoder(source)\n",
    "        decoder_output = self.decoder(target, encoder_output, mask)\n",
    "        return decoder_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos la máscara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(sequence_len):\n",
    "    mask = torch.tril(torch.ones((sequence_len, sequence_len)))\n",
    "    return mask\n",
    "\n",
    "max_secuence_length = 10 + 2\n",
    "mask = create_mask(max_secuence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora creamos un objeto del transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 100277, dim_embedding: 64, max_secuence_length: 12, heads: 8, Nx: 6, prob_dropout: 0.1\n",
      "Modelo de 20.053877 millones de parámetros\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoder = tiktoken.get_encoding(\"cl100k_base\")\n",
    "vocab_size = encoder.n_vocab\n",
    "dim_embedding = 512\n",
    "heads = 8\n",
    "Nx = 6\n",
    "prob_dropout = 0.1\n",
    "print(f\"vocab_size: {vocab_size}, dim_embedding: {dim_embedding}, max_secuence_length: {max_secuence_length}, heads: {heads}, Nx: {Nx}, prob_dropout: {prob_dropout}\")\n",
    "\n",
    "transformer = Transformer(vocab_size=vocab_size,\n",
    "                          dim_embedding=dim_embedding,\n",
    "                          max_sequence_len=max_secuence_length,\n",
    "                          heads=heads,\n",
    "                          Nx=Nx,\n",
    "                          prob_dropout=prob_dropout)\n",
    "print(f\"Modelo de {sum(p.numel() for p in transformer.parameters())/1e6} millones de parámetros\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo de 198.264245 millones de parámetros\n"
     ]
    }
   ],
   "source": [
    "print(f\"Modelo de {sum(p.numel() for p in transformer.parameters())/1e6} millones de parámetros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferencia con modelo sin entrenar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver el resultado del transformer sin entrenarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_token: [189], end_token: [190], padding_token: [191]\n"
     ]
    }
   ],
   "source": [
    "start_token = chr(1)\n",
    "start_token = encoder.encode(start_token)\n",
    "\n",
    "end_token = chr(2)\n",
    "end_token = encoder.encode(end_token)\n",
    "\n",
    "padding_token = chr(3)\n",
    "padding_token = encoder.encode(padding_token)\n",
    "\n",
    "print(f\"start_token: {start_token}, end_token: {end_token}, padding_token: {padding_token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_source_sentence(sentence, start_token, end_token, pad_token, max_length, device):\n",
    "    sentence = encoder.encode(sentence)\n",
    "    sentence = start_token + sentence + end_token\n",
    "    if len(sentence) < max_length:\n",
    "        sentence = sentence + pad_token * (max_length - len(sentence))\n",
    "    else:\n",
    "        sentence = sentence[:max_length]\n",
    "    sentence = torch.tensor([sentence]).to(device)\n",
    "    return sentence\n",
    "\n",
    "def prepare_target_sentence(sentence, start_token, pad_token, max_length, device):\n",
    "    sentence = encoder.encode(sentence)\n",
    "    sentence = start_token + sentence + end_token\n",
    "    if len(sentence) < max_length:\n",
    "        sentence = sentence + pad_token * (max_length - len(sentence))\n",
    "    else:\n",
    "        sentence = sentence[:max_length]\n",
    "    sentence = torch.tensor([sentence]).to(device)\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encode english sencence: tensor([[ 189,   40,  617, 9687,  264, 2763,  505,  420, 3388,  190,  191,  191]])\n",
      "English sencence shape: torch.Size([1, 12])\n"
     ]
    }
   ],
   "source": [
    "sentence_en = \"I have learned a lot from this course\"\n",
    "encode_sentence_en = prepare_source_sentence(sentence_en, start_token, end_token, padding_token, max_secuence_length, device)\n",
    "print(f\"Encode english sencence: {encode_sentence_en}\")\n",
    "print(f\"English sencence shape: {encode_sentence_en.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encode spanish sentence: tensor([[189, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191]])\n",
      "Spanish sentence shape: torch.Size([1, 12])\n"
     ]
    }
   ],
   "source": [
    "sentence_es = \"\"\n",
    "encode_sentence_es = prepare_target_sentence(sentence_es, start_token, padding_token, max_secuence_length, device)\n",
    "print(f\"Encode spanish sentence: {encode_sentence_es}\")\n",
    "print(f\"Spanish sentence shape: {encode_sentence_es.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_sentence(source, target, mask, model, device, end_token, max_len):\n",
    "    model = model.to(device)\n",
    "    # model.eval()\n",
    "    source = source.to(device)\n",
    "    target = target.to(device)\n",
    "    mask = mask.to(device)\n",
    "    end_token = torch.tensor(end_token)\n",
    "    output_sentence = target.clone()\n",
    "\n",
    "    for i in range(max_len-2):\n",
    "        with torch.no_grad():\n",
    "            output = model(source, target, mask)\n",
    "            next_token = output[0, i+1].argmax().item()\n",
    "            output_sentence[0, i+1] = next_token\n",
    "            if next_token == end_token:\n",
    "                break\n",
    "    output_sentence[0, max_len-1] = end_token\n",
    "\n",
    "    return output_sentence\n",
    "\n",
    "def decode_sentence(sentence, decoder, end_token):\n",
    "    decoded = \"\"\n",
    "    if isinstance(end_token, list):\n",
    "        end_token = end_token[0]\n",
    "    if isinstance(sentence, torch.Tensor):\n",
    "        sentence = sentence.cpu().numpy()\n",
    "    if end_token in sentence:\n",
    "        position_end_token = int(np.where(sentence == end_token)[0])\n",
    "        sentence = sentence[:position_end_token+1]\n",
    "    sentence = sentence[1:-1]   # Remove start and end token\n",
    "    decoded = decoder(sentence)\n",
    "    return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded output: [  189 20175 50518 38440 39050 90818 90818 90818 90818 62407 62407   190]\n",
      "Decoded output: Aut diagnostics.AbstractImGuiremaremaremarema assemblies assemblies\n"
     ]
    }
   ],
   "source": [
    "encoded_output = get_target_sentence(encode_sentence_en, encode_sentence_es, mask, transformer, device, end_token, max_secuence_length).squeeze(0).cpu().numpy()\n",
    "print(f\"Encoded output: {encoded_output}\")\n",
    "\n",
    "decoded_output = decode_sentence(encoded_output, encoder.decode, max_secuence_length)\n",
    "print(f\"Decoded output: {decoded_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferencia con modelo entrenado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 188"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel\n"
     ]
    }
   ],
   "source": [
    "weights = \"model/transformer_model_188_138556.pth\"\n",
    "transformer = torch.load(weights, map_location='cpu')\n",
    "\n",
    "if isinstance(transformer, nn.DataParallel):\n",
    "    print(\"DataParallel\")\n",
    "    transformer = transformer.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded output: [  189 24652  1933 11532 47012 92908  2247  2247  2247  2247  2247   190]\n",
      "Decoded output: ajs color_qu获取 nex\",\"\",\"\",\"\",\"\",\"\n"
     ]
    }
   ],
   "source": [
    "encoded_output = get_target_sentence(encode_sentence_en, encode_sentence_es, mask, transformer, device, end_token, max_secuence_length).squeeze(0).cpu().numpy()\n",
    "print(f\"Encoded output: {encoded_output}\")\n",
    "\n",
    "decoded_output = decode_sentence(encoded_output, encoder.decode, max_secuence_length)\n",
    "print(f\"Decoded output: {decoded_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 296"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel\n"
     ]
    }
   ],
   "source": [
    "weights = \"model/transformer_model_296_218152.pth\"\n",
    "transformer = torch.load(weights, map_location='cpu')\n",
    "\n",
    "if isinstance(transformer, nn.DataParallel):\n",
    "    print(\"DataParallel\")\n",
    "    transformer = transformer.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded output: [   189 100068   1933  18572  23245  90347   2247   2247   2247   2247\n",
      "   2247    190]\n",
      "Decoded output: Seats color399 Antonio awakened\",\"\",\"\",\"\",\"\",\"\n"
     ]
    }
   ],
   "source": [
    "encoded_output = get_target_sentence(encode_sentence_en, encode_sentence_es, mask, transformer, device, end_token, max_secuence_length).squeeze(0).cpu().numpy()\n",
    "print(f\"Encoded output: {encoded_output}\")\n",
    "\n",
    "decoded_output = decode_sentence(encoded_output, encoder.decode, max_secuence_length)\n",
    "print(f\"Decoded output: {decoded_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 309"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel\n"
     ]
    }
   ],
   "source": [
    "weights = \"model/transformer_model_309_227733.pth\"\n",
    "transformer = torch.load(weights, map_location='cpu')\n",
    "\n",
    "if isinstance(transformer, nn.DataParallel):\n",
    "    print(\"DataParallel\")\n",
    "    transformer = transformer.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded output: [   189 100068   1933  18572  23245  90347   2247   2247   2247   2247\n",
      "   2247    190]\n",
      "Decoded output: Seats color399 Antonio awakened\",\"\",\"\",\"\",\"\",\"\n"
     ]
    }
   ],
   "source": [
    "encoded_output = get_target_sentence(encode_sentence_en, encode_sentence_es, mask, transformer, device, end_token, max_secuence_length).squeeze(0).cpu().numpy()\n",
    "print(f\"Encoded output: {encoded_output}\")\n",
    "\n",
    "decoded_output = decode_sentence(encoded_output, encoder.decode, max_secuence_length)\n",
    "print(f\"Decoded output: {decoded_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 331"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel\n"
     ]
    }
   ],
   "source": [
    "weights = \"model/transformer_model_331_243947.pth\"\n",
    "transformer = torch.load(weights, map_location='cpu')\n",
    "\n",
    "if isinstance(transformer, nn.DataParallel):\n",
    "    print(\"DataParallel\")\n",
    "    transformer = transformer.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded output: [   189 100068   1933  18572  40955  90347   2247   2247   2247   2247\n",
      "   2247    190]\n",
      "Decoded output: Seats color399ต awakened\",\"\",\"\",\"\",\"\",\"\n"
     ]
    }
   ],
   "source": [
    "encoded_output = get_target_sentence(encode_sentence_en, encode_sentence_es, mask, transformer, device, end_token, max_secuence_length).squeeze(0).cpu().numpy()\n",
    "print(f\"Encoded output: {encoded_output}\")\n",
    "\n",
    "decoded_output = decode_sentence(encoded_output, encoder.decode, max_secuence_length)\n",
    "print(f\"Decoded output: {decoded_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 509"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel\n"
     ]
    }
   ],
   "source": [
    "weights = \"model/transformer_model_509_375133.pth\"\n",
    "transformer = torch.load(weights, map_location='cpu')\n",
    "\n",
    "if isinstance(transformer, nn.DataParallel):\n",
    "    print(\"DataParallel\")\n",
    "    transformer = transformer.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded output: [   189 100068   1933  40955  26066  92908   2247   2247   2247   2247\n",
      "   2247    190]\n",
      "Decoded output: Seats colorตIGNED nex\",\"\",\"\",\"\",\"\",\"\n"
     ]
    }
   ],
   "source": [
    "encoded_output = get_target_sentence(encode_sentence_en, encode_sentence_es, mask, transformer, device, end_token, max_secuence_length).squeeze(0).cpu().numpy()\n",
    "print(f\"Encoded output: {encoded_output}\")\n",
    "\n",
    "decoded_output = decode_sentence(encoded_output, encoder.decode, max_secuence_length)\n",
    "print(f\"Decoded output: {decoded_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 564"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel\n"
     ]
    }
   ],
   "source": [
    "weights = \"model/transformer_model_564_1104078.pth\"\n",
    "transformer = torch.load(weights, map_location='cpu')\n",
    "\n",
    "if isinstance(transformer, nn.DataParallel):\n",
    "    print(\"DataParallel\")\n",
    "    transformer = transformer.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded output: [  189 50165 68892 68892 86785 68983 56827 23109 23109 23109 23109   190]\n",
      "Decoded output: .NAMEFIRSTFIRST Salvation_spaces watcher Ka Ka Ka Ka\n"
     ]
    }
   ],
   "source": [
    "encoded_output = get_target_sentence(encode_sentence_en, encode_sentence_es, mask, transformer, device, end_token, max_secuence_length).squeeze(0).cpu().numpy()\n",
    "print(f\"Encoded output: {encoded_output}\")\n",
    "\n",
    "decoded_output = decode_sentence(encoded_output, encoder.decode, max_secuence_length)\n",
    "print(f\"Decoded output: {decoded_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 595"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel\n"
     ]
    }
   ],
   "source": [
    "weights = \"model/transformer_model_595_1256474.pth\"\n",
    "transformer = torch.load(weights, map_location='cpu')\n",
    "\n",
    "if isinstance(transformer, nn.DataParallel):\n",
    "    print(\"DataParallel\")\n",
    "    transformer = transformer.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded output: [  189 50165 47097 47097 86785 93615 56827 23109 23109 23109 23109   190]\n",
      "Decoded output: .NAME marca marca Salvation()=> watcher Ka Ka Ka Ka\n"
     ]
    }
   ],
   "source": [
    "encoded_output = get_target_sentence(encode_sentence_en, encode_sentence_es, mask, transformer, device, end_token, max_secuence_length).squeeze(0).cpu().numpy()\n",
    "print(f\"Encoded output: {encoded_output}\")\n",
    "\n",
    "decoded_output = decode_sentence(encoded_output, encoder.decode, max_secuence_length)\n",
    "print(f\"Decoded output: {decoded_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 619"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel\n"
     ]
    }
   ],
   "source": [
    "weights = \"model/transformer_model_619_1374458.pth\"\n",
    "transformer = torch.load(weights, map_location='cpu')\n",
    "\n",
    "if isinstance(transformer, nn.DataParallel):\n",
    "    print(\"DataParallel\")\n",
    "    transformer = transformer.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded output: [  189 50165 47097 47097 86785 93615 56827 23109 23109 23109 23109   190]\n",
      "Decoded output: .NAME marca marca Salvation()=> watcher Ka Ka Ka Ka\n"
     ]
    }
   ],
   "source": [
    "encoded_output = get_target_sentence(encode_sentence_en, encode_sentence_es, mask, transformer, device, end_token, max_secuence_length).squeeze(0).cpu().numpy()\n",
    "print(f\"Encoded output: {encoded_output}\")\n",
    "\n",
    "decoded_output = decode_sentence(encoded_output, encoder.decode, max_secuence_length)\n",
    "print(f\"Decoded output: {decoded_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 643"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel\n"
     ]
    }
   ],
   "source": [
    "weights = \"model/transformer_model_643_1492442.pth\"\n",
    "transformer = torch.load(weights, map_location='cpu')\n",
    "\n",
    "if isinstance(transformer, nn.DataParallel):\n",
    "    print(\"DataParallel\")\n",
    "    transformer = transformer.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded output: [  189 50165 19541 47097 86785 93615 56827 23109 23109 23109 23109   190]\n",
      "Decoded output: .NAME ny marca Salvation()=> watcher Ka Ka Ka Ka\n"
     ]
    }
   ],
   "source": [
    "encoded_output = get_target_sentence(encode_sentence_en, encode_sentence_es, mask, transformer, device, end_token, max_secuence_length).squeeze(0).cpu().numpy()\n",
    "print(f\"Encoded output: {encoded_output}\")\n",
    "\n",
    "decoded_output = decode_sentence(encoded_output, encoder.decode, max_secuence_length)\n",
    "print(f\"Decoded output: {decoded_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 667"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel\n"
     ]
    }
   ],
   "source": [
    "weights = \"model/transformer_model_667_1610426.pth\"\n",
    "transformer = torch.load(weights, map_location='cpu')\n",
    "\n",
    "if isinstance(transformer, nn.DataParallel):\n",
    "    print(\"DataParallel\")\n",
    "    transformer = transformer.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded output: [  189 19541 19541 56060 86785 93615 93075 56827 23109 23109 23109   190]\n",
      "Decoded output:  ny ny Prayer Salvation()=> Restrictions watcher Ka Ka Ka\n"
     ]
    }
   ],
   "source": [
    "encoded_output = get_target_sentence(encode_sentence_en, encode_sentence_es, mask, transformer, device, end_token, max_secuence_length).squeeze(0).cpu().numpy()\n",
    "print(f\"Encoded output: {encoded_output}\")\n",
    "\n",
    "decoded_output = decode_sentence(encoded_output, encoder.decode, max_secuence_length)\n",
    "print(f\"Decoded output: {decoded_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 691"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel\n"
     ]
    }
   ],
   "source": [
    "weights = \"model/transformer_model_691_1728410.pth\"\n",
    "transformer = torch.load(weights, map_location='cpu')\n",
    "\n",
    "if isinstance(transformer, nn.DataParallel):\n",
    "    print(\"DataParallel\")\n",
    "    transformer = transformer.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded output: [  189 19541 19541 56060   409 93615 93075 56827 23109 23109  2158   190]\n",
      "Decoded output:  ny ny Prayer de()=> Restrictions watcher Ka Kaftware\n"
     ]
    }
   ],
   "source": [
    "encoded_output = get_target_sentence(encode_sentence_en, encode_sentence_es, mask, transformer, device, end_token, max_secuence_length).squeeze(0).cpu().numpy()\n",
    "print(f\"Encoded output: {encoded_output}\")\n",
    "\n",
    "decoded_output = decode_sentence(encoded_output, encoder.decode, max_secuence_length)\n",
    "print(f\"Decoded output: {decoded_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 718"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel\n"
     ]
    }
   ],
   "source": [
    "weights = \"model/transformer_model_718_1861142.pth\"\n",
    "transformer = torch.load(weights, map_location='cpu')\n",
    "\n",
    "if isinstance(transformer, nn.DataParallel):\n",
    "    print(\"DataParallel\")\n",
    "    transformer = transformer.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded output: [  189 19541 19541 56060   409 93615 93075 93075 23109  2158  2158   190]\n",
      "Decoded output:  ny ny Prayer de()=> Restrictions Restrictions Kaftwareftware\n"
     ]
    }
   ],
   "source": [
    "encoded_output = get_target_sentence(encode_sentence_en, encode_sentence_es, mask, transformer, device, end_token, max_secuence_length).squeeze(0).cpu().numpy()\n",
    "print(f\"Encoded output: {encoded_output}\")\n",
    "\n",
    "decoded_output = decode_sentence(encoded_output, encoder.decode, max_secuence_length)\n",
    "print(f\"Decoded output: {decoded_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 748"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel\n"
     ]
    }
   ],
   "source": [
    "weights = \"model/transformer_model_748_2008622.pth\"\n",
    "transformer = torch.load(weights, map_location='cpu')\n",
    "\n",
    "if isinstance(transformer, nn.DataParallel):\n",
    "    print(\"DataParallel\")\n",
    "    transformer = transformer.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded output: [  189 19541 56060 22180   409   409 93075 65612 65612  2158  2158   190]\n",
      "Decoded output:  ny Prayer ale de de Restrictions.Cmd.Cmdftwareftware\n"
     ]
    }
   ],
   "source": [
    "encoded_output = get_target_sentence(encode_sentence_en, encode_sentence_es, mask, transformer, device, end_token, max_secuence_length).squeeze(0).cpu().numpy()\n",
    "print(f\"Encoded output: {encoded_output}\")\n",
    "\n",
    "decoded_output = decode_sentence(encoded_output, encoder.decode, max_secuence_length)\n",
    "print(f\"Decoded output: {decoded_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 813"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel\n"
     ]
    }
   ],
   "source": [
    "weights = \"model/transformer_model_813_2328162.pth\"\n",
    "transformer = torch.load(weights, map_location='cpu')\n",
    "\n",
    "if isinstance(transformer, nn.DataParallel):\n",
    "    print(\"DataParallel\")\n",
    "    transformer = transformer.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded output: [  189 74426 56060 22180   409   409 93075 93075   329  1832  2158   190]\n",
      "Decoded output:  getModel Prayer ale de de Restrictions Restrictionsadóftware\n"
     ]
    }
   ],
   "source": [
    "encoded_output = get_target_sentence(encode_sentence_en, encode_sentence_es, mask, transformer, device, end_token, max_secuence_length).squeeze(0).cpu().numpy()\n",
    "print(f\"Encoded output: {encoded_output}\")\n",
    "\n",
    "decoded_output = decode_sentence(encoded_output, encoder.decode, max_secuence_length)\n",
    "print(f\"Decoded output: {decoded_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 830"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel\n"
     ]
    }
   ],
   "source": [
    "weights = \"model/transformer_model_830_2411734.pth\"\n",
    "transformer = torch.load(weights, map_location='cpu')\n",
    "\n",
    "if isinstance(transformer, nn.DataParallel):\n",
    "    print(\"DataParallel\")\n",
    "    transformer = transformer.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded output: [  189 74426 56060 22180   409   409 93075 93075   329   329  2158   190]\n",
      "Decoded output:  getModel Prayer ale de de Restrictions Restrictionsadadftware\n"
     ]
    }
   ],
   "source": [
    "encoded_output = get_target_sentence(encode_sentence_en, encode_sentence_es, mask, transformer, device, end_token, max_secuence_length).squeeze(0).cpu().numpy()\n",
    "print(f\"Encoded output: {encoded_output}\")\n",
    "\n",
    "decoded_output = decode_sentence(encoded_output, encoder.decode, max_secuence_length)\n",
    "print(f\"Decoded output: {decoded_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 845"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel\n"
     ]
    }
   ],
   "source": [
    "weights = \"model/transformer_model_845_2485474.pth\"\n",
    "transformer = torch.load(weights, map_location='cpu')\n",
    "\n",
    "if isinstance(transformer, nn.DataParallel):\n",
    "    print(\"DataParallel\")\n",
    "    transformer = transformer.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded output: [  189 74426 56060 22180   409   409 93075 93075   329   329  2158   190]\n",
      "Decoded output:  getModel Prayer ale de de Restrictions Restrictionsadadftware\n"
     ]
    }
   ],
   "source": [
    "encoded_output = get_target_sentence(encode_sentence_en, encode_sentence_es, mask, transformer, device, end_token, max_secuence_length).squeeze(0).cpu().numpy()\n",
    "print(f\"Encoded output: {encoded_output}\")\n",
    "\n",
    "decoded_output = decode_sentence(encoded_output, encoder.decode, max_secuence_length)\n",
    "print(f\"Decoded output: {decoded_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 917"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel\n"
     ]
    }
   ],
   "source": [
    "weights = \"model/transformer_model_917_2839426.pth\"\n",
    "transformer = torch.load(weights, map_location='cpu')\n",
    "\n",
    "if isinstance(transformer, nn.DataParallel):\n",
    "    print(\"DataParallel\")\n",
    "    transformer = transformer.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded output: [  189 74426   300   409    11    11  1832   329   329   329  2158   190]\n",
      "Decoded output:  getModelas de,,óadadadftware\n"
     ]
    }
   ],
   "source": [
    "encoded_output = get_target_sentence(encode_sentence_en, encode_sentence_es, mask, transformer, device, end_token, max_secuence_length).squeeze(0).cpu().numpy()\n",
    "print(f\"Encoded output: {encoded_output}\")\n",
    "\n",
    "decoded_output = decode_sentence(encoded_output, encoder.decode, max_secuence_length)\n",
    "print(f\"Decoded output: {decoded_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 937"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel\n"
     ]
    }
   ],
   "source": [
    "weights = \"model/transformer_model_937_2937746.pth\"\n",
    "transformer = torch.load(weights, map_location='cpu')\n",
    "\n",
    "if isinstance(transformer, nn.DataParallel):\n",
    "    print(\"DataParallel\")\n",
    "    transformer = transformer.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded output: [  189 74426   735   409   409   409  1832  9779   329   329  1832   190]\n",
      "Decoded output:  getModel K de de deóaceradadó\n"
     ]
    }
   ],
   "source": [
    "encoded_output = get_target_sentence(encode_sentence_en, encode_sentence_es, mask, transformer, device, end_token, max_secuence_length).squeeze(0).cpu().numpy()\n",
    "print(f\"Encoded output: {encoded_output}\")\n",
    "\n",
    "decoded_output = decode_sentence(encoded_output, encoder.decode, max_secuence_length)\n",
    "print(f\"Decoded output: {decoded_output}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cursopytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
