{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tensores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ¿Qué son los tensores?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Los [tensores](https://pytorch.org/docs/stable/tensors.html) son una estructura de datos multidimensional que contiene elementos de un solo tipo de datos.\n",
        "\n",
        "En PyTorch, se usan tensores para codificar las entradas y salidas de un modelo, así como los parámetros del modelo.\n",
        "\n",
        "Los tensores son similares a los ndarrays de NumPy, excepto que los tensores pueden ejecutarse en GPU u otros aceleradores de hardware. De hecho, los tensores y las matrices de NumPy a menudo pueden compartir la misma memoria subyacente, lo que elimina la necesidad de copiar datos.\n",
        "\n",
        "Los tensores también están optimizados para la diferenciación automática (Autograd)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tipo de datos de los tensores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Los tensores pueden tener los siguientes tipos de datos con variantes de CPU y GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "|Tipo de datos|dtype|Tensor de CPU|Tensor de GPU|\n",
        "|------|------|------|------|\n",
        "|Punto flotante de 32 bits|``torch.float32`` o ``torch.float``|``torch.FloatTensor``|``torch.cuda.FloatTensor``|\n",
        "|Punto flotante de 64 bits|``torch.float64`` o ``torch.double``|``torch.DoubleTensor``|``torch.cuda.DoubleTensor``|\n",
        "|Coma flotante de 16 bits|``torch.float16`` o ``torch.half``|``torch.HalfTensor``|``torch.cuda.HalfTensor``|\n",
        "|Coma flotante de 16 bits|``torch.bfloat16``|``torch.BFloat16Tensor``|``torch.cuda.BFloat16Tensor``|\n",
        "|Complejo de 32 bits|``torch.complex32``|||\n",
        "|Complejo de 64 bits|``torch.complex64``|||\n",
        "|Complejo de 128 bits|``torch.complex128`` o ``torch.cdouble``|||\n",
        "|Entero de 8 bits (sin signo)|``torch.uint8``|``torch.ByteTensor``|``torch.cuda.ByteTensor``|\n",
        "|Entero de 8 bits (con signo)|``torch.int8``|``torch.CharTensor``|``torch.cuda.CharTensor``|\n",
        "|Entero de 16 bits (con signo)|``torch.int16`` o ``torch.short``|``torch.ShortTensor``|``torch.cuda.ShortTensor``|\n",
        "|Entero de 32 bits (con signo)|``torch.int32`` o ``torch.int``|``torch.IntTensor``|``torch.cuda.IntTensor``|\n",
        "|Entero de 64 bits (con signo)|``torch.int64`` o ``torch.long``|``torch.LongTensor``|``torch.cuda.LongTensor``|\n",
        "|Booleano|``torch.bool``|``torch.BoolTensor``|``torch.cuda.BoolTensor``|\n",
        "|entero cuantificado de 8 bits (sin signo)|``torch.quint8``|``torch.ByteTensor``|/|\n",
        "|entero de 8 bits cuantificado (con signo)|``torch.qint8``|``torch.CharTensor``|/|\n",
        "|entero cuantificado de 32 bits (con signo)|``torch.qfint32``|``torch.IntTensor``|/|\n",
        "|entero cuantificado de 4 bits (sin signo)|``torch.quint4x2``|torch.ByteTensor|/|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inicialización de tensores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hay muchas maneras de [inicializar un tensor](https://pytorch.org/docs/stable/torch.html#tensor-creation-ops), aquí se muestran algunas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Directamente con datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = [[1, 2],[3, 4]]\n",
        "x_data = torch.tensor(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Desde un array de NumPy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La matriz de Numpy y el Tensor comparten memoria, si se modifica uno se ve reflejado el cambio en el otro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Numpy matrix: \n",
            " [[ 99   2]\n",
            " [  3 100]] \n",
            "\n",
            "Tensor: \n",
            " tensor([[ 99,   2],\n",
            "        [  3, 100]], dtype=torch.int32) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "np_array[0, 0] = 99\n",
        "x_np[1, 1] = 100\n",
        "\n",
        "print(f\"Numpy matrix: \\n {np_array} \\n\")\n",
        "print(f\"Tensor: \\n {x_np} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Esto es así, aunque el tensor esté en la GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Numpy matrix: \n",
            " [[ 99   2]\n",
            " [  3 101]] \n",
            "\n",
            "Tensor: \n",
            " tensor([[ 99,   2],\n",
            "        [  3, 101]], dtype=torch.int32) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "gpu_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "cpu_device = \"cpu\"\n",
        "\n",
        "x_np.to(gpu_device)\n",
        "\n",
        "x_np[1, 1] = 101\n",
        "\n",
        "print(f\"Numpy matrix: \\n {np_array} \\n\")\n",
        "print(f\"Tensor: \\n {x_np} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Desde otro tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.2517, 0.8286],\n",
            "        [0.0082, 0.3182]]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Con valores aleatorios o constnates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Tensor: \n",
            " tensor([[0.4184, 0.1314, 0.7662],\n",
            "        [0.9868, 0.1299, 0.4800]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]]) \n",
            "\n",
            "Zeros Tensor: \n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ],
      "source": [
        "shape = (2,3,)\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cambiar el tipo de datos de un tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para cambiar el tipo de datos de un tensor hay que usar el atributo ``dtype``"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor con datos de tipo entero de 32 bits: \n",
            " tensor([[1, 2],\n",
            "        [3, 4]], dtype=torch.int32)\n",
            "Tensor con datos de tipo entero de 8 bits: \n",
            " tensor([[1, 2],\n",
            "        [3, 4]], dtype=torch.int8)\n"
          ]
        }
      ],
      "source": [
        "data = [[1, 2],[3, 4]]\n",
        "x_np_32 = torch.tensor(data, dtype=torch.int32)\n",
        "x_np_8 = torch.tensor(data, dtype=torch.int8)\n",
        "\n",
        "print(f\"Tensor con datos de tipo entero de 32 bits: \\n {x_np_32}\")\n",
        "print(f\"Tensor con datos de tipo entero de 8 bits: \\n {x_np_8}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tener el tensor en la GPU o en la CPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aunque ya se ha mostrado antes, se puede tener el tensor en la CPU o en la GPU (si se tiene una GPU Nvidia). Al tener el tensor en la GPU se puede aprovechar la capacidad del procesamiento en paralelo\n",
        "\n",
        "Para pasar el tensr a la GPU se puede usar el parámetro ``device`` o usar el método ``to()``"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor en la CPU: \n",
            " tensor([[1, 2],\n",
            "        [3, 4]]) \n",
            "\n",
            "Tensor 1 en la GPU: \n",
            " tensor([[1, 2],\n",
            "        [3, 4]], device='cuda:0') \n",
            "\n",
            "Tensor 2 en la GPU: \n",
            " tensor([[1, 2],\n",
            "        [3, 4]], device='cuda:0') \n",
            "\n"
          ]
        }
      ],
      "source": [
        "gpu_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "cpu_device = \"cpu\"\n",
        "\n",
        "data = [[1, 2],[3, 4]]\n",
        "x_np_CPU = torch.tensor(data, device=cpu_device)\n",
        "x_np_GPU1 = torch.tensor(data, device=gpu_device)\n",
        "x_np_GPU2 = x_np_CPU.to(gpu_device)\n",
        "\n",
        "print(f\"Tensor en la CPU: \\n {x_np_CPU} \\n\")\n",
        "print(f\"Tensor 1 en la GPU: \\n {x_np_GPU1} \\n\")\n",
        "print(f\"Tensor 2 en la GPU: \\n {x_np_GPU2} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Atributos de un tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se pueden obtener los atributos de un tensor, como el tamaño, el tipo y el dispositivo en el que está"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.rand(3,4)\n",
        "\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Operaciones con Tensores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hay más de 100 operaciones con tensores, en este [enlace](https://pytorch.org/docs/stable/torch.html). Cada una de estas operaciones se puede ejecutar en la GPU (normalmente a velocidades más altas que en una CPU).\n",
        "\n",
        "De forma predeterminada, los tensores se crean en la CPU. Necesitamos mover explícitamente los tensores a la GPU usando el método .to (después de verificar la disponibilidad de la GPU). Hay que tener en cuenta que copiar grandes tensores entre dispositivos puede resultar caro en términos de tiempo y memoria."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device tensor is stored on: cuda:0\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    tensor = tensor.to('cuda')\n",
        "\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Veamos algunas de las operaciones. Al ser muy similares a Numpy, la API de Tensor es muy fácil de usar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Indexación y segmentación como en Numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First row:  tensor([1., 1., 1., 1.])\n",
            "First column:  tensor([1., 1., 1., 1.])\n",
            "Last column: tensor([1., 1., 1., 1.])\n",
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.ones(4, 4)\n",
        "print('First row: ', tensor[0])\n",
        "print('First column: ', tensor[:, 0])\n",
        "print('Last column:', tensor[..., -1])\n",
        "tensor[:,1] = 0\n",
        "print(tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Unión de tensores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se puede utilizar ``torch.cat`` para concatenar una secuencia de tensores a lo largo de una dimensión determinada. También se puede usar ``torch.stack`` para unir otro tensor y es sutilmente diferente de ``torch.cat``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Operaciones aritméticas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "matrix multiplication: \n",
            " tensor([[3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.]]) \n",
            "\n",
            "dot multiplication: \n",
            " tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n",
        "y1 = tensor @ tensor.T\n",
        "y2 = tensor.matmul(tensor.T)\n",
        "\n",
        "y3 = torch.rand_like(tensor)\n",
        "mat_mult = torch.matmul(tensor, tensor.T, out=y3)\n",
        "\n",
        "print(f\"matrix multiplication: \\n {mat_mult} \\n\")\n",
        "\n",
        "\n",
        "# This computes the element-wise product. z1, z2, z3 will have the same value\n",
        "z1 = tensor * tensor\n",
        "z2 = tensor.mul(tensor)\n",
        "\n",
        "z3 = torch.rand_like(tensor)\n",
        "dot_mult = torch.mul(tensor, tensor, out=z3)\n",
        "\n",
        "print(f\"dot multiplication: \\n {dot_mult} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tensores de un solo elemento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se puede tener un tensor de un solo elemento, en este caso, si se quiere convertir a número se puede usar el método `item()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor de un solo elemento: 12.0, su dimensión es torch.Size([])\n",
            "Tensor convertido a número: 12.0, es de tipo <class 'float'>\n"
          ]
        }
      ],
      "source": [
        "agg = tensor.sum()\n",
        "print(f\"Tensor de un solo elemento: {agg}, su dimensión es {agg.shape}\")\n",
        "\n",
        "agg_item = agg.item()\n",
        "print(f\"Tensor convertido a número: {agg_item}, es de tipo {type(agg_item)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Operaciones in situ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Son operaciones que se realizan sobre el propio elemento, se indican añadiendo un guión bajo `_` al final de la operación. Por ejemplo `x.copy_()` o `x.t_()` modificarán `x`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]]) \n",
            "\n",
            "tensor([[6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.]])\n"
          ]
        }
      ],
      "source": [
        "print(tensor, \"\\n\")\n",
        "tensor.add_(5)\n",
        "print(tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> Nota: Las operaciones in situ ahorran algo de memoria, pero pueden resultar problemáticas al calcular derivadas debido a una pérdida inmediata del historial. Por tanto, se desaconseja su uso."
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "d1c24abb23a313e1f9ae042292cd8e6e3c60c5818227ced3d46e3df2c65171ef"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
