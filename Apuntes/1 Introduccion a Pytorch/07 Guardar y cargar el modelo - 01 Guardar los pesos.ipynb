{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Guardar y cargar el modelo - 01 Guardar los pesos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Entrenamiento de la red"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos a hacer de manera rápida el entrenamiento de una red (creada desde cero) para el conjunto de datos `CIFAR-10`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Descargamos y creamos el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Descargamos y creamos el dataset\n",
        "dataset_train = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "dataset_test = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creamos un dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_dataloader = DataLoader(dataset_train, batch_size=BATCH_SIZE)\n",
        "test_dataloader = DataLoader(dataset_test, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Red"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creamos la red neuronal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "# Creamos la red neuronal desde cero\n",
        "class NeuralNetworkFromScratch(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetworkFromScratch, self).__init__()   # Se inicializa el módulo nn.Module\n",
        "        self.flatten = nn.Flatten()             # Se crea una primera capa que aplana la imagen de entrada\n",
        "        self.linear_relu_stack = nn.Sequential( # Se crea una módulo de arquitectura secuencial:\n",
        "            nn.Linear(3*32*32, 512),                # Se añade una primera capa lineal que está preparada \n",
        "                                                    # para que le entre un vector de 28*28 (784)\n",
        "                                                    # y sacará un vector de 512\n",
        "            nn.ReLU(),                              # Se añade una no linealidad\n",
        "            nn.Linear(512, 512),                    # Se añade una segunda capa lineal que le entran 512 \n",
        "                                                    # datos y saca 512 datos\n",
        "            nn.ReLU(),                              # Se añade una no linealidad\n",
        "            nn.Linear(512, 10)                      # Se añade una tercera capa lineal que le entran 512 \n",
        "                                                    # datos y saca un array de tamaño 10 (el número\n",
        "                                                    # de etiquetas)\n",
        "        )\n",
        "        #self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)                         # Se pasa la imagen por la capa de aplanado\n",
        "        logits = self.linear_relu_stack(x)          # Se pasa el vector resultante por la red\n",
        "        #probs = self.softmax(logits)\n",
        "        return logits\n",
        "\n",
        "model_scratch = NeuralNetworkFromScratch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Función de pérdida"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optimizador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "LR = 1e-2\n",
        "\n",
        "optimizer = torch.optim.SGD(model_scratch.parameters(), lr=LR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ciclo de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # X and y to device\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            # X and y to device\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            \n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "NeuralNetworkFromScratch(\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (linear_relu_stack): Sequential(\n",
              "    (0): Linear(in_features=3072, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))\n",
        "\n",
        "model_scratch.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.299342  [    0/50000]\n",
            "loss: 2.272410  [ 6400/50000]\n",
            "loss: 2.159123  [12800/50000]\n",
            "loss: 2.180902  [19200/50000]\n",
            "loss: 2.076792  [25600/50000]\n",
            "loss: 2.039117  [32000/50000]\n",
            "loss: 2.141944  [38400/50000]\n",
            "loss: 1.978299  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 29.5%, Avg loss: 1.958375 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.007046  [    0/50000]\n",
            "loss: 1.994200  [ 6400/50000]\n",
            "loss: 1.767032  [12800/50000]\n",
            "loss: 1.994457  [19200/50000]\n",
            "loss: 1.974489  [25600/50000]\n",
            "loss: 1.936294  [32000/50000]\n",
            "loss: 1.989090  [38400/50000]\n",
            "loss: 1.863240  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 33.9%, Avg loss: 1.858009 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.834620  [    0/50000]\n",
            "loss: 1.840008  [ 6400/50000]\n",
            "loss: 1.624486  [12800/50000]\n",
            "loss: 1.881370  [19200/50000]\n",
            "loss: 1.906578  [25600/50000]\n",
            "loss: 1.861387  [32000/50000]\n",
            "loss: 1.907754  [38400/50000]\n",
            "loss: 1.786044  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 36.6%, Avg loss: 1.791673 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.740529  [    0/50000]\n",
            "loss: 1.725471  [ 6400/50000]\n",
            "loss: 1.532026  [12800/50000]\n",
            "loss: 1.795460  [19200/50000]\n",
            "loss: 1.828100  [25600/50000]\n",
            "loss: 1.809107  [32000/50000]\n",
            "loss: 1.830502  [38400/50000]\n",
            "loss: 1.725908  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 37.6%, Avg loss: 1.747231 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.693377  [    0/50000]\n",
            "loss: 1.650945  [ 6400/50000]\n",
            "loss: 1.471339  [12800/50000]\n",
            "loss: 1.753187  [19200/50000]\n",
            "loss: 1.755042  [25600/50000]\n",
            "loss: 1.773771  [32000/50000]\n",
            "loss: 1.767992  [38400/50000]\n",
            "loss: 1.680757  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 37.7%, Avg loss: 1.733218 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.688710  [    0/50000]\n",
            "loss: 1.598959  [ 6400/50000]\n",
            "loss: 1.420931  [12800/50000]\n",
            "loss: 1.737972  [19200/50000]\n",
            "loss: 1.698354  [25600/50000]\n",
            "loss: 1.735643  [32000/50000]\n",
            "loss: 1.717137  [38400/50000]\n",
            "loss: 1.645127  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 36.9%, Avg loss: 1.742300 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.710231  [    0/50000]\n",
            "loss: 1.557873  [ 6400/50000]\n",
            "loss: 1.381722  [12800/50000]\n",
            "loss: 1.731419  [19200/50000]\n",
            "loss: 1.662945  [25600/50000]\n",
            "loss: 1.694431  [32000/50000]\n",
            "loss: 1.676500  [38400/50000]\n",
            "loss: 1.615886  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 36.5%, Avg loss: 1.748914 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 1.715709  [    0/50000]\n",
            "loss: 1.525188  [ 6400/50000]\n",
            "loss: 1.342122  [12800/50000]\n",
            "loss: 1.724922  [19200/50000]\n",
            "loss: 1.630092  [25600/50000]\n",
            "loss: 1.663233  [32000/50000]\n",
            "loss: 1.644495  [38400/50000]\n",
            "loss: 1.595977  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 36.4%, Avg loss: 1.755438 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 1.724303  [    0/50000]\n",
            "loss: 1.496930  [ 6400/50000]\n",
            "loss: 1.308744  [12800/50000]\n",
            "loss: 1.717606  [19200/50000]\n",
            "loss: 1.604217  [25600/50000]\n",
            "loss: 1.636209  [32000/50000]\n",
            "loss: 1.623033  [38400/50000]\n",
            "loss: 1.573638  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 36.5%, Avg loss: 1.762738 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 1.740092  [    0/50000]\n",
            "loss: 1.473193  [ 6400/50000]\n",
            "loss: 1.279258  [12800/50000]\n",
            "loss: 1.711365  [19200/50000]\n",
            "loss: 1.572375  [25600/50000]\n",
            "loss: 1.609900  [32000/50000]\n",
            "loss: 1.597456  [38400/50000]\n",
            "loss: 1.558551  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 37.9%, Avg loss: 1.728433 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model_scratch, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model_scratch, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Guardar los pesos del modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Los modelos de PyTorch almacenan los parámetros aprendidos en un diccionario de estado interno, llamado ``state_dict``. Estos se pueden conservar a través del método ``torch.save``:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "path = \"data/pesos.pth\"\n",
        "torch.save(model_scratch.state_dict(), path)"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "d1c24abb23a313e1f9ae042292cd8e6e3c60c5818227ced3d46e3df2c65171ef"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
