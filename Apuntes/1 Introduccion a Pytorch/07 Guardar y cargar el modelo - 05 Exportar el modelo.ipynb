{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Guardar y cargar el modelo - 05 Exportar el modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Entrenamiento de la red"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos a hacer de manera rápida el entrenamiento de una red (creada desde cero) para el conjunto de datos `CIFAR-10`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Descargamos y creamos el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Descargamos y creamos el dataset\n",
        "dataset_train = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "dataset_test = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creamos un dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_dataloader = DataLoader(dataset_train, batch_size=BATCH_SIZE)\n",
        "test_dataloader = DataLoader(dataset_test, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Red"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creamos la red neuronal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "# Creamos la red neuronal desde cero\n",
        "class NeuralNetworkFromScratch(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetworkFromScratch, self).__init__()   # Se inicializa el módulo nn.Module\n",
        "        self.flatten = nn.Flatten()             # Se crea una primera capa que aplana la imagen de entrada\n",
        "        self.linear_relu_stack = nn.Sequential( # Se crea una módulo de arquitectura secuencial:\n",
        "            nn.Linear(3*32*32, 512),                # Se añade una primera capa lineal que está preparada \n",
        "                                                    # para que le entre un vector de 28*28 (784)\n",
        "                                                    # y sacará un vector de 512\n",
        "            nn.ReLU(),                              # Se añade una no linealidad\n",
        "            nn.Linear(512, 512),                    # Se añade una segunda capa lineal que le entran 512 \n",
        "                                                    # datos y saca 512 datos\n",
        "            nn.ReLU(),                              # Se añade una no linealidad\n",
        "            nn.Linear(512, 10)                      # Se añade una tercera capa lineal que le entran 512 \n",
        "                                                    # datos y saca un array de tamaño 10 (el número\n",
        "                                                    # de etiquetas)\n",
        "        )\n",
        "        #self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)                         # Se pasa la imagen por la capa de aplanado\n",
        "        logits = self.linear_relu_stack(x)          # Se pasa el vector resultante por la red\n",
        "        #probs = self.softmax(logits)\n",
        "        return logits\n",
        "\n",
        "model_scratch = NeuralNetworkFromScratch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Función de pérdida"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optimizador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "LR = 1e-2\n",
        "\n",
        "optimizer = torch.optim.SGD(model_scratch.parameters(), lr=LR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ciclo de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # X and y to device\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            # X and y to device\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            \n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "NeuralNetworkFromScratch(\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (linear_relu_stack): Sequential(\n",
              "    (0): Linear(in_features=3072, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))\n",
        "\n",
        "model_scratch.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.309021  [    0/50000]\n",
            "loss: 2.273057  [ 6400/50000]\n",
            "loss: 2.177390  [12800/50000]\n",
            "loss: 2.192432  [19200/50000]\n",
            "loss: 2.063237  [25600/50000]\n",
            "loss: 2.049211  [32000/50000]\n",
            "loss: 2.136148  [38400/50000]\n",
            "loss: 1.967081  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 29.9%, Avg loss: 1.953621 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 1.998021  [    0/50000]\n",
            "loss: 1.979714  [ 6400/50000]\n",
            "loss: 1.755367  [12800/50000]\n",
            "loss: 1.983313  [19200/50000]\n",
            "loss: 1.972812  [25600/50000]\n",
            "loss: 1.939373  [32000/50000]\n",
            "loss: 1.986053  [38400/50000]\n",
            "loss: 1.846420  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 34.3%, Avg loss: 1.849024 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.834622  [    0/50000]\n",
            "loss: 1.842938  [ 6400/50000]\n",
            "loss: 1.618993  [12800/50000]\n",
            "loss: 1.863506  [19200/50000]\n",
            "loss: 1.914225  [25600/50000]\n",
            "loss: 1.861549  [32000/50000]\n",
            "loss: 1.897058  [38400/50000]\n",
            "loss: 1.767818  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 36.6%, Avg loss: 1.779849 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.738927  [    0/50000]\n",
            "loss: 1.739343  [ 6400/50000]\n",
            "loss: 1.535591  [12800/50000]\n",
            "loss: 1.780629  [19200/50000]\n",
            "loss: 1.834686  [25600/50000]\n",
            "loss: 1.819635  [32000/50000]\n",
            "loss: 1.818671  [38400/50000]\n",
            "loss: 1.714460  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 38.5%, Avg loss: 1.730064 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.684163  [    0/50000]\n",
            "loss: 1.670182  [ 6400/50000]\n",
            "loss: 1.476767  [12800/50000]\n",
            "loss: 1.734503  [19200/50000]\n",
            "loss: 1.764073  [25600/50000]\n",
            "loss: 1.785982  [32000/50000]\n",
            "loss: 1.758056  [38400/50000]\n",
            "loss: 1.674280  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 38.7%, Avg loss: 1.712511 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.668317  [    0/50000]\n",
            "loss: 1.620115  [ 6400/50000]\n",
            "loss: 1.427314  [12800/50000]\n",
            "loss: 1.711604  [19200/50000]\n",
            "loss: 1.708618  [25600/50000]\n",
            "loss: 1.745800  [32000/50000]\n",
            "loss: 1.712542  [38400/50000]\n",
            "loss: 1.642705  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 38.5%, Avg loss: 1.708924 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.670001  [    0/50000]\n",
            "loss: 1.576222  [ 6400/50000]\n",
            "loss: 1.385483  [12800/50000]\n",
            "loss: 1.698024  [19200/50000]\n",
            "loss: 1.664896  [25600/50000]\n",
            "loss: 1.698696  [32000/50000]\n",
            "loss: 1.671637  [38400/50000]\n",
            "loss: 1.624601  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 38.1%, Avg loss: 1.716954 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 1.679124  [    0/50000]\n",
            "loss: 1.539359  [ 6400/50000]\n",
            "loss: 1.342723  [12800/50000]\n",
            "loss: 1.696142  [19200/50000]\n",
            "loss: 1.631825  [25600/50000]\n",
            "loss: 1.663392  [32000/50000]\n",
            "loss: 1.644388  [38400/50000]\n",
            "loss: 1.608216  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 38.5%, Avg loss: 1.705163 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 1.670175  [    0/50000]\n",
            "loss: 1.504787  [ 6400/50000]\n",
            "loss: 1.313736  [12800/50000]\n",
            "loss: 1.693967  [19200/50000]\n",
            "loss: 1.602989  [25600/50000]\n",
            "loss: 1.633718  [32000/50000]\n",
            "loss: 1.617692  [38400/50000]\n",
            "loss: 1.595931  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 38.8%, Avg loss: 1.697956 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 1.668567  [    0/50000]\n",
            "loss: 1.477296  [ 6400/50000]\n",
            "loss: 1.288745  [12800/50000]\n",
            "loss: 1.684520  [19200/50000]\n",
            "loss: 1.575779  [25600/50000]\n",
            "loss: 1.609712  [32000/50000]\n",
            "loss: 1.601016  [38400/50000]\n",
            "loss: 1.582026  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 39.4%, Avg loss: 1.685524 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model_scratch, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model_scratch, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exportar el modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hasta ahora teníamos el problema de que para cargar un modelo, una de dos, si guardábamos los pesos, necesitábamos declarar la red e instanciarla, y en el caso de guardar el modelo, no hacía falta instanciarla, pero si declarar la red.\n",
        "\n",
        "Además que cuando queríamos volver a usar el modelo entrenado necesitábamos Pytorch, pero si en donde vamos a realizar la inferencia no tenemos Pytorch, o incluso peor, no tenemos ni Python estos métodos no nos valen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para ello Pytorch también tiene soporte de exportación [ONNX](https://onnx.ai/) nativo.\n",
        "\n",
        "ONNX es un formato abierto creado para representar modelos de aprendizaje automático. ONNX define un conjunto común de operadores (los componentes básicos de los modelos de aprendizaje automático y aprendizaje profundo) y un formato de archivo común para permitir que los desarrolladores de IA usen modelos con una variedad de marcos, herramientas, tiempos de ejecución y compiladores.\n",
        "\n",
        "Sin embargo, dada la naturaleza dinámica del gráfico de ejecución de PyTorch, el proceso de exportación debe atravesar el gráfico de ejecución para producir un modelo ONNX persistente. Por esta razón, se debe pasar una variable de prueba del tamaño apropiado a la rutina de exportación (en nuestro caso, crearemos un tensor aleatorio ficticio del tamaño correcto):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch.onnx as onnx\n",
        "\n",
        "path = \"data/modelo.onnx\"\n",
        "\n",
        "batch = 8\n",
        "input_image = torch.rand((batch,3,32,32))\n",
        "\n",
        "# Llevamos la red neuronal a la CPU\n",
        "model_scratch.to('cpu')\n",
        "\n",
        "onnx.export(model_scratch, input_image, 'model.onnx')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El uso de [ONNX](https://onnx.ai/) es algo que se escapa al objetivo de este curso, por lo que si se quiere aprender cómo importar el modelo se recomienda visitar el [tutorial de ONNX](https://github.com/onnx/tutorials)."
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "d1c24abb23a313e1f9ae042292cd8e6e3c60c5818227ced3d46e3df2c65171ef"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
