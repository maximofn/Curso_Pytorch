{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "%matplotlib inline"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensores"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los tensores son una estructura de datos especializada que es muy similar a los arrays y matrices. En PyTorch, se usan tensores para codificar las entradas y salidas de un modelo, así como los parámetros del modelo.\n",
        "\n",
        "Los tensores son similares a los ndarrays de NumPy, excepto que los tensores pueden ejecutarse en GPU u otros aceleradores de hardware. De hecho, los tensores y las matrices de NumPy a menudo pueden compartir la misma memoria subyacente, lo que elimina la necesidad de copiar datos. Los tensores también están optimizados para la diferenciación automática (Autograd)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carga de librerias"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "import torch\r\n",
        "import numpy as np"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inicialización de tensores"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los tensores se pueden inicializar de varias formas"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Directamente con datos"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "data = [[1, 2],[3, 4]]\r\n",
        "x_data = torch.tensor(data)"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Desde un array de NumPy\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "np_array = np.array(data)\r\n",
        "x_np = torch.from_numpy(np_array)"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La matriz de Numpy y el Tensor comparten memoria, si se modifica uno se ve reflejado el cambio en el otro"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "np_array[0, 0] = 99\r\n",
        "x_np[1, 1] = 100\r\n",
        "\r\n",
        "print(f\"Numpy matrix: \\n {np_array} \\n\")\r\n",
        "print(f\"Tensor: \\n {x_np} \\n\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numpy matrix: \n",
            " [[ 99   2]\n",
            " [  3 100]] \n",
            "\n",
            "Tensor: \n",
            " tensor([[ 99,   2],\n",
            "        [  3, 100]], dtype=torch.int32) \n",
            "\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esto es así, aunque el tensor esté en la GPU"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "gpu_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n",
        "cpu_device = \"cpu\"\r\n",
        "\r\n",
        "x_np.to(gpu_device)\r\n",
        "\r\n",
        "x_np[1, 1] = 101\r\n",
        "\r\n",
        "print(f\"Numpy matrix: \\n {np_array} \\n\")\r\n",
        "print(f\"Tensor: \\n {x_np} \\n\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numpy matrix: \n",
            " [[ 99   2]\n",
            " [  3 101]] \n",
            "\n",
            "Tensor: \n",
            " tensor([[ 99,   2],\n",
            "        [  3, 101]], dtype=torch.int32) \n",
            "\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Desde otro tensor"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "x_ones = torch.ones_like(x_data) # retains the properties of x_data\r\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\r\n",
        "\r\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\r\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.7157, 0.3992],\n",
            "        [0.3843, 0.9938]]) \n",
            "\n"
          ]
        }
      ],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Con valores aleatorios o constnates"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "shape = (2,3,)\r\n",
        "rand_tensor = torch.rand(shape)\r\n",
        "ones_tensor = torch.ones(shape)\r\n",
        "zeros_tensor = torch.zeros(shape)\r\n",
        "\r\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\r\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\r\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor: \n",
            " tensor([[0.9277, 0.6535, 0.7438],\n",
            "        [0.0253, 0.8267, 0.8434]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]]) \n",
            "\n",
            "Zeros Tensor: \n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------\n",
        "\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Atributos de un tensor"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se pueden obtener los atributos de un tensor, como el tamaño, el tipo y el dispositivo en el que está"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "tensor = torch.rand(3,4)\r\n",
        "\r\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\r\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\r\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------\n",
        "\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Operaciones con Tensores"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hay más de 100 operaciones con tensores, en este [enlace](https://pytorch.org/docs/stable/torch.html). Cada una de estas operaciones se puede ejecutar en la GPU (normalmente a velocidades más altas que en una CPU).\r\n",
        "\r\n",
        "De forma predeterminada, los tensores se crean en la CPU. Necesitamos mover explícitamente los tensores a la GPU usando el método .to (después de verificar la disponibilidad de la GPU). Hay que tener en cuenta que copiar grandes tensores entre dispositivos puede resultar caro en términos de tiempo y memoria."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "# We move our tensor to the GPU if available\r\n",
        "if torch.cuda.is_available():\r\n",
        "    tensor = tensor.to('cuda')\r\n",
        "\r\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device tensor is stored on: cuda:0\n"
          ]
        }
      ],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos algunas de las operaciones. Al ser muy similares a Numpy, la API de Tensor es muy fácil de usar."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Indexación y segmentación como en Numpy"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "tensor = torch.ones(4, 4)\r\n",
        "print('First row: ', tensor[0])\r\n",
        "print('First column: ', tensor[:, 0])\r\n",
        "print('Last column:', tensor[..., -1])\r\n",
        "tensor[:,1] = 0\r\n",
        "print(tensor)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First row:  tensor([1., 1., 1., 1.])\n",
            "First column:  tensor([1., 1., 1., 1.])\n",
            "Last column: tensor([1., 1., 1., 1.])\n",
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unión de tensores"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se puede utilizar torch.cat para concatenar una secuencia de tensores a lo largo de una dimensión determinada. También se puede usar torch.stack para unir otro tensor y es sutilmente diferente de torch.cat."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\r\n",
        "print(t1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
          ]
        }
      ],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Operaciones aritméticas"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\r\n",
        "y1 = tensor @ tensor.T\r\n",
        "y2 = tensor.matmul(tensor.T)\r\n",
        "\r\n",
        "y3 = torch.rand_like(tensor)\r\n",
        "mat_mult = torch.matmul(tensor, tensor.T, out=y3)\r\n",
        "\r\n",
        "print(f\"matrix multiplication: \\n {mat_mult} \\n\")\r\n",
        "\r\n",
        "\r\n",
        "# This computes the element-wise product. z1, z2, z3 will have the same value\r\n",
        "z1 = tensor * tensor\r\n",
        "z2 = tensor.mul(tensor)\r\n",
        "\r\n",
        "z3 = torch.rand_like(tensor)\r\n",
        "dot_mult = torch.mul(tensor, tensor, out=z3)\r\n",
        "\r\n",
        "print(f\"dot multiplication: \\n {dot_mult} \\n\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "matrix multiplication: \n",
            " tensor([[3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.]]) \n",
            "\n",
            "dot multiplication: \n",
            " tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]]) \n",
            "\n"
          ]
        }
      ],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensores de un solo elemento"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se puede tener un tensor de un solo elemento, en este caso, si se quiere convertir a número se puede usar el método `item()`"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "agg = tensor.sum()\r\n",
        "print(f\"Tensor de un solo elemento: {agg}, su dimensión es {agg.shape}\")\r\n",
        "\r\n",
        "agg_item = agg.item()\r\n",
        "print(f\"Tensor convertido a número: {agg_item}, es de tipo {type(agg_item)}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor de un solo elemento: 12.0, su dimensión es torch.Size([])\n",
            "Tensor convertido a número: 12.0, es de tipo <class 'float'>\n"
          ]
        }
      ],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Operaciones in situ"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Son operaciones que se realizan sobre el propio elemento, se indican añadiendo un guión bajo `_` al final de la operación. Por ejemplo `x.copy_()` o `x.t_()` modificarán `x`"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "print(tensor, \"\\n\")\r\n",
        "tensor.add_(5)\r\n",
        "print(tensor)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]]) \n",
            "\n",
            "tensor([[6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.]])\n"
          ]
        }
      ],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Nota: Las operaciones in situ ahorran algo de memoria, pero pueden resultar problemáticas al calcular derivadas debido a una pérdida inmediata del historial. Por tanto, se desaconseja su uso."
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.5 64-bit ('base': conda)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "interpreter": {
      "hash": "d1c24abb23a313e1f9ae042292cd8e6e3c60c5818227ced3d46e3df2c65171ef"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}