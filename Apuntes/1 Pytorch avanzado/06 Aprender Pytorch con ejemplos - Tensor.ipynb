{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Aprender Pytorch con ejemplos - Tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Numpy es un gran marco, pero no puede utilizar GPU para acelerar sus cálculos numéricos. Para las redes neuronales profundas modernas, las GPU a menudo brindan aceleraciones de [50x o más](https://github.com/jcjohnson/cnn-benchmarks), por lo que, desafortunadamente, numpy no será suficiente para el aprendizaje profundo moderno.\n",
        "\n",
        "Aquí presentamos el concepto más fundamental de PyTorch: el ``Tensor``. Un tensor de PyTorch es conceptualmente idéntico a una matriz numérica: un tensor es una matriz de n dimensiones y PyTorch proporciona muchas funciones para operar en estos tensores. Detrás de escena, los tensores pueden realizar un seguimiento de un gráfico computacional y gradientes, pero también son útiles como una herramienta genérica para la computación científica.\n",
        "\n",
        "También a diferencia de numpy, los tensores PyTorch pueden utilizar GPU para acelerar sus cálculos numéricos. Para ejecutar un PyTorch Tensor en GPU, simplemente necesita especificar el dispositivo correcto.\n",
        "\n",
        "Aquí usamos Tensores PyTorch para ajustar un polinomio de tercer orden a la función seno. Como en el ejemplo anterior, necesitamos implementar manualmente los pases hacia adelante y hacia atrás a través de la red:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "99 615.1214599609375\n",
            "199 409.7394714355469\n",
            "299 273.9296569824219\n",
            "399 184.1245574951172\n",
            "499 124.74034118652344\n",
            "599 85.47217559814453\n",
            "699 59.50581359863281\n",
            "799 42.335472106933594\n",
            "899 30.981456756591797\n",
            "999 23.47347068786621\n",
            "1099 18.508834838867188\n",
            "1199 15.225869178771973\n",
            "1299 13.05500602722168\n",
            "1399 11.61949634552002\n",
            "1499 10.670235633850098\n",
            "1599 10.042546272277832\n",
            "1699 9.627472877502441\n",
            "1799 9.352996826171875\n",
            "1899 9.171492576599121\n",
            "1999 9.051473617553711\n",
            "Result: y = 0.0003305132267996669 + 0.8418641686439514 x + -5.7019158703042194e-05 x^2 + -0.09121430665254593 x^3\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import math\n",
        "\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cpu\")\n",
        "# device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
        "\n",
        "# Create random input and output data\n",
        "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
        "y = torch.sin(x)\n",
        "\n",
        "# Randomly initialize weights\n",
        "a = torch.randn((), device=device, dtype=dtype)\n",
        "b = torch.randn((), device=device, dtype=dtype)\n",
        "c = torch.randn((), device=device, dtype=dtype)\n",
        "d = torch.randn((), device=device, dtype=dtype)\n",
        "\n",
        "learning_rate = 1e-6\n",
        "for t in range(2000):\n",
        "    # Forward pass: compute predicted y\n",
        "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
        "\n",
        "    # Compute and print loss\n",
        "    loss = (y_pred - y).pow(2).sum().item()\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss)\n",
        "\n",
        "    # Backprop to compute gradients of a, b, c, d with respect to loss\n",
        "    grad_y_pred = 2.0 * (y_pred - y)\n",
        "    grad_a = grad_y_pred.sum()\n",
        "    grad_b = (grad_y_pred * x).sum()\n",
        "    grad_c = (grad_y_pred * x ** 2).sum()\n",
        "    grad_d = (grad_y_pred * x ** 3).sum()\n",
        "\n",
        "    # Update weights using gradient descent\n",
        "    a -= learning_rate * grad_a\n",
        "    b -= learning_rate * grad_b\n",
        "    c -= learning_rate * grad_c\n",
        "    d -= learning_rate * grad_d\n",
        "\n",
        "\n",
        "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "d1c24abb23a313e1f9ae042292cd8e6e3c60c5818227ced3d46e3df2c65171ef"
    },
    "kernelspec": {
      "display_name": "Python 3.8.11 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
