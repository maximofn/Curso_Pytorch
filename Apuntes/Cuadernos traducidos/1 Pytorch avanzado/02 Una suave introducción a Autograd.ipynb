{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Una suave introducción a Autograd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``torch.autograd`` es el motor de diferenciación automática de PyTorch que impulsa el entrenamiento de redes neuronales. En esta sección, obtendrá una comprensión conceptual de cómo autograd ayuda a entrenar una red neuronal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Background"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Las redes neuronales (NN) son una colección de funciones anidadas que se ejecutan en algunos datos de entrada. Estas funciones están definidas por parámetros (que consisten en pesos y sesgos), que en PyTorch se almacenan en tensores.\n",
        "\n",
        "El entrenamiento de una NN ocurre en dos pasos:\n",
        "\n",
        "**Forward Propagation**: en forward prop, la NN hace su mejor conjetura sobre la salida correcta. Ejecuta los datos de entrada a través de cada una de sus funciones para realizar esta conjetura.\n",
        "\n",
        "**Backward Propagation**: en backprop, la NN ajusta sus parámetros proporcionalmente al error en su conjetura. Lo hace atravesando hacia atrás desde la salida, recopilando las derivadas del error con respecto a los parámetros de las funciones (gradientes) y optimizando los parámetros mediante el descenso de gradiente. Para obtener un tutorial más detallado de backprop, vea este [video](https://www.youtube.com/watch?v=tIeHLnjs5U8) de 3Blue1Brown ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Uso en Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Echemos un vistazo a un solo paso de entrenamiento. Para este ejemplo, cargamos un modelo resnet18 previamente entrenado de ``torchvision``. Creamos un tensor de datos aleatorios para representar una sola imagen con 3 canales, y alto y ancho de 64, y su correspondiente ``label`` inicializado a algunos valores aleatorios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /home/mfnunez/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n",
            "100%|██████████| 44.7M/44.7M [01:12<00:00, 644kB/s]\n"
          ]
        }
      ],
      "source": [
        "import torch, torchvision\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "data = torch.rand(1, 3, 64, 64)\n",
        "labels = torch.rand(1, 1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuación, ejecutamos los datos de entrada a través del modelo a través de cada una de sus capas para hacer una predicción. Este es el **forward pass**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "prediction = model(data) # forward pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Usamos la predicción del modelo y la etiqueta correspondiente para calcular el error (`loss`). El siguiente paso es propagar este error a través de la red. La propagación hacia atrás se inicia cuando invocamos `.backward()` en el tensor de error. Luego, Autograd calcula y almacena los gradientes para cada parámetro del modelo en el atributo `.grad` del parámetro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "loss = (prediction - labels).sum()\n",
        "loss.backward() # backward pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuación, cargamos un optimizador, en este caso SGD con una tasa de aprendizaje de 0.01 y un impulso de 0.9. Registramos todos los parámetros del modelo en el optimizador."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "optim = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finalmente, llamamos a `.step()` para iniciar el descenso de gradiente. El optimizador ajusta cada parámetro por su gradiente almacenado en `.grad`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "optim.step() #gradient descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En este punto, tienes todo lo que necesitas para entrenar tu red neuronal. Las secciones a continuación detallan el funcionamiento de autograd; no dude en omitirlas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Diferenciación en Autograd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Echemos un vistazo a cómo `autograd` recopila los degradados. Creamos dos tensores `a` y `b` con `requires_grad=True`. Esto indica autogradque se debe realizar un seguimiento de cada operación en ellos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "a = torch.tensor([2., 3.], requires_grad=True)\n",
        "b = torch.tensor([6., 4.], requires_grad=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creamos otro tensor `Q` a partir de `a` y `b`.\n",
        "\n",
        "$$\n",
        "\\begin{align}Q = 3a^3 - b^2\\end{align}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "Q = 3*a**3 - b**2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Supongamos que `a` y `b` son parámetros de una NN, y `Q` es el error. En el entrenamiento de la NN, queremos los gradientes de los parámetros de error, es decir\n",
        "\n",
        "$$\n",
        "\\begin{align}\\frac{\\partial Q}{\\partial a} = 9a^2\\end{align}\n",
        "$$\n",
        "$$\n",
        "\\begin{align}\\frac{\\partial Q}{\\partial b} = -2b\\end{align}\n",
        "$$\n",
        "\n",
        "Cuando llamamos a `.backward()` en Q, autograd calcula estos gradientes y los almacena en los respectivos tensores atributo `.grad`.\n",
        "\n",
        "Necesitamos pasar explícitamente un argumento `gradient` a `Q.backward()` porque es un vector. `gradient` es un tensor de la misma forma que `Q`, y representa el gradiente de `Q` en sí mismo, es decir:\n",
        "\n",
        "$$\n",
        "\\begin{align}\\frac{dQ}{dQ} = 1\\end{align}\n",
        "$$\n",
        "\n",
        "De manera equivalente, también podemos agregar `Q` en un escalar y llamar hacia atrás implícitamente, como `Q.sum().backward()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "external_grad = torch.tensor([1., 1.])\n",
        "Q.backward(gradient=external_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Los degradados ahora se depositan en `a.grad` y `b.grad`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([True, True])\n",
            "tensor([True, True])\n"
          ]
        }
      ],
      "source": [
        "# check if collected gradients are correct\n",
        "print(9*a**2 == a.grad)\n",
        "print(-2*b == b.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "----------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lectura opcional: cálculo vectorial usando autograd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Matemáticamente, si tienes una función con valor vectorial $\\vec{y}=f(\\vec{x})$, luego el gradiente de $\\vec{y}$ con respecto a $\\vec{x}$ es una matriz jacobiana $J$:\n",
        "\n",
        "$$\n",
        "\\begin{align}J\n",
        "     =\n",
        "      \\left(\\begin{array}{cc}\n",
        "      \\frac{\\partial \\bf{y}}{\\partial x_{1}} &\n",
        "      ... &\n",
        "      \\frac{\\partial \\bf{y}}{\\partial x_{n}}\n",
        "      \\end{array}\\right)\n",
        "     =\n",
        "     \\left(\\begin{array}{ccc}\n",
        "      \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{1}}{\\partial x_{n}}\\\\\n",
        "      \\vdots & \\ddots & \\vdots\\\\\n",
        "      \\frac{\\partial y_{m}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}}\n",
        "      \\end{array}\\right)\\end{align}\n",
        "$$\n",
        "\n",
        "en términos generales, `torch.autograd` es un motor de cálculo de producto jacobiano vectorial. Es decir, dado cualquier vector $\\vec{v}$, calcula el producto $J^{T}\\cdot \\vec{v}$\n",
        "\n",
        "Si \\vec{v}$ pasa a ser el gradiente de una función escalar $l=g\\left(\\vec{y}\\right)$:\n",
        "\n",
        "$$\n",
        "\\begin{align}\\vec{v}\n",
        "   =\n",
        "   \\left(\\begin{array}{ccc}\\frac{\\partial l}{\\partial y_{1}} & \\cdots & \\frac{\\partial l}{\\partial y_{m}}\\end{array}\\right)^{T}\\end{align}\n",
        "$$\n",
        "\n",
        "luego, por la regla de la cadena, el producto vectorial-jacobiano sería el gradiente de $l$ con respecto a $\\vec{x}$:\n",
        "\n",
        "$$\n",
        "\\begin{align}J^{T}\\cdot \\vec{v}=\\left(\\begin{array}{ccc}\n",
        "      \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{1}}\\\\\n",
        "      \\vdots & \\ddots & \\vdots\\\\\n",
        "      \\frac{\\partial y_{1}}{\\partial x_{n}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}}\n",
        "      \\end{array}\\right)\\left(\\begin{array}{c}\n",
        "      \\frac{\\partial l}{\\partial y_{1}}\\\\\n",
        "      \\vdots\\\\\n",
        "      \\frac{\\partial l}{\\partial y_{m}}\n",
        "      \\end{array}\\right)=\\left(\\begin{array}{c}\n",
        "      \\frac{\\partial l}{\\partial x_{1}}\\\\\n",
        "      \\vdots\\\\\n",
        "      \\frac{\\partial l}{\\partial x_{n}}\n",
        "      \\end{array}\\right)\\end{align}\n",
        "$$\n",
        "\n",
        "Esta característica del producto vector-jacobiano es lo que usamos en el ejemplo anterior; `external_grad` representa $\\vec{v}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Gráfico computacional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Conceptualmente, autograd mantiene un registro de datos (tensores) y todas las operaciones ejecutadas (junto con los nuevos tensores resultantes) en un gráfico acíclico dirigido (DAG) que consta de objetos de [Function](https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function). En este DAG, las hojas son los tensores de entrada, las raíces son los tensores de salida. Al trazar este gráfico desde las raíces hasta las hojas, puede calcular automáticamente los gradientes usando la regla de la cadena.\n",
        "\n",
        "En forward pass, autograd hace dos cosas simultáneamente:\n",
        " * ejecutar la operación solicitada para calcular un tensor resultante, y\n",
        " * mantener la *función de gradiente* de la operación en el DAG.\n",
        "\n",
        "El backward pass comienza cuando `.backward()` se llama en la raíz del DAG. `autograd` luego:\n",
        "\n",
        " * calcula los gradientes de cada uno `.grad_fn`,\n",
        " * los acumula en el `.grad` atributo del tensor respectivo, y\n",
        " * utilizando la regla de la cadena, se propaga hasta los tensores de las hojas.\n",
        "\n",
        "A continuación se muestra una representación visual del DAG en nuestro ejemplo. En el gráfico, las flechas están en la dirección del pase hacia adelante. Los nodos representan las funciones hacia atrás de cada operación en el pase hacia adelante. Los nodos de hojas en azul representan nuestros tensores de hojas `a` y `b`.\n",
        "\n",
        "![dag_autograd](https://pytorch.org/tutorials/_images/dag_autograd.png)\n",
        "\n",
        " > **Nota**:\n",
        " > **Los DAG son dinámicos en PyTorch**. Una cosa importante a tener en cuenta es que el gráfico se recrea desde cero; después de cada llamada a `.backward()`, autograd comienza a completar un nuevo gráfico. Esto es exactamente lo que le permite utilizar declaraciones de flujo de control en su modelo; puede cambiar la forma, el tamaño y las operaciones en cada iteración si es necesario."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exclusión del DAG\n",
        "\n",
        "`torch.autograd` rastrea las operaciones en todos los tensores que tienen su bandera `requires_grad` establecida en `True`. Para tensores que no requieren gradientes, configurar este atributo `False` para excluirlo del DAG de cálculo de gradiente.\n",
        "\n",
        "El tensor de salida de una operación requerirá gradientes incluso si solo tiene un tensor de entrada `requires_grad=True`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Does `a` require gradients? : False\n",
            "Does `b` require gradients?: True\n"
          ]
        }
      ],
      "source": [
        "x = torch.rand(5, 5)\n",
        "y = torch.rand(5, 5)\n",
        "z = torch.rand((5, 5), requires_grad=True)\n",
        "\n",
        "a = x + y\n",
        "print(f\"Does `a` require gradients? : {a.requires_grad}\")\n",
        "b = x + z\n",
        "print(f\"Does `b` require gradients?: {b.requires_grad}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En una NN, los parámetros que no calculan gradientes generalmente se denominan **frozen parameters**. Es útil “congelar” parte de su modelo si sabe de antemano que no necesitará los gradientes de esos parámetros (esto ofrece algunos beneficios de rendimiento al reducir los cálculos de autograd).\n",
        "\n",
        "Otro caso de uso común donde la exclusión del DAG es importante es para ajustar una red previamente capacitada ([finetuning pretrained network](https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html))\n",
        "\n",
        "En el ajuste fino, congelamos la mayor parte del modelo y, por lo general, solo modificamos las capas del clasificador para hacer predicciones en nuevas etiquetas. Veamos un pequeño ejemplo para demostrarlo. Como antes, cargamos un modelo resnet18 previamente entrenado y congelamos todos los parámetros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch import nn, optim\n",
        "\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "# Freeze all the parameters in the network\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Digamos que queremos ajustar el modelo en un nuevo conjunto de datos con 10 etiquetas. En resnet, el clasificador es la última capa lineal `model.fc`. Simplemente podemos reemplazarlo con una nueva capa lineal (descongelada por defecto) que actúa como nuestro clasificador."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model.fc = nn.Linear(512, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora todos los parámetros del modelo, excepto los parámetros de `model.fc`, están congelados. Los únicos parámetros que calculan los gradientes son los pesos y el sesgo de `model.fc`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Optimize only the classifier\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observe que, aunque registramos todos los parámetros en el optimizador, los únicos parámetros que calculan gradientes (y, por lo tanto, se actualizan en el descenso de gradientes) son los pesos y el sesgo del clasificador.\n",
        "\n",
        "La misma funcionalidad de exclusión está disponible como administrador de contexto en [`torch.no_grad()`](https://pytorch.org/docs/stable/generated/torch.no_grad.html)"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "d1c24abb23a313e1f9ae042292cd8e6e3c60c5818227ced3d46e3df2c65171ef"
    },
    "kernelspec": {
      "display_name": "Python 3.8.11 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
