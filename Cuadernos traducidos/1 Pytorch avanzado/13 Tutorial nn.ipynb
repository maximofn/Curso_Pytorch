{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ¿Que es torch.nn realmente?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "PyTorch proporciona los módulos y clases elegantemente diseñados [``torch.nn``](https://pytorch.org/docs/stable/nn.html), [``torch.optim``](https://pytorch.org/docs/stable/optim.html), [``Dataset``](https://pytorch.org/docs/stable/data.html?highlight=dataset#torch.utils.data.Dataset) y [``DataLoader``](https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader) para ayudarlo a crear y entrenar redes neuronales. Para utilizar completamente su poder y personalizarlos para su problema, debe comprender realmente exactamente lo que están haciendo. Para desarrollar esta comprensión, primero entrenaremos la red neuronal básica en el conjunto de datos MNIST sin utilizar ninguna característica de estos modelos; Inicialmente, solo usaremos la funcionalidad de tensor de PyTorch más básica. A continuación, vamos a añadir de forma incremental una característica de ``torch.nn``, ``torch.optim``, ``Dataset``, o ``DataLoader`` en un momento, mostrando exactamente lo que hace cada pieza, y cómo funciona para que el código sea más concisa, o más flexible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuración de datos MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Usaremos el conjunto de datos clásico [MNIST](http://deeplearning.net/data/mnist), que consiste en imágenes en blanco y negro de dígitos dibujados a mano (entre 0 y 9).\n",
        "\n",
        "Usaremos [``pathlib``](https://docs.python.org/3/library/pathlib.html) para tratar con rutas (parte de la biblioteca estándar de Python 3) y descargaremos el conjunto de datos mediante [solicitudes](http://docs.python-requests.org/en/master). Solo importaremos módulos cuando los usemos, para que pueda ver exactamente lo que se está usando en cada punto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import requests\n",
        "\n",
        "DATA_PATH = Path(\"data\")\n",
        "PATH = DATA_PATH / \"mnist\"\n",
        "\n",
        "PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "URL = \"https://github.com/pytorch/tutorials/raw/master/_static/\"\n",
        "FILENAME = \"mnist.pkl.gz\"\n",
        "\n",
        "if not (PATH / FILENAME).exists():\n",
        "        content = requests.get(URL + FILENAME).content\n",
        "        (PATH / FILENAME).open(\"wb\").write(content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Este conjunto de datos está en formato de matriz de numpy y se ha almacenado usando pickle, un formato específico de Python para serializar datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import gzip\n",
        "\n",
        "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
        "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cada imagen mide 28 x 28 y se almacena como una fila plana de 784 de longitud (= 28x28). Echemos un vistazo a uno; primero tenemos que remodelarlo a 2d."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(50000, 784)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from matplotlib import pyplot\n",
        "import numpy as np\n",
        "\n",
        "pyplot.imshow(x_train[0].reshape((28, 28)), cmap=\"gray\")\n",
        "print(x_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "PyTorch usa ``torch.tensor``, en lugar de matrices numpy, por lo que necesitamos convertir nuestros datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([5, 0, 4,  ..., 8, 4, 8])\n",
            "torch.Size([50000, 784])\n",
            "tensor(0) tensor(9)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "x_train, y_train, x_valid, y_valid = map(\n",
        "    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
        ")\n",
        "n, c = x_train.shape\n",
        "print(x_train, y_train)\n",
        "print(x_train.shape)\n",
        "print(y_train.min(), y_train.max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Red neuronal desde cero (sin torch.nn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Primero creemos un modelo usando nada más que operaciones de tensor de PyTorch.\n",
        "\n",
        "PyTorch proporciona métodos para crear tensores llenos de cero o aleatorios, que usaremos para crear nuestros pesos y sesgos para un modelo lineal simple. Estos son solo tensores regulares, con una adición muy especial: le decimos a PyTorch que requieren un gradiente. Esto hace que PyTorch registre todas las operaciones realizadas en el tensor, de modo que pueda calcular el gradiente durante la retropropagación automáticamente.\n",
        "\n",
        "Para los pesos, los configuramos ``requires_grad`` **después** de la inicialización, ya que no queremos que ese paso se incluya en el gradiente. (Tenga en cuenta que un final _ en PyTorch significa que la operación se realiza en el lugar).\n",
        "\n",
        " > **Nota**: Estamos inicializando los pesos aquí con la [inicialización de Xavier](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf) (multiplicando por 1/sqrt(n))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "weights = torch.randn(784, 10) / math.sqrt(784)\n",
        "weights.requires_grad_()\n",
        "bias = torch.zeros(10, requires_grad=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Gracias a la capacidad de PyTorch para calcular gradientes automáticamente, podemos usar cualquier función estándar de Python (u objeto invocable) como modelo. Así que escribamos una multiplicación de matriz simple y una suma transmitida para crear un modelo lineal simple. También necesitamos una función de activación, así que escribiremos ``log_softmax`` y la usaremos. Recuerde: aunque PyTorch proporciona muchas funciones de pérdida preescritas, funciones de activación, etc., puede escribir fácilmente las suyas propias usando Python simple. PyTorch incluso creará código de GPU rápido o de CPU vectorizado para su función automáticamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def log_softmax(x):\n",
        "    return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
        "\n",
        "def model(xb):\n",
        "    return log_softmax(xb @ weights + bias)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En lo anterior, ``@`` representa la operación del producto escalar. Llamaremos a nuestra función en un lote de datos (en este caso, 64 imágenes). Este es un *forward pass*. Tenga en cuenta que nuestras predicciones no serán mejores que las aleatorias en esta etapa, ya que comenzamos con pesos aleatorios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-2.6717, -1.8259, -2.0875, -2.6154, -2.6661, -2.1858, -2.6514, -2.1348,\n",
            "        -2.2511, -2.3368], grad_fn=<SelectBackward>) torch.Size([64, 10])\n"
          ]
        }
      ],
      "source": [
        "bs = 64  # batch size\n",
        "\n",
        "xb = x_train[0:bs]  # a mini-batch from x\n",
        "preds = model(xb)  # predictions\n",
        "preds[0], preds.shape\n",
        "print(preds[0], preds.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como puede ver, el tensor ``preds`` contiene no solo los valores del tensor, sino también una función de gradiente. Usaremos esto más tarde para hacer backprop.\n",
        "\n",
        "Implementemos una probabilidad de registro negativa para usarla como función de pérdida (nuevamente, podemos usar Python estándar):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def nll(input, target):\n",
        "    return -input[range(target.shape[0]), target].mean()\n",
        "\n",
        "loss_func = nll"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comprobemos nuestra pérdida con nuestro modelo aleatorio, para que podamos ver si mejoramos después de un pase de backprop más tarde."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.3309, grad_fn=<NegBackward>)\n"
          ]
        }
      ],
      "source": [
        "yb = y_train[0:bs]\n",
        "print(loss_func(preds, yb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Implementemos también una función para calcular la precisión de nuestro modelo. Para cada predicción, si el índice con el valor más grande coincide con el valor objetivo, entonces la predicción fue correcta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def accuracy(out, yb):\n",
        "    preds = torch.argmax(out, dim=1)\n",
        "    return (preds == yb).float().mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comprobemos la precisión de nuestro modelo aleatorio, para que podamos ver si nuestra precisión mejora a medida que mejora nuestra pérdida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0312)\n"
          ]
        }
      ],
      "source": [
        "print(accuracy(preds, yb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora podemos ejecutar un ciclo de entrenamiento. Para cada iteración, haremos lo siguiente:\n",
        "\n",
        " * seleccione un mini-lote de datos (de tamaño ``bs``)\n",
        " * usar el modelo para hacer predicciones\n",
        " * calcular la perdida\n",
        " * loss.backward() actualiza los gradientes del modelo, en este caso, ``weights`` y ``bias``.\n",
        "\n",
        "\n",
        "Ahora usamos estos gradientes para actualizar los ``weights`` y ``bias``. Hacemos esto dentro del administrador de contexto ``torch.no_grad()``, porque no queremos que estas acciones se registren para nuestro próximo cálculo del gradiente. Puede leer más sobre cómo PyTorch's Autograd registra las operaciones [aquí](https://pytorch.org/docs/stable/notes/autograd.html).\n",
        "\n",
        "Luego, establecemos los gradientes en cero, de modo que estemos listos para el siguiente ciclo. De lo contrario, nuestros gradientes registrarían un recuento de todas las operaciones que habían sucedido (es decir, ``loss.backward()`` agregarían los gradientes a lo que ya esté almacenado, en lugar de reemplazarlos).\n",
        "\n",
        " > **Tip**:\n",
        " > Puede usar el depurador de Python estándar para recorrer el código PyTorch, lo que le permite verificar los distintos valores de las variables en cada paso. Descomenta ``set_trace()`` a continuación para probarlo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from IPython.core.debugger import set_trace\n",
        "\n",
        "lr = 0.5  # learning rate\n",
        "epochs = 2  # how many epochs to train for\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for i in range((n - 1) // bs + 1):\n",
        "        #         set_trace()\n",
        "        start_i = i * bs\n",
        "        end_i = start_i + bs\n",
        "        xb = x_train[start_i:end_i]\n",
        "        yb = y_train[start_i:end_i]\n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        loss.backward()\n",
        "        with torch.no_grad():\n",
        "            weights -= weights.grad * lr\n",
        "            bias -= bias.grad * lr\n",
        "            weights.grad.zero_()\n",
        "            bias.grad.zero_()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Eso es todo: hemos creado y entrenado una red neuronal mínima (en este caso, una regresión logística, ya que no tenemos capas ocultas) ¡completamente desde cero!\n",
        "\n",
        "Comprobemos la pérdida y la precisión y comparémoslas con lo que obtuvimos antes. Esperamos que la pérdida haya disminuido y la precisión haya aumentado, y lo han hecho."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0797, grad_fn=<NegBackward>) tensor(1.)\n"
          ]
        }
      ],
      "source": [
        "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Usando torch.nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora refactorizaremos nuestro código, para que haga lo mismo que antes, solo que comenzaremos a aprovechar las clases de PyTorch ``nn`` para hacerlo más conciso y flexible. En cada paso a partir de aquí, deberíamos hacer nuestro código uno o más de: más corto, más comprensible y/o más flexible.\n",
        "\n",
        "El primer paso y el más fácil es acortar nuestro código reemplazando nuestras funciones de activación y pérdida escritas a mano por las de ``torch.nn.functional`` (que generalmente se importa al espacio de nombres ``F`` por convención). Este módulo contiene todas las funciones de la biblioteca ``torch.nn`` (mientras que otras partes de la biblioteca contienen clases). Además de una amplia gama de funciones de pérdida y activación, también encontrará aquí algunas funciones convenientes para crear redes neuronales, como las funciones de agrupación. (También hay funciones para hacer convoluciones, capas lineales, etc., pero como veremos, generalmente se manejan mejor usando otras partes de la biblioteca).\n",
        "\n",
        "Si está utilizando una pérdida de probabilidad de registro negativa y una activación de softmax de registro, entonces Pytorch proporciona una única función ``F.cross_entropy`` que combina los dos. Así que incluso podemos eliminar la función de activación de nuestro modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "loss_func = F.cross_entropy\n",
        "\n",
        "def model(xb):\n",
        "    return xb @ weights + bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tenga en cuenta que ya no llamamos a ``log_softmax`` en la función model. Confirmemos que nuestra pérdida y precisión son las mismas que antes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0797, grad_fn=<NllLossBackward>) tensor(1.)\n"
          ]
        }
      ],
      "source": [
        "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Refactorizar usando nn.Module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuación, usaremos ``nn.Module`` y ``nn.Parameter``, para un ciclo de entrenamiento más claro y conciso. Hacemos una subclase ``nn.Module`` (que en sí misma es una clase y es capaz de realizar un seguimiento del estado). En este caso, queremos crear una clase que contenga nuestros pesos, sesgo y método para el forward step. ``nn.Module`` tiene una serie de atributos y métodos (como ``.parameters()`` y ``.zero_grad()``) que usaremos.\n",
        "\n",
        " > **Nota**:\n",
        " > ``nn.Module`` (M mayúscula) es un concepto específico de PyTorch, y es una clase que usaremos mucho. ``nn.Module`` no debe confundirse con el concepto de Python de un [module](https://docs.python.org/3/tutorial/modules.html) (en minúsculas m) , que es un archivo de código Python que se puede importar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class Mnist_Logistic(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.weights = nn.Parameter(torch.randn(784, 10) / math.sqrt(784))\n",
        "        self.bias = nn.Parameter(torch.zeros(10))\n",
        "\n",
        "    def forward(self, xb):\n",
        "        return xb @ self.weights + self.bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dado que ahora estamos usando un objeto en lugar de solo usar una función, primero tenemos que crear una instancia de nuestro modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = Mnist_Logistic()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora podemos calcular la pérdida de la misma forma que antes. Tenga en cuenta que los objetos ``nn.Module`` se utilizan como si fueran funciones (es decir, son *invocables*), pero detrás de escena Pytorch llamará a nuestro método ``forward`` automáticamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.4979, grad_fn=<NllLossBackward>)\n"
          ]
        }
      ],
      "source": [
        "print(loss_func(model(xb), yb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Anteriormente, para nuestro ciclo de entrenamiento, teníamos que actualizar los valores para cada parámetro por nombre y poner a cero manualmente los grados de cada parámetro por separado, así:\n",
        "\n",
        "```python\n",
        "with torch.no_grad():\n",
        "    weights -= weights.grad * lr\n",
        "    bias -= bias.grad * lr\n",
        "    weights.grad.zero_()\n",
        "    bias.grad.zero_()\n",
        "```\n",
        "\n",
        "Ahora podemos aprovechar ``model.parameters()`` y ``model.zero_grad()`` (ambos definidos por PyTorch para ``nn.Module``) para hacer esos pasos más concisos y menos propensos al error de olvidar algunos de nuestros parámetros, particularmente si tuviéramos un modelo más complicado:\n",
        "\n",
        "```python\n",
        "with torch.no_grad():\n",
        "    for p in model.parameters(): p -= p.grad * lr\n",
        "    model.zero_grad()\n",
        "```\n",
        "\n",
        "Envolveremos nuestro pequeño ciclo de entrenamiento en una función ``fit`` para que podamos ejecutarlo de nuevo más tarde."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def fit():\n",
        "    for epoch in range(epochs):\n",
        "        for i in range((n - 1) // bs + 1):\n",
        "            start_i = i * bs\n",
        "            end_i = start_i + bs\n",
        "            xb = x_train[start_i:end_i]\n",
        "            yb = y_train[start_i:end_i]\n",
        "            pred = model(xb)\n",
        "            loss = loss_func(pred, yb)\n",
        "\n",
        "            loss.backward()\n",
        "            with torch.no_grad():\n",
        "                for p in model.parameters():\n",
        "                    p -= p.grad * lr\n",
        "                model.zero_grad()\n",
        "\n",
        "fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comprobemos dos veces que nuestra pérdida ha disminuido:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0837, grad_fn=<NllLossBackward>)\n"
          ]
        }
      ],
      "source": [
        "print(loss_func(model(xb), yb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Refactorizar usando nn.Lineal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Seguimos refactorizando nuestro código. En lugar de definir e inicializar manualmente ``self.weights`` y ``self.bias``, y calcular ``xb@self.weights + self.bias``, usaremos la clase [``nn.Linear``](https://pytorch.org/docs/stable/nn.html#linear-layers) de Pytorch para una capa lineal, que hace todo eso por nosotros. Pytorch tiene muchos tipos de capas predefinidas que pueden simplificar enormemente nuestro código y, a menudo, también lo hacen más rápido"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class Mnist_Logistic(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.lin = nn.Linear(784, 10)\n",
        "\n",
        "    def forward(self, xb):\n",
        "        return self.lin(xb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Instanciamos nuestro modelo y calculamos la pérdida de la misma manera que antes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.3060, grad_fn=<NllLossBackward>)\n"
          ]
        }
      ],
      "source": [
        "model = Mnist_Logistic()\n",
        "print(loss_func(model(xb), yb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Todavía podemos usar nuestro mismo método ``fit`` igual que antes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0801, grad_fn=<NllLossBackward>)\n"
          ]
        }
      ],
      "source": [
        "fit()\n",
        "\n",
        "print(loss_func(model(xb), yb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Refactorizar usando optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pytorch también tiene un paquete con varios algoritmos de optimización, ``torch.optim``. Podemos usar el método ``step`` de nuestro optimizador para dar un paso adelante, en lugar de actualizar manualmente cada parámetro.\n",
        "\n",
        "Esto nos permitirá reemplazar nuestro anterior paso de optimización codificado manualmente:\n",
        "\n",
        "```python\n",
        "with torch.no_grad():\n",
        "    for p in model.parameters(): p -= p.grad * lr\n",
        "    model.zero_grad()\n",
        "```\n",
        "\n",
        "y en su lugar use solo:\n",
        "\n",
        "```python\n",
        "opt.step()\n",
        "opt.zero_grad()\n",
        "```\n",
        "\n",
        "(``optim.zero_grad()`` restablece el gradiente a 0 y debemos llamarlo antes de calcular el gradiente para el siguiente minibatch)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch import optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Definiremos una pequeña función para crear nuestro modelo y optimizador para que podamos reutilizarlo en el futuro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.3182, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0814, grad_fn=<NllLossBackward>)\n"
          ]
        }
      ],
      "source": [
        "def get_model():\n",
        "    model = Mnist_Logistic()\n",
        "    return model, optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "model, opt = get_model()\n",
        "print(loss_func(model(xb), yb))\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for i in range((n - 1) // bs + 1):\n",
        "        start_i = i * bs\n",
        "        end_i = start_i + bs\n",
        "        xb = x_train[start_i:end_i]\n",
        "        yb = y_train[start_i:end_i]\n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "print(loss_func(model(xb), yb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Refactorizar usando Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "PyTorch tiene una clase de conjunto de datos abstracta. Un conjunto de datos puede ser cualquier cosa que tenga una función ``__len__`` (llamada por la lenfunción estándar de Python) y una función ``__getitem__`` como una forma de indexarlo. Este [tutorial](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html) muestra un buen ejemplo de cómo crear una clase ``FacialLandmarkDataset`` personalizada como una subclase de ``Dataset``.\n",
        "\n",
        "[``TensorDataset``](https://pytorch.org/docs/stable/_modules/torch/utils/data/dataset.html#TensorDataset) de PyTorch es un conjunto de datos que envuelve tensores. Al definir una longitud y una forma de indexar, esto también nos da una forma de iterar, indexar y cortar a lo largo de la primera dimensión de un tensor. Esto facilitará el acceso tanto a las variables independientes como a las dependientes en la misma línea mientras entrenamos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ambos ``x_train`` y ``y_train`` se pueden combinar en uno solo ``TensorDataset``, lo que será más fácil de iterar y cortar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train_ds = TensorDataset(x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Anteriormente, teníamos que iterar a través de minibatches de valores x e y por separado:\n",
        "\n",
        "```python\n",
        "xb = x_train[start_i:end_i]\n",
        "yb = y_train[start_i:end_i]\n",
        "```\n",
        "\n",
        "Ahora, podemos hacer estos dos pasos juntos:\n",
        "\n",
        "```python\n",
        "xb = x_train[start_i:end_i]\n",
        "yb = y_train[start_i:end_i]\n",
        "```\n",
        "\n",
        "xb,yb = train_ds[i*bs : i*bs+bs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0812, grad_fn=<NllLossBackward>)\n"
          ]
        }
      ],
      "source": [
        "model, opt = get_model()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for i in range((n - 1) // bs + 1):\n",
        "        xb, yb = train_ds[i * bs: i * bs + bs]\n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "print(loss_func(model(xb), yb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Refactorizar usando DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``DataLoaderes`` es responsable de administrar los lotes. Puede crear un ``DataLoader`` desde cualquier ``Dataset``. ``DataLoader`` facilita la iteración sobre lotes. En lugar de tener que usar ``train_ds[i*bs : i*bs+bs]``, ``DataLoader`` nos entrega cada minibatch automáticamente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_ds = TensorDataset(x_train, y_train)\n",
        "train_dl = DataLoader(train_ds, batch_size=bs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Anteriormente, nuestro ciclo iteraba sobre lotes (xb, yb) como este:\n",
        "\n",
        "```python\n",
        "for i in range((n-1)//bs + 1):\n",
        "    xb,yb = train_ds[i*bs : i*bs+bs]\n",
        "    pred = model(xb)\n",
        "```\n",
        "\n",
        "Ahora, nuestro bucle es mucho más limpio, ya que (xb, yb) se cargan automáticamente desde el cargador de datos:\n",
        "\n",
        "```python\n",
        "for xb,yb in train_dl:\n",
        "    pred = model(xb)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0814, grad_fn=<NllLossBackward>)\n"
          ]
        }
      ],
      "source": [
        "model, opt = get_model()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for xb, yb in train_dl:\n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "print(loss_func(model(xb), yb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Gracias a ``nn.Module``, ``nn.Parameter``, ``Dataset``, y ``DataLoader``, nuestro bucle de entrenamiento es ahora dramáticamente más pequeño y más fácil de entender. Intentemos ahora agregar las características básicas necesarias para crear modelos efectivos en la práctica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Agregar validación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En la sección 1, solo estábamos tratando de configurar un ciclo de entrenamiento razonable para usar en nuestros datos de entrenamiento. En realidad, **siempre** debe tener un conjunto de validación para identificar si está sobreajustado.\n",
        "\n",
        "Mezclar los datos de entrenamiento es [importante](https://www.quora.com/Does-the-order-of-training-data-matter-when-training-neural-networks) para evitar la correlación entre lotes y el sobreajuste. Por otro lado, la pérdida de validación será idéntica tanto si barajamos el conjunto de validación como si no. Dado que barajar lleva más tiempo, no tiene sentido barajar los datos de validación.\n",
        "\n",
        "Usaremos un tamaño de lote para el conjunto de validación que es dos veces más grande que el del conjunto de entrenamiento. Esto se debe a que el conjunto de validación no necesita backpropagation y, por lo tanto, requiere menos memoria (no necesita almacenar los gradientes). Aprovechamos esto para usar un tamaño de lote más grande y calcular la pérdida más rápidamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train_ds = TensorDataset(x_train, y_train)\n",
        "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
        "\n",
        "valid_ds = TensorDataset(x_valid, y_valid)\n",
        "valid_dl = DataLoader(valid_ds, batch_size=bs * 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calcularemos e imprimiremos la pérdida de validación al final de cada época.\n",
        "\n",
        "(Tenga en cuenta que siempre llamamos a ``model.train()`` antes del entrenamiento y a ``model.eval()`` antes de la inferencia, porque estos son utilizados por capas como ``nn.BatchNorm2d`` y ``nn.Dropout`` para garantizar un comportamiento apropiado para estas diferentes fases)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 tensor(0.3714)\n",
            "1 tensor(0.2934)\n"
          ]
        }
      ],
      "source": [
        "model, opt = get_model()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for xb, yb in train_dl:\n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        valid_loss = sum(loss_func(model(xb), yb) for xb, yb in valid_dl)\n",
        "\n",
        "    print(epoch, valid_loss / len(valid_dl))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Crear fit() y get_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora haremos una pequeña refactorización por nuestra cuenta. Dado que pasamos por un proceso similar dos veces para calcular la pérdida tanto para el conjunto de entrenamiento como para el conjunto de validación, hagamos eso en su propia función ``loss_batch``, que calcula la pérdida para un lote.\n",
        "\n",
        "Pasamos un optimizador para el conjunto de entrenamiento y lo usamos para realizar backprop. Para el conjunto de validación, no pasamos un optimizador, por lo que el método no realiza backprop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
        "    loss = loss_func(model(xb), yb)\n",
        "\n",
        "    if opt is not None:\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "    return loss.item(), len(xb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``fit`` ejecuta las operaciones necesarias para entrenar nuestro modelo y calcular las pérdidas de entrenamiento y validación para cada época."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for xb, yb in train_dl:\n",
        "            loss_batch(model, loss_func, xb, yb, opt)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            losses, nums = zip(\n",
        "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
        "            )\n",
        "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
        "\n",
        "        print(epoch, val_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``get_data`` devuelve cargadores de datos para los conjuntos de entrenamiento y validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def get_data(train_ds, valid_ds, bs):\n",
        "    return (\n",
        "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
        "        DataLoader(valid_ds, batch_size=bs * 2),\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora, todo nuestro proceso de obtención de los cargadores de datos y ajuste del modelo se puede ejecutar en 3 líneas de código:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 0.6188143182277679\n",
            "1 0.31489434183835985\n"
          ]
        }
      ],
      "source": [
        "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
        "model, opt = get_model()\n",
        "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Puede utilizar estas 3 líneas básicas de código para entrenar una amplia variedad de modelos. ¡Veamos si podemos usarlos para entrenar una red neuronal convolucional (CNN)!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cambiar a una CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora vamos a construir nuestra red neuronal con tres capas convolucionales. Debido a que ninguna de las funciones de la sección anterior asume nada sobre el formulario del modelo, podremos usarlas para entrenar una CNN sin ninguna modificación.\n",
        "\n",
        "Usaremos la clase [``Conv2d``](https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d) predefinida de Pytorch como nuestra capa convolucional. Definimos una CNN con 3 capas convolucionales. Cada convolución va seguida de un ReLU. Al final, realizamos un pooling promedio. (Tenga en cuenta que ``view`` es la versión de PyTorch de numpy ``reshape``)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class Mnist_CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1)\n",
        "        self.conv3 = nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    def forward(self, xb):\n",
        "        xb = xb.view(-1, 1, 28, 28)\n",
        "        xb = F.relu(self.conv1(xb))\n",
        "        xb = F.relu(self.conv2(xb))\n",
        "        xb = F.relu(self.conv3(xb))\n",
        "        xb = F.avg_pool2d(xb, 4)\n",
        "        return xb.view(-1, xb.size(1))\n",
        "\n",
        "lr = 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[``Momentum``](https://cs231n.github.io/neural-networks-3/#sgd) es una variación del descenso de gradiente estocástico que también tiene en cuenta las actualizaciones anteriores y, por lo general, conduce a un entrenamiento más rápido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 0.36609563262462613\n",
            "1 0.2646807765483856\n"
          ]
        }
      ],
      "source": [
        "model = Mnist_CNN()\n",
        "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## nn.Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``torch.nn`` tiene otra clase útil que podemos usar para simplificar nuestro código: [``Sequential``](https://pytorch.org/docs/stable/nn.html#torch.nn.Sequential). Un objeto ``Sequential`` ejecuta cada uno de los módulos que contiene, de forma secuencial. Esta es una forma más sencilla de escribir nuestra red neuronal.\n",
        "\n",
        "Para aprovechar esto, necesitamos poder definir fácilmente una **capa personalizada** a partir de una función determinada. Por ejemplo, PyTorch no tiene una capa de vista y necesitamos crear una para nuestra red. ``Lambda`` creará una capa que luego podremos usar al definir una red con ``Sequential``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class Lambda(nn.Module):\n",
        "    def __init__(self, func):\n",
        "        super().__init__()\n",
        "        self.func = func\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.func(x)\n",
        "\n",
        "\n",
        "def preprocess(x):\n",
        "    return x.view(-1, 1, 28, 28)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El modelo creado con ``Sequential`` es simplemente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 0.3352325009584427\n",
            "1 0.2778443576335907\n"
          ]
        }
      ],
      "source": [
        "model = nn.Sequential(\n",
        "    Lambda(preprocess),\n",
        "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.AvgPool2d(4),\n",
        "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
        ")\n",
        "\n",
        "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Envolviendo con DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nuestra CNN es bastante concisa, pero solo funciona con MNIST, porque:\n",
        " * Se asume que la entrada es un vector de tipo long de 28*28\n",
        " * Se asume que el tamaño final de la cuadrícula de CNN es 4*4 (ya que ese es el promedio\n",
        "agrupando el tamaño del grano que usamos)\n",
        "\n",
        "Vamos a deshacernos de estos dos supuestos, por lo que nuestro modelo funciona con cualquier imagen 2d de un solo canal. Primero, podemos eliminar la capa Lambda inicial moviendo el preprocesamiento de datos a un generador:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def preprocess(x, y):\n",
        "    return x.view(-1, 1, 28, 28), y\n",
        "\n",
        "\n",
        "class WrappedDataLoader:\n",
        "    def __init__(self, dl, func):\n",
        "        self.dl = dl\n",
        "        self.func = func\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dl)\n",
        "\n",
        "    def __iter__(self):\n",
        "        batches = iter(self.dl)\n",
        "        for b in batches:\n",
        "            yield (self.func(*b))\n",
        "\n",
        "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
        "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
        "valid_dl = WrappedDataLoader(valid_dl, preprocess)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuación, podemos reemplazar ``nn.AvgPool2d`` con ``nn.AdaptiveAvgPool2d``, lo que nos permite definir el tamaño del tensor de salida que queremos, en lugar del tensor de entrada que tenemos. Como resultado, nuestro modelo funcionará con cualquier tamaño de entrada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.AdaptiveAvgPool2d(1),\n",
        "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
        ")\n",
        "\n",
        "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Probémoslo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 0.32772532162666324\n",
            "1 0.25251343932151793\n"
          ]
        }
      ],
      "source": [
        "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Usando tu GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Si tiene la suerte de tener acceso a una GPU compatible con CUDA (puede alquilar una por aproximadamente $0.50/hora en la mayoría de los proveedores de la nube), puede usarla para acelerar su código. Primero verifique que su GPU esté funcionando en Pytorch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Y luego crea un objeto de dispositivo para él:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dev = torch.device(\n",
        "    \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Actualicemos ``preprocess`` para mover lotes a la GPU:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def preprocess(x, y):\n",
        "    return x.view(-1, 1, 28, 28).to(dev), y.to(dev)\n",
        "\n",
        "\n",
        "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
        "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
        "valid_dl = WrappedDataLoader(valid_dl, preprocess)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finalmente, podemos mover nuestro modelo a la GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model.to(dev)\n",
        "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Debería encontrar que corre más rápido ahora:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 0.24973450191020966\n",
            "1 0.18176193383932113\n"
          ]
        }
      ],
      "source": [
        "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resumen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora tenemos una canalización de datos general y un ciclo de entrenamiento que puede usar para entrenar muchos tipos de modelos usando Pytorch. Para ver qué tan simple puede ser el entrenamiento de un modelo ahora, eche un vistazo al cuaderno de muestra ``mnist_sample``.\n",
        "\n",
        "Por supuesto, hay muchas cosas que querrá agregar, como aumento de datos, ajuste de hiperparámetros, entrenamiento de monitoreo, aprendizaje de transferencia, etc. Estas funciones están disponibles en la biblioteca fastai, que se ha desarrollado utilizando el mismo enfoque de diseño que se muestra en este tutorial, lo que proporciona un siguiente paso natural para los profesionales que buscan llevar sus modelos más lejos.\n",
        "\n",
        "Prometimos al comienzo de este tutorial nos gustaría explicar a través del ejemplo de cada uno ``torch.nn``, ``torch.optim``, ``Dataset``, y ``DataLoader``. Así que resumamos lo que hemos visto:\n",
        "\n",
        " - **torch.nn**\n",
        "\n",
        "   + ``Module``: crea un invocable que se comporta como una función, pero también puede contener estados (como pesos de capa de red neuronal). Sabe que ``Parameter`` contiene y puede poner a cero todos sus gradientes, recorrerlos para actualizaciones de pesos, etc.\n",
        "   + ``Parameter``: un contenedor para un tensor que le dice a a ``Module`` que tiene pesos que necesitan actualizarse durante backprop. Solamente los tensores con el atributo ``requires_grad`` se actualizan\n",
        "   + ``functional``: un módulo (generalmente importado al ``F`` espacio de nombres por convención) que contiene funciones de activación, funciones de pérdida, etc., así como versiones sin estado de capas, como capas convolucionales y lineales.\n",
        " - ``torch.optim``: Contiene optimizadores como ``SGD``, que actualizan los pesos de ``Parameter`` durante el backward step\n",
        "   of ``Parameter`` during the backward step\n",
        " - ``Dataset``: Una interfaz abstracta de objetos con como ``__len__`` y ``__getitem__``, incluidas las clases proporcionadas con Pytorch como ``TensorDataset``\n",
        " - ``DataLoader``: Toma cualquiera ``Dataset`` y crea un iterador que devuelve lotes de datos.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
